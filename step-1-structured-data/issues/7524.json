{
  "_url": "https://github.com/PowerShell/PowerShell/issues/7524",
  "author": "alx9r",
  "body": "This arose from [#3008(comment)](https://github.com/PowerShell/PowerShell/issues/3008#issuecomment-411313301) where the slow performance of opening numerous runspaces that import modules was noted as a barrier to a generally-performant implementation of `Invoke-Parallel` and parallel `ForEach-Object`.  From what I can tell, this slow performance is a barrier to generally-performant PowerShell everywhere scriptblocks are invoked concurrently within a process.  One such example is the certificate validation scriptblock in #4970, which (as best I can tell) performs whatever CPU-bound work is necessary to import whatever modules are used for certificate validation each time the http client invokes `HttpClientHandler.ServerCertificateCustomValidationCallback`.\r\n\r\n### The root performance limiter\r\n\r\nCurrently, the performance of an implementation involving concurrent scriptblocks is limited by contention amongst threads importing a common script module in parallel.  That limitation is detailed in #7035.\r\n\r\n### What _is_ currently possible\r\n\r\nDespite #7035, it is possible to achieve some useful concurrency with slow-loading modules using the current Runspace implementation.  In order to achieve this, the following is necessary:\r\n\r\n* Open each runspace and import the required modules into it in anticipation of its use.  The best performance is (currently) achieved by importing modules into runspaces one runspace at a time because of the contention problems.\r\n* Reset and re-use the runspaces with the imported modules.  Note that [there are limitations to the degree to which a runspace can be reset](https://github.com/PowerShell/PowerShell/issues/7131#issuecomment-399229457), so you should expect some cross-talk between invocations as a result.\r\n\r\nI applied this strategy in an experimental implementation of `Invoke-Parallel`.  The processing of a CPU-bound workload on 8 cores looks like this (click to see the gif):\r\n\r\n[![invokeparallel](https://user-images.githubusercontent.com/11237922/44104673-5518b090-9fa4-11e8-9302-f23b72b237a1.png)](https://user-images.githubusercontent.com/11237922/44104697-6693cb70-9fa4-11e8-9b2b-52d6b42c837c.gif)\r\n\r\nIn this example, `Invoke-Parallel` is processing 20 items through the same scriptblock, and the scriptblock performs 10 operations on each item. You can see that runspaces are opened one at a time, and used as they become available.  They are re-used as each concurrent Scriptblock invokation completes.  So you get increasing parallelism as each runspace becomes available.  \r\n\r\nUsing this technique to parallelize unit tests on my 16-core computer took 40 seconds to open all the runspaces and reach full parallelism.  This is simply because it takes 40 seconds to import the test framework module and module under test 16 times.\r\n\r\n### What _is not_ currently possible\r\n\r\nAs best I can tell, it is currently not possible to open runspaces with imported modules within a single process any faster than single-threaded.  The problem with this is that if there is a demand for many concurrent scriptblocks that use a slow-loading module, the last scriptblock can be waiting in line for a runspace with imported modules for quite a while before it can start to execute.  This occurs easily when you want to invoke in parallel a scriptblock involving a blocking call  and a module that is slow loading.  \r\n\r\nFor example, Suppose you want to run a scriptblock that involves the following:\r\n\r\n*  a module that takes 1 second to import\r\n* a 20-second call to `Invoke-WebRequest`\r\n\r\nSuppose you want to invoke that scriptblock 20 times with different parameters.  Ideally this would all take around 20 seconds to complete, but with the current runspace implementation it would take 40 seconds: 20 seconds to import the module for 20 times into the 20 runspaces, and another 20 seconds for that runspace to invoke the 20th call to `Invoke-WebRequest`.\r\n\r\n### Runspace features that would support improved performance\r\n\r\nIt seems like the following features would support improved performance for concurrent scriptblocks:\r\n\r\n1. Relieve the contention that results when multiple threads attempt to import the same module.\r\n2. Rearrange when and how compilation of script modules occurs such that it is possible to pay the price of compilation as little once per process even when using that module in several runspaces.  It seems like this would involve two different things:\r\n   a. Introduce the concept of a compiled-but-not-imported script module.  The idea would be that the compiled script module could be used when `Runspace.Open()` is invoked such that numerous runspaces could be opened without having to compile the same module again.\r\n   b. Establish a supported way of defining multi-file script modules that doesn't involve invoking scriptblocks to gather the files.  By doing so, the compilation of a module could be separated from the invocation of its scriptblock.  Note that per [#5942(comment)](https://github.com/PowerShell/PowerShell/issues/5942#issuecomment-365067309) there currently doesn't seem to be an alternative to dot-sourcing `.ps1` files inside the `.psm1`.\r\n3. Reduce the cost of producing clones of a runspace with imported script modules.  I think this is what [@powercode's suggested Snapshot, ResetToSnapShot, and CloneSnapshot](https://github.com/PowerShell/PowerShell/issues/3008#issuecomment-411313301) could do.  I suspect that the time it takes to execute a script module's scriptblock on module import is probably non-trivial.  I'm not sure how, exactly, this would work since a module's scriptblock could be constructing any variety of objects that themselves aren't trivially clonable.\r\n4. Improve the ability to reset Runspaces to their InitialSessionState.  `ResetRunspaceState()` only resets variables, so there are situations where that precludes Runspace reuse.\r\n\r\nI think that (1) alone would be a significant improvement because at least then all the cores could be used for module import instead of just one.",
  "closed_at": null,
  "comments": [
    {
      "author": "BrucePay",
      "author_association": "COLLABORATOR",
      "body": "For some history on why things are the way they are:\r\n\r\nWhile we were implementing workflows in version 3, we spent a lot of time looking into runspace creation performance. Unfortunately, after a lot of work runspace creation was still too slow for our purposes. (Remember - every command in a workflow runs in a separate runspace).  A big part of what makes it slow is processing initial session state and then loading any modules. To get \"reasonable\" performance, we finally went with runspace reuse instead, adding the ability to reset the runspace variables back to their initial state but leaving commands alone otherwise we'd be back where we started. Resetting a runspace is not blindingly fast but it's at least an order of magnitude faster than creating a new runspace.  As far as cross-contamination with commands goes, it's mostly not a problem (item 4 above). Considering that most people run with module autoloading turned on, what's in your runspace at any given time is theoretically random but practically not important (most of the time). If you do really care about a specific (version of a) module, then you can force-load it into your runspace. Of course this incurs a non-trivial cost. By allowing modules to be \"cached\" in runspaces, you only incur the overhead the first time you use that runspace. Subsequent uses don't have have the overhead of the module load so for an 8-core processor, assuming 1 runspace per core, you'd load the module 8 times. If you're iterating over a 1000 objects, that becomes reasonable. Loading the module 1000 times is probably not. As far as script module contention goes, we compile a script exactly once then cache the results because compiling a script takes time, uses up a *lot* of memory and creates many, many objects. We cache to minimize this memory use. This is why there is contention - we can't allow the script to be compiled on multiple threads. On the other hand, subsequent imports of a script module don't need to get compiled again, just looked up in the cache which is much faster. (I think this addresses your items 1 and 2 above). Item 3  - cloning the dynamic state of an evaluated scriptblock - that might be possible - deep-clone the contents of the session state scope object at initial module load, cache it then use it to initialize new instances of that module by deep-cloning the clone. It's a bit complicated and I'm not sure how much of a performance win you'd get but it would be interesting to investigate. Item 4 I discussed earlier in this message.\r\n",
      "created_at": "2018-08-15T01:28:03Z",
      "updated_at": "2018-08-15T01:28:03Z"
    },
    {
      "author": "alx9r",
      "author_association": "NONE",
      "body": "Thank you very much for the background @BrucePay, that has really helped to set my expectations to be consistent with how PowerShell is implemented.\r\n\r\n>As far as script module contention goes, we compile a script exactly once then cache the results because compiling a script takes time, uses up a lot of memory and creates many, many objects. We cache to minimize this memory use. This is why there is contention - we can't allow the script to be compiled on multiple threads. On the other hand, subsequent imports of a script module don't need to get compiled again, just looked up in the cache which is much faster. (I think this addresses your items 1 and 2 above).\r\n\r\nThis sounds really ideal.  Now that I have looked for this caching, I can indeed see the speedup from caching for single-threaded import.  For example,\r\n\r\n```PowerShell\r\n1..2 |\r\n    % {\r\n        Measure-Command {\r\n            [powershell]::Create().AddScript({\r\n                Import-Module Pester\r\n            }).Invoke()\r\n        }\r\n    } |\r\n        % TotalSeconds\r\n```\r\n\r\noutputs\r\n\r\n```none\r\n2.981724\r\n0.7399639\r\n```\r\n\r\nThis seems consistent with the caching story you described in your last post: The first import took 3 seconds because it had to first compile the module, and the second import took only 0.74 seconds because the cached compiled module was used.\r\n\r\nFor concurrent importing of modules, however, I'm not seeing the same speedup on subsequent module imports.  For example,\r\n\r\n```PowerShell\r\n$p = [System.Environment]::ProcessorCount\r\n\"Processors: $p\"\r\n& {\r\n    @{\r\n        Label = 'first import        '\r\n        Time  = Measure-Command { Import-Module Pester }\r\n    }\r\n\r\n    Remove-Module Pester\r\n\r\n    @{\r\n        Label = 'second import       '\r\n        Time  = Measure-Command { Import-Module Pester }\r\n    }\r\n\r\n    $invocations = 1..$p |\r\n        % {\r\n            $powershell = [powershell]::Create().AddScript({\r\n                Measure-Command {Import-Module Pester}\r\n            })\r\n            [pscustomobject]@{\r\n                PowerShell = $powershell\r\n                Invocation = $powershell.BeginInvoke()\r\n            }\r\n        }\r\n\r\n    $invocations | \r\n        % { \r\n            @{\r\n                Label = 'concurrent import'\r\n                Time = $_.PowerShell.EndInvoke($_.Invocation)\r\n            }\r\n        }\r\n} |\r\n    % {\r\n        [pscustomobject]@{\r\n            Label = $_.Label\r\n            Time = $_.Time.TotalSeconds | % {[System.Math]::Round($_,2)}\r\n        }\r\n    }\r\n```\r\n\r\noutputs\r\n\r\n```none\r\nProcessors: 16\r\n\r\nLabel                Time\r\n-----                ----\r\nfirst import         3.01\r\nsecond import        0.78\r\nconcurrent import    3.89\r\nconcurrent import    3.92\r\nconcurrent import    3.68\r\nconcurrent import    3.87\r\nconcurrent import     3.9\r\nconcurrent import    3.57\r\nconcurrent import    3.92\r\nconcurrent import    3.89\r\nconcurrent import    3.78\r\nconcurrent import    3.54\r\nconcurrent import    3.86\r\nconcurrent import     3.8\r\nconcurrent import    3.88\r\nconcurrent import    3.84\r\nconcurrent import    3.86\r\nconcurrent import    3.34\r\n```\r\n\r\nThe \"second import\" was imported when no other thread was importing, and it took only 0.78 seconds.  Then the module was imported into 16 runspaces concurrently.  Each such import took 3 to 4 seconds to complete.  \r\n\r\nI was expecting the concurrent importing of an already-compiled-and-cached module to take about the same amount of time as such a single-threaded import.  What should I be expecting here?\r\n\r\n_Sidenote: Importing the uncached module concurrently (by commenting out the first and second import) results in the following:_\r\n\r\n```none\r\nProcessors: 16\r\n\r\nLabel             Time\r\n-----             ----\r\nconcurrent import 8.19\r\nconcurrent import  8.2\r\nconcurrent import 8.16\r\nconcurrent import 8.16\r\nconcurrent import 8.14\r\nconcurrent import 8.17\r\nconcurrent import 8.19\r\nconcurrent import 8.17\r\nconcurrent import 8.15\r\nconcurrent import 8.15\r\nconcurrent import 8.16\r\nconcurrent import 8.19\r\nconcurrent import 8.18\r\nconcurrent import 8.14\r\nconcurrent import 8.14\r\nconcurrent import 8.16\r\n```\r\n\r\n_This slow importing seems consistent with the contention during compilation that you described._",
      "created_at": "2018-08-21T01:34:53Z",
      "updated_at": "2018-08-21T01:34:53Z"
    }
  ],
  "created_at": "2018-08-14T17:58:06Z",
  "labels": [
    "WG-Engine",
    "WG-Engine-Performance",
    "Issue-Discussion"
  ],
  "number": 7524,
  "state": "open",
  "title": "Features to improve performance of concurrent Runspaces",
  "updated_at": "2018-08-21T01:34:53Z"
}