{
  "_url": "https://github.com/PowerShell/PowerShell/issues/8831",
  "author": "powercode",
  "body": "<!-- Anything that looks like this is a comment and can't be seen after the Pull Request is created. -->  \r\n\r\n## PR Summary\r\n\r\nCache FullName property in the ProviderInfo class. Causes extra string allocations for every item in the formatting pipeline.\r\n\r\n## PR Context  \r\n\r\n\r\n## PR Checklist\r\n\r\n- [x] [PR has a meaningful title](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n    - Use the present tense and imperative mood when describing your changes\r\n- [x] [Summarized changes](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [x] [Change is not breaking](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#making-breaking-changes)\r\n- [x] [Make sure all `.h`, `.cpp`, `.cs`, `.ps1` and `.psm1` files have the correct copyright header](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [x] This PR is ready to merge and is not [Work in Progress](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---work-in-progress).\r\n    - If the PR is work in progress, please add the prefix `WIP:` or `[ WIP ]` to the beginning of the title (the `WIP` bot will keep its status check at `Pending` while the prefix is present) and remove the prefix when the PR is ready.  \r\n- **User-facing changes**\r\n    - [x] Not Applicable\r\n    - **OR**  \r\n    - [ ] [Documentation needed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n        - [ ] Issue filed: <!-- Number/link of that issue here -->\r\n- **Testing - New and feature**\r\n    - [ ] N/A or can only be tested interactively\r\n    - **OR**\r\n    - [x] [Make sure you've added a new test if existing tests do not effectively test the code changed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#before-submitting)\r\n        - [ ] [Add `[feature]` to your commit messages if the change is significant or affects feature tests](https://github.com/PowerShell/PowerShell/blob/master/docs/testing-guidelines/testing-guidelines.md#requesting-additional-tests-for-a-pr)\r\n",
  "closed_at": "2019-02-07T04:23:27Z",
  "comments": [
    {
      "author": "adityapatwardhan",
      "author_association": "MEMBER",
      "body": "@powercode Please have a look at the test failure.",
      "created_at": "2019-02-05T17:46:06Z",
      "updated_at": "2019-02-05T17:46:06Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "Awesome. Out of curiosity: Do you have time measurements  of cases where this improvement is noticeable?",
      "created_at": "2019-02-06T22:00:32Z",
      "updated_at": "2019-02-06T22:00:42Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister It's mostly in allocations - it generates lots of extra strings, like 2 strings per item in the pipeline.\r\n\r\nI'm reasoning more in terms of steadily removing silly allocations, and fixing the worst offenders perf-wise, and eventually we will have a more snappy shell.\r\n\r\nThe image below show the dotmemory view of strings allocated, grouped by callstack, when looking at the first 50000 items in the windows dir. It wasn't the biggest, but it was one of the bigger, and it was low hanging fruit. Does it make sense?\r\n\r\n![image](https://user-images.githubusercontent.com/3505151/52378827-0a0bf800-2a69-11e9-8384-e6ae44040968.png)\r\n",
      "created_at": "2019-02-06T22:47:25Z",
      "updated_at": "2019-02-06T22:49:01Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "Thanks @powercode. Yes, makes sense. I agree that continous improvement will make it better over time. :)",
      "created_at": "2019-02-06T22:52:21Z",
      "updated_at": "2019-02-06T22:52:21Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister It may seem like I'm just doing random changes, but I actually measure things now and then :)\r\n\r\ndotTrace and dotMemory are almost always running on my machine.",
      "created_at": "2019-02-06T23:15:45Z",
      "updated_at": "2019-02-06T23:21:41Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@powercode I was not questioning it, I was just curious for my own education (because knowing this also means that one will know the scenarios where PSCore is stronger than Windows PowerShell meaning that I could recommend an upgrade to clients).\r\nWould you mind having a look at issue #7603 with Import-Csv please which is causing actual OutOfMemory problems in some workflows where CSV files are a couple of GB large.",
      "created_at": "2019-02-07T18:55:28Z",
      "updated_at": "2019-02-07T18:57:23Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister Windows PowerShell is still more efficient than PowerShell Core \r\nin many scenarios. Main reason that .Net Framework engine works differently than .Net Core one. Optimizing individual cmdlets would be fine, but maybe we need something more general.",
      "created_at": "2019-02-08T03:35:54Z",
      "updated_at": "2019-02-08T03:35:54Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister I'm currently working on optimizations for the formatting system, the filesystem provider, etc that makes it out-perform windows powershell with a huge margin, often like 4x. And with a memory footprint reduction of the similar size.\r\n\r\nImport-Csv is problematic, since our property abstraction is heavier that I would like it to be. Especially in cases like that, where we actually have a table, we wouldn't need to store all the metadata for each object. I haven't given it so much thought - just passed by it last fall when doing related work.\r\n\r\nI have an idea that I like to try out for Import-CSV - could drastically reduce the memory footprint.\r\nThat is to generate a dynamic assembly, with a class containing the fields of the CSV. ",
      "created_at": "2019-02-10T09:22:06Z",
      "updated_at": "2019-02-10T09:22:34Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I was thinking about compiling to classes too and found some problems in the approach. One problem could be solved by #8852 (not trivial). After finding IDataView  #8855 I suppose this is preferred way we should start research.",
      "created_at": "2019-02-10T10:18:49Z",
      "updated_at": "2019-02-10T10:18:49Z"
    }
  ],
  "created_at": "2019-02-05T16:41:15Z",
  "number": 8831,
  "state": "closed",
  "title": "Reduce string allocations when formatting file system objects.",
  "updated_at": "2019-02-10T10:18:49Z"
}