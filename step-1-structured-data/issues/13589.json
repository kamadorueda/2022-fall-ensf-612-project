{
  "_url": "https://github.com/PowerShell/PowerShell/issues/13589",
  "author": "nohwnd",
  "body": "<!-- Anything that looks like this is a comment and can't be seen after the Pull Request is created. -->\r\n\r\n# PR Summary\r\n\r\n<!-- Summarize your PR between here and the checklist. -->\r\n\r\nTrying to get early feedback on a feature proposal.\r\n\r\nThis PR enhances `Set-PSDebug -Trace` to write down timestamps for every powershell instruction instead of just writing to Debug stream. This information allows us to write a very simple, but very effective profiler, which does not require complicated AST rewriting to instrument the code. Additionally, this profiler is able to profile any code that runs in the session, in any ps file, not just a single scriptblock.  Additionally this would greatly simplify Code Coverage in Pester where we currently rely on AST analysis, and setting breakpoints on any hittable command, which makes code coverage extremely slow. This approach on the other hand seems to have very little overhead. \r\n\r\nThe behavior provided in this PR is similar to https://www.powershellgallery.com/packages/PSProfiler/1.0.2.0 and it's predecessors, but does not use any of it's code.\r\n\r\nA running example is provided in profiler-demo/demo.ps1, it profiles to two attached files and shows output like this: \r\n\r\n```shell\r\n\r\n>>>> file: C:\\Projects\\powershell\\profiler-demo\\test2.ps1\r\n\r\nLine Duration         HitCount Text\r\n---- --------         -------- ----\r\n   1 00:00:00.0065457       31 1..30 | % {\r\n   2 00:00:00.0065401       30     \"hello\"\r\n   3 00:00:00.0022406       30 }\r\n\r\n>>>> file: C:\\Projects\\powershell\\profiler-demo\\test1.ps1\r\n\r\nLine Duration         HitCount Text\r\n---- --------         -------- ----\r\n   1 00:00:00                0 function a {\r\n   2 00:00:00                0     \"me\"\r\n   3 00:00:00                0 }\r\n   4 00:00:00                0\r\n   5 00:00:00.0000154        3 function ff() {\r\n   6 00:00:00.0011866        3     \"hello\"\r\n   7 00:00:00.0009275        3     \"this\"\r\n   8 00:00:00.0006904        3     \"is\"\r\n   9 00:00:00.0006037        3     \"me\"\r\n  10 00:00:00.0000925        3 }\r\n  11 00:00:00                0\r\n  12 00:00:00.0010957        1 if ($true) {\r\n  13 00:00:00.0262122        1     \"hit\"\r\n  14 00:00:00                0 }\r\n  15 00:00:00                0 else {\r\n  16 00:00:00                0     \"not-hit\"\r\n  17 00:00:00                0 }\r\n  18 00:00:00                0\r\n  19 00:00:00.0005986        1 $a = @()\r\n  20 00:00:00                0\r\n  21 00:00:00.0035798       12 foreach ($i in 1..10) {\r\n  22 00:00:00.0020147       10     $a += @(100)\r\n  23 00:00:01.1893329       10     Start-Sleep -Milliseconds 100\r\n  24 00:00:00                0 }\r\n  25 00:00:00                0\r\n  26 00:00:01.0044725        1 [Threading.Thread]::Sleep(1000)\r\n  27 00:00:00                0\r\n  28 00:00:00.0004876        1 ff\r\n  29 00:00:00.0001773        1 ff\r\n  30 00:00:00.0001201        1 ff\r\n  31 00:00:00                0\r\n```\r\n\r\nThe implementation is very simple. Trace level 3 is introduced to `Set-PSDebug`. When `Set-PSDebug -Trace 3` is used, every PowerShell instruction adds a hit entry into `[System.Management.Automation.Profiler]::Hits` collection. The hit entry lists in which file, on which line and when the hit happened. It also checks if there is any previous hit and updates when it ended, to get the total duration of that instruction. The data are then exposed via a static property and processed by `Get-Profile` function (attached in the demo.ps1). That function simply adds up all the traced entries for the files and returns them in an object. \r\n\r\nThis gives us at minimum, overview of how many times was each line hit, and how long the line took overall. But with more careful analysis we could also see who called the current function the most, how long did a given function or branch took overall, what are the hotspots etc. \r\n\r\nThe implementation should mainly show a proof of concept, and start a discussion of how this data should be made available and how much of the profiling functionality should be implemented in powershell itself. I am purposefully limiting the profiling to just files, to avoid handing some of the edge cases. I also butchered the Debug output in some cases. \r\n\r\nI would love answers to the following questions: \r\n\r\n- Would you allow such change to be made and this data to be collected? \r\n- Should powershell only collect the data and the basic analysis should be done in a custom module (hopefully @IISResetMe  will share keys to his PSProfiler module \ud83e\udd1e)\r\n- OR This basic implementation is pretty tiny, should we add it directly to Powershell? \r\n- Should the profiling become it's own mechanism and a cmdlet, or Set-PSDebug should get some callback (probably pointer to a method, because we probably can't run compiled powershell code in a scriptblock callback?)\r\n- I would also add way to specify the files to be traced, with some `-like` wildcard, to allow profiling many files at the same time, but not absolutely everything that get's executed.\r\n\r\nIn the end we might have something like this: \r\n\r\n```powershell\r\nStart-PSProfiler -Path \"C:\\MyCode\\\" # <- directory with 20 files\r\nStart-PSProfiler -ScriptBlock { ...my code... }\r\n\r\n... run some code \r\n\r\n$profile = Stop-PSProfiler \r\n```\r\n\r\nOr maybe some `Measure-Script -ScriptBlock { } ` type of syntax. \r\n\r\nIdeally a basic way would be built in, with the ability to get the raw data, and process them yourself.\r\n\r\n## PR Context\r\n\r\n<!-- Provide a little reasoning as to why this Pull Request helps and why you have opened it. -->\r\n\r\nProfiling code, and collecting Code Coverage is extremely difficult in PowerShell, but with little support from the runtime we can easily profile and code coverage, in a performant way.\r\n\r\n\r\n## PR Checklist\r\n\r\n- [x] [PR has a meaningful title](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n    - Use the present tense and imperative mood when describing your changes\r\n- [x] [Summarized changes](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [ ] [Make sure all `.h`, `.cpp`, `.cs`, `.ps1` and `.psm1` files have the correct copyright header](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [ ] This PR is ready to merge and is not [Work in Progress](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---work-in-progress).\r\n    - If the PR is work in progress, please add the prefix `WIP:` or `[ WIP ]` to the beginning of the title (the `WIP` bot will keep its status check at `Pending` while the prefix is present) and remove the prefix when the PR is ready.\r\n- **[Breaking changes](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#making-breaking-changes)**\r\n    - [ ] None\r\n    - **OR**\r\n    - [ ] [Experimental feature(s) needed](https://github.com/MicrosoftDocs/PowerShell-Docs/blob/staging/reference/6/Microsoft.PowerShell.Core/About/about_Experimental_Features.md)\r\n        - [ ] Experimental feature name(s): <!-- Experimental feature name(s) here -->\r\n- **User-facing changes**\r\n    - [ ] Not Applicable\r\n    - **OR**\r\n    - [ ] [Documentation needed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n        - [ ] Issue filed: <!-- Number/link of that issue here -->\r\n- **Testing - New and feature**\r\n    - [ ] N/A or can only be tested interactively\r\n    - **OR**\r\n    - [ ] [Make sure you've added a new test if existing tests do not effectively test the code changed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#before-submitting)\r\n- **Tooling**\r\n    - [ ] I have considered the user experience from a tooling perspective and don't believe tooling will be impacted.\r\n    - **OR**\r\n    - [ ] I have considered the user experience from a tooling perspective and enumerated concerns in the summary. This may include:\r\n        - Impact on [PowerShell Editor Services](https://github.com/PowerShell/PowerShellEditorServices) which is used in the [PowerShell extension](https://github.com/PowerShell/vscode-powershell) for VSCode (which runs in a different PS Host).\r\n        - Impact on Completions (both in the console and in editors) - one of PowerShell's most powerful features.\r\n        - Impact on [PSScriptAnalyzer](https://github.com/PowerShell/PSScriptAnalyzer) (which provides linting & formatting in the editor extensions).\r\n        - Impact on [EditorSyntax](https://github.com/PowerShell/EditorSyntax) (which provides syntax highlighting with in VSCode, GitHub, and many other editors).\r\n",
  "closed_at": "2020-10-08T07:26:08Z",
  "comments": [
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "A method based on Ast visitors is more accurate, power and reliable. And more slow of cause. We could add some enhancements in PowerShell Engine to make it more faster - Why do we need to set breakpoints on every line? I hope we could avoid this.\r\nA kind of sampling is alternative method that is proposed in the PR. I am not sure that it is so useful for Pester as first method. As for implementation it is more \"powershelly\" to enhance Trace-Command cmdlet to support files.",
      "created_at": "2020-09-07T06:29:37Z",
      "updated_at": "2020-09-07T06:29:37Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "@iSazonov When you talk about AST being more accurate, powerful and reliable what are you comparing it to? The approach proposed in this PR gives us a way better baseline, and is able to profile any script without having to resort to AST. This is a huge limitation of PSProfiler / Measure-Script, you can analyze only a single scriptblock, and any referenced scripts are not instrumented. And you have to have an AST Visitor that understands every branch of your code and instruments it. This PR shows a way to do this without any of that.\r\n\r\nAs for Code Coverage, I am sure it will help Pester a lot. Some additional analysis will need to be done on the returned data to identify lines that can't be hit (e.g. empty line, return, else etc.), but that is pretty easy, we already have AST analyzer that does that, and imho we could write a simple regex that gets us 95% there. Or do you see some obvious gap that I am missing?\r\n\r\nAll in all, I am really excited about this change, and would love to get it in one form or another. \ud83d\ude42",
      "created_at": "2020-09-07T07:31:23Z",
      "updated_at": "2020-09-07T07:31:23Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> When you talk about AST being more accurate, powerful and reliable what are you comparing it to?\r\n\r\nI was not too accurate - both options (AST visitors and sampling) have pros and cons.\r\n\r\nI believe we don't want to add an profiler implementation in PowerShell Engine but we could enhance PowerShell Engine so that simplify third-party profiler implementations.\r\n\r\nIf PowerShell Debugger class is only source we can get an needed information from my suggestion is:\r\n- add Hit struct (with better name, maybe PSTraceLineEvent)\r\n- inject PSTraceSource in Debugger (can we use GetTracer() ?)\r\n- with PSTraceSource write raw Hit structs to trace listeners\r\n- enhance Trace-Command to turn on/off the feature\r\n- third-party Profiler (and maybe PowerShell Editor Service) can read from a file or a socket the Hit structs, collect and process its.\r\n",
      "created_at": "2020-09-08T13:38:41Z",
      "updated_at": "2020-09-08T13:38:41Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "Sounds good, except for the last point: \r\n\r\n> third-party Profiler (and maybe PowerShell Editor Service) can read from a file or a socket the Hit structs, collect and process its.\r\n\r\nCould this be all done directly by just providing a callback of some sort, e.g. `Action<PSTraceLineEvent>`? Writing and reading the file with results, or communicating over sockets seems like unnecessary overhead.\r\n",
      "created_at": "2020-09-08T14:49:39Z",
      "updated_at": "2020-09-08T14:49:39Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> Could this be all done directly by just providing a callback of some sort, e.g. Action<PSTraceLineEvent>? Writing and reading the file with results, or communicating over sockets seems like unnecessary overhead.\r\n\r\nI have big doubts that the callback is applicable here. A common practice is to release events so that an external tool can collect and analyze them.\r\nI guess you mean that the callback simplify a profile creation. This has negative effects on the engine.\r\nAlso, the callback will create an unpredictable delay, which just goes against the idea of \u200b\u200bthe profiler.\r\n",
      "created_at": "2020-09-08T17:16:02Z",
      "updated_at": "2020-09-08T17:16:02Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "Added @PaulHigin for debugger expertise and @daxian-dbw for performance insights.\r\n\r\nThis seems like a really valuable addition. The questions in my mind are:\r\n\r\n- What's the appropriate mechanism for this? The trace calls seem like a good one, but I don't know enough about the debugger to say whether they are the \"right\" one. Do they correspond to sequence points in a script?\r\n- What shape should the APIs take, where should they be accessible from and in what states? Should they require privileges? What about optimisations/pessimisations due to debugging?\r\n    - One thought that strikes me just based on the current prototype is that rather than being static, the API should probably be per-runspace or per-debugger\r\n    - Is coupling this to the debugger an implementation detail or does it make sense to the end user?",
      "created_at": "2020-09-08T20:15:18Z",
      "updated_at": "2020-09-08T20:15:18Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> One thought that strikes me just based on the current prototype is that rather than being static, the API should probably be per-runspace or per-debugger\r\n\r\nDebugger class is created per ExecutionContext.\r\n\r\n> Is coupling this to the debugger an implementation detail or does it make sense to the end user?\r\n\r\nDebugger class is already injected in execution process and if we could use this class it would greatly simplify the implementation.\r\nUsers will only see new parameter in `Trace-Command` like `Trace-Command -TraceFile @(file1, file2, file3)`.",
      "created_at": "2020-09-09T04:18:15Z",
      "updated_at": "2020-09-09T04:18:15Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "@PaulHigin @daxian-dbw Tagging you here one more time, in case you see some fundamental problems with this proposal. Thanks!",
      "created_at": "2020-09-14T17:54:02Z",
      "updated_at": "2020-09-14T17:54:02Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "One more thought.\r\n\r\n> I have big doubts that the callback is applicable here. A common practice is to release events so that an external tool can collect and analyze them.\r\n\r\nThis is always a classic tradeoff. Do we allow arbitrary callbacks so we can reuse this later but which could become a doorway for all kinds of issues, or do we specialise the API? Or do we make the callbacks into asynchronous events?\r\n\r\nFor a trace API, I don't think it needs to be synchronous (i.e. it can simply emit events with timestamps to subscriber threads). In turn that makes the API a bit more cohesive; it's not for arbitrary callbacks, but for trace events saying when and where code was hit. The only problem with not being synchronous is that a subscriber needs a way to know that a session has ended.",
      "created_at": "2020-09-14T18:12:25Z",
      "updated_at": "2020-09-14T18:13:57Z"
    },
    {
      "author": "vexx32",
      "author_association": "COLLABORATOR",
      "body": "Another possible problem with it being async is that there are well known complications that can tend to happen for any PS-focused tooling that might want to make use of such an API. That could perhaps be alleviated by packing it into an in-box cmdlet, though.",
      "created_at": "2020-09-14T20:41:05Z",
      "updated_at": "2020-09-14T20:43:44Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> For a trace API, I don't think it needs to be synchronous\r\n\r\nWe use standard trace API and it already injected in all PowerShell code base. Writing one more event will not worsen anything. (If this is really a problem then we will have to rewrite all the tracing code which looks unnecessary.)\r\n",
      "created_at": "2020-09-15T11:31:36Z",
      "updated_at": "2020-09-15T11:31:36Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "I tried implementing it via the TraceSource, and it is pretty annoying. \r\n\r\n- I am tracing in OnSequencePointHit and I need to enable debugging for Trace-Command to trace anything in my source. \r\n- Using the file listener I get terrible performance. For run of all pester tests the resulting log is 65MB and reading that takes couple of seconds. This is mainly because I can't filter the internal Pester calls, and exposing api to provide only the files to be traced does not fit well with the Trace-Command existing api. \r\n- It would be nice to have inMemoryListener but I would have to implement it. \r\n- All of this would give me a relatively simple way of collecting the trace in memory. \r\n\r\nBut here is another proposal, that does the same thing without most of the loose ends: \r\n\r\n- Add TraceVariable parameter to Set-PSDebug, this will be variable to be used as output of the trace collection.\r\n- If the variable does not exist we will create it on `Set-PSDebug -Trace 1 -TraceVariable \"trace\"`.\r\n- If the variable exist and has value of IList<PSTraceLine>, use it. \r\n- otherwise check the type of the value and throw. \r\n\r\nThis has great performance, the data are immediately available. And it requires minimal changes. The Api is also pretty natural to use, and don't require you to implement any c# code if you want to consume it (unlike using an event, where the handler could not be powershell action, because that would cause stack overflow): \r\n\r\n```powershell\r\nSet-PSDebug -Trace 1 -TraceVariable \"trace\"\r\n<Run your code> \r\nSet-PSDebug -Off\r\n\r\n<Fiddle with the $trace as you like. >\r\n```\r\n\r\nI played with it a bit and if the line struct looks like this, it seems to consume little memory, and have no noticable perf impact on the execution. I've run some Pester tests 10 times in a row and they still run for the same amount of time, and ran fast: \r\n\r\n```csharp\r\n    public struct PSTraceLine\r\n    {\r\n        public IScriptExtent Extent { get; set; }\r\n\r\n        public long Timestamp { get; set; }\r\n    }\r\n```\r\n\r\nAdditionally, by being able to provide the IList<PSTraceLine> instance ourselves, we can implement minimal filtering directly in the collection if we wish. \r\n\r\nWhat do you think?\r\n\r\n",
      "created_at": "2020-09-16T15:21:45Z",
      "updated_at": "2020-09-16T15:21:45Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "Code for that is here https://github.com/PowerShell/PowerShell/compare/master...nohwnd:pwsh-profiler-take2",
      "created_at": "2020-09-16T15:25:06Z",
      "updated_at": "2020-09-16T15:25:06Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": ">\r\n\r\n> I tried implementing it via the TraceSource, and it is pretty annoying.\r\n> \r\n> * I am tracing in OnSequencePointHit and I need to enable debugging for Trace-Command to trace anything in my source.\r\n\r\nWhy is it worse than `Set-PSDebug -Trace 1 / Set-PSDebug -Off`.\r\n\r\nAlso, for better UX we could implement Enable-Profiler/Disable-Profiler/Set-Profiler.\r\n\r\n> * Using the file listener I get terrible performance. For run of all pester tests the resulting log is 65MB and reading that takes couple of seconds. This is mainly because I can't filter the internal Pester calls, and exposing api to provide only the files to be traced does not fit well with the Trace-Command existing api.\r\n> * It would be nice to have inMemoryListener but I would have to implement it.\r\n\r\nIt is easy to implement such inMemoryListener. Also alternative scenarios could prefer a file output. The output should be binary (like EWT does) for performance. (If we converted timestamps to strings or Datetime we would lost performance over 100x or more.)\r\nAs for filtering, I'd expect Pester enable the profiler before a file run and disable after the file finished.\r\n\r\n> * All of this would give me a relatively simple way of collecting the trace in memory.\r\n> \r\n> But here is another proposal, that does the same thing without most of the loose ends:\r\n> \r\n> * Add TraceVariable parameter to Set-PSDebug, this will be variable to be used as output of the trace collection.\r\n\r\nAs I already said it is not right place for the profile feature. It is better to use *-Trace cmdlets or create new *-Profile cmdlets.\r\n\r\n> * If the variable does not exist we will create it on `Set-PSDebug -Trace 1 -TraceVariable \"trace\"`.\r\n> * If the variable exist and has value of IList, use it.\r\n> * otherwise check the type of the value and throw.\r\n\r\nIf we want to have a profiler feature in Engine it must works for both scripts and binaries too. I'd expect users will want to implement alternative profilers (in different IDEs).\r\n\r\n\r\n> \r\n> This has great performance, the data are immediately available. And it requires minimal changes. The Api is also pretty natural to use, and don't require you to implement any c# code if you want to consume it (unlike using an event, where the handler could not be powershell action, because that would cause stack overflow):\r\n> \r\n> ```powershell\r\n> Set-PSDebug -Trace 1 -TraceVariable \"trace\"\r\n> <Run your code> \r\n> Set-PSDebug -Off\r\n> \r\n> <Fiddle with the $trace as you like. >\r\n> ```\r\n> \r\n> I played with it a bit and if the line struct looks like this, it seems to consume little memory, and have no noticable perf impact on the execution. I've run some Pester tests 10 times in a row and they still run for the same amount of time, and ran fast:\r\n> \r\n> ```cs\r\n>     public struct PSTraceLine\r\n>     {\r\n>         public IScriptExtent Extent { get; set; }\r\n> \r\n>         public long Timestamp { get; set; }\r\n>     }\r\n> ```\r\n\r\nIt is right to have Timestamp as binary but we still lost performance on coping Extent. We could issue events for file start and file end, between them events could contain  Timestamp and Line number as binaries.\r\n\r\n> \r\n> Additionally, by being able to provide the IList instance ourselves, we can implement minimal filtering directly in the collection if we wish.\r\n> \r\n> What do you think?\r\n\r\n",
      "created_at": "2020-09-16T16:16:03Z",
      "updated_at": "2020-09-16T16:16:03Z"
    },
    {
      "author": "vexx32",
      "author_association": "COLLABORATOR",
      "body": "I dunno. I mean, I get that we do already have tracing cmdlets, but they trace events moreso than just lines of a script. I'm of the opinion that since the debugger is build from the beginning to be more cognizant of how a script is structured moreso than the _engine_ is structured, it's a better place to put things here.",
      "created_at": "2020-09-16T16:56:44Z",
      "updated_at": "2020-09-16T16:56:55Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "> As I already said it is not right place for the profile feature. It is better to use *-Trace cmdlets or create new *-Profile cmdlets.\r\n\r\nI don't get this. The cmdlet already has -Trace parameter, it combines Debugging with Trace, which is exactly what I do. I just write to a collection instead of writing it to debug stream. I don't do any profiling in the code, I just write a Trace. \r\n\r\nProfiling would be additional functionality provided by external module that would consume the data. This would be just a very simple way to get the data. They are not very useful by themselves, but it allows me to keep the change to PowerShell minimal.\r\n\r\n> Why is it worse than Set-PSDebug -Trace 1 / Set-PSDebug -Off.\r\n\r\n> Also, for better UX we could implement Enable-Profiler/Disable-Profiler/Set-Profiler.\r\n\r\nTrace-Command does not enable debugging by default. I have to enable tracing of my trace event, and then somehow enable debugging, but not by Set-PSDEbug -trace 1, because that writes to Debug stream. And then I need to run the code.\r\n\r\n> It is easy to implement such inMemoryListener. Also alternative scenarios could prefer a file output. The output should be binary (like EWT does) for performance. (If we converted timestamps to strings or Datetime we would lost performance over 100x or more.)\r\n\r\nYes, maybe, but why bother with adding another trace listener? We would also need to make it  work for all the possible traces, because the current api of Trace-Command is not suited well for using different tracers with different sources of events.\r\n\r\n> As for filtering, I'd expect Pester enable the profiler before a file run and disable after the file finished. \r\n\r\nYes but it would enable it before running the tests file, because we don't control how users import their dependencies. So we need a way to tell the profiler which files we are interested in, otherwise it captures everything from everywhere. Putting a lot of noise in the trace, and storing unnecessary data. \r\n\r\n> If we want to have a profiler feature in Engine it must works for both scripts and binaries too. I'd expect users will want to implement alternative profilers (in different IDEs).\r\n\r\nBy binaries you mean binary modules? That would require a totally different approach and I and the current tracing that writes to Debug does not do that either. Profiling your own \"C#\" code is not hard, you have VS and all the awesome tooling at your disposal. I don't see why we should complicated it with this. \r\n\r\nI also don't understand how implementing different profilers depends on being able to trace binary code. And I doubt there will be more that a handful of profilers, there is only so much you can do with the trace.\r\n\r\n> It is right to have Timestamp as binary but we still lost performance on coping Extent. We could issue events for file start and file end, between them events could contain Timestamp and Line number as binaries.\r\n\r\nIs it not just copying the struct that has a reference to IScriptExtent that already exists? I don't see any impact on the execution time, and it also is running in debug mode, so we expect some perf degradation to be there.\r\n\r\nHaving an event for start and end of file is further complicating the problem. \r\n\r\n",
      "created_at": "2020-09-16T17:29:50Z",
      "updated_at": "2020-09-16T17:29:50Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> Yes, maybe, but why bother with adding another trace listener? We would also need to make it work for all the possible traces, because the current api of Trace-Command is not suited well for using different tracers with different sources of events.\r\n\r\nIt is huge work to refactor all trace code. But it is not block additions which we can implement in right way.\r\n\r\n> By binaries you mean binary modules?\r\n\r\nNo, I mean hosting applications. I think about a profiler in VS Code/PES. \r\n\r\nYou are trying to find minimal and fastest solution for Pester (and maybe script scenarios (calling Profiler from script)) but I am sure that PowerShell engine must expose more power API so that users can profile scripts from scripts but also create other kinds of profilers and analyzers.",
      "created_at": "2020-09-17T05:20:55Z",
      "updated_at": "2020-09-17T05:20:55Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "> It is huge work to refactor all trace code. But it is not block additions which we can implement in right way.\r\n\r\nWhy are you forcing me to implement this in the most complicated way then? Trace-Command does not enable debugging, and I need debugging. Trace-Command does not have in memory trace and I need in memory tracer.\r\n\r\nOn the other hand Set-PSDebug enables debugging, and already has -Trace parameter, I just want a way to write the data to a different stream that I can consume, not just to Debug. \r\n\r\n> You are trying to find minimal and fastest solution for Pester (and maybe script scenarios (calling Profiler from script)) but I am sure that PowerShell engine must expose more power API so that users can profile scripts from scripts but also create other kinds of profilers and analyzers.\r\n\r\nYou are mostly right, I am trying to find a minimal solution so I can finally profile my scripts, without jumping through so many hoops. All I ask for is being able to write the trace in a way that I can consume it, instead of being written into Debug stream. That is it. You are trying to make this into an effort to allow profilers to be written in any IDE, but do you have any asks for it? \r\n\r\nIf someone wants to integrate this into VSCode they can call the same cmdlets as I do, or they can download the module that we will write around this, and use it. Or replicate that code in their language of choice. Look at Pester, it is also an external module and it integrates with VSCode. \r\n\r\n--- \r\n\r\nI am slowly giving up here. So how about the events that @rjmholt mentioned, is there an example of such event already in the engine, and where would I surface it? ",
      "created_at": "2020-09-17T08:33:01Z",
      "updated_at": "2020-09-17T08:33:01Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "Here is it implemented with event, much like `CommandNotFoundAction`. \r\n\r\nhttps://github.com/PowerShell/PowerShell/compare/master...nohwnd:pwsh-trace-with-sync-event\r\n\r\nI make sure to not invoke the action when already in the action. This way you can hook it up from PowerShell, by simply providing a scriptblock. You can also debug the provided scriptblock. With my basic example there is again no significant perf degradation even if running powershell scriptblock as the callback.  \r\n\r\nI don't think that making it async is worth it, because it is obvious that the more work you do in the callback the slower the code will be, and it would be difficult to leverage that in powershell. In C# we can simply push the data into a queue and process it on another thread, if we need. But seeing that even using scriptblock callback causes no visible perf degradation it probably won't be needed.\r\n\r\nThe naming and location could be improved. Do you have any suggestions?\r\n",
      "created_at": "2020-09-17T11:52:26Z",
      "updated_at": "2020-09-17T11:52:26Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> Why are you forcing me to implement this in the most complicated way then?\r\n\r\nI cannot force you. :-) Since we intend to make a new _public_ API, we need to weigh all the options.\r\n\r\n>  but do you have any asks for it?\r\n\r\nIt was always a big gap in PowerShell. We can find in Internet some Profiles implemented on tracing. Also MSFT team have an interest https://github.com/PowerShell/PowerShell/issues/7857#issuecomment-425978740",
      "created_at": "2020-09-17T12:12:04Z",
      "updated_at": "2020-09-17T12:12:04Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> Here is it implemented with event\r\n\r\nIf we consider only \"in-session\" profiling this looks like overhead and previous prototype is more good for the scenario where you directly collect full info in a list.",
      "created_at": "2020-09-17T12:24:40Z",
      "updated_at": "2020-09-17T12:24:40Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "It seems @daxian-dbw is busy maybe @lzybkr will share some thoughts.",
      "created_at": "2020-09-17T12:27:31Z",
      "updated_at": "2020-09-17T12:27:31Z"
    },
    {
      "author": "lzybkr",
      "author_association": "MEMBER",
      "body": "I honestly never considered `Set-PSDebug`, possibly because I was never a fan of the cmdlet, but I do see it is a viable approach for some scenarios.\r\n\r\nI do prefer an EventSource (or ETW for Windows) based approach. I actually started this approach a long time back [here](https://github.com/lzybkr/PowerShell/commit/d620bb4494b94a85a479ebd62ce935ba8e797ff5).\r\n\r\nA huge benefit to ETW is the ability to enable a trace from outside the process. It's more work to produce useful reports, but it's useful when you need to profile:\r\n* an already running script that you don't want to restart\r\n* hosted PowerShell processes that may not expose `Set-PSDebug`\r\n\r\nThat said, in-process is important too, and EventSource supports that. I don't think EventSource is a huge effort to support in-process, but my WIP is incomplete because my approach introduces some extra complexity to support ETW/out-of-process reporting.\r\n\r\nThe basic idea is to, while measuring, add as little impact as possible, collecting minimal information (collecting a GUID + sequence number while tracing) - then post process. In-process is a bit easier as the data structures are still in memory, ETW would require additional events to enable mapping the GUID+sequence number back to something meaningful. These events would be written after stopping the trace, similar to the .Net rundown events.",
      "created_at": "2020-09-17T19:27:30Z",
      "updated_at": "2020-09-17T19:27:30Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@lzybkr Many thanks! We could continue this work if @daxian-dbw hadn't intercepted it already. Have you a time to mentor?",
      "created_at": "2020-09-18T06:12:02Z",
      "updated_at": "2020-09-18T06:12:02Z"
    },
    {
      "author": "lzybkr",
      "author_association": "MEMBER",
      "body": "@iSazonov - I could mentor if someone wants to pick up my approach.",
      "created_at": "2020-09-21T17:40:49Z",
      "updated_at": "2020-09-21T17:40:49Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@lzybkr Thanks! Now I'm working with your code and I was able to get the first results. Now I'm stuck on \"rundown events\". because there we need to send an array of SequencePoint-s and I do not still find how implement this.\r\n",
      "created_at": "2020-09-22T04:22:16Z",
      "updated_at": "2020-09-22T04:22:16Z"
    },
    {
      "author": "lzybkr",
      "author_association": "MEMBER",
      "body": "@iSazonov - You would have 2 event sources: `ProfilerEventSource` and `RundownEventSource`. The sequence for an external profiler would be:\r\n1. Enable `ProfilerEventSource`\r\n2. Disable `ProfilerEventSource`\r\n3. Enable `RundownEventSource`\r\n4. Disable `RundownEventSource`\r\n\r\nI was thinking the `RundownEventSource` would generate:\r\n* 1 event per ScriptBlock with a payload of:\r\n  - Guid (for mapping events from the `ProfilerEventSource`\r\n  - ScriptBlock text\r\n* 1 event per sequence point with a payload of:\r\n  - Guid\r\n  - Id\r\n  - Extent\r\n\r\nThis way, a tool need not depend on PowerShell at all and could generate a nice report.",
      "created_at": "2020-09-22T16:40:57Z",
      "updated_at": "2020-09-22T16:40:57Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@lzybkr Thanks! I did not see your last comment and already pulled #13673. You can play with working prototype and feedback.\r\n\r\n@nohwnd Please look #13673 and feedback.",
      "created_at": "2020-09-22T17:25:26Z",
      "updated_at": "2020-09-22T17:25:26Z"
    },
    {
      "author": "msftbot[bot]",
      "author_association": "NONE",
      "body": "This pull request has been automatically marked as stale because it has been marked as requiring author feedback but has not had any activity for **15 days**. It will be closed if no further activity occurs **within 10 days of this comment**.",
      "created_at": "2020-10-07T20:00:05Z",
      "updated_at": "2020-10-07T20:00:05Z"
    },
    {
      "author": "nohwnd",
      "author_association": "NONE",
      "body": "This is superseded by #13673, thanks @iSazonov  for doing all the work! ",
      "created_at": "2020-10-08T07:26:08Z",
      "updated_at": "2020-10-08T07:26:08Z"
    }
  ],
  "created_at": "2020-09-06T19:14:41Z",
  "number": 13589,
  "state": "closed",
  "title": "Early feedback: PowerShell profiler",
  "updated_at": "2020-10-08T07:26:12Z"
}