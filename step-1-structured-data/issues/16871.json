{
  "_url": "https://github.com/PowerShell/PowerShell/issues/16871",
  "author": "Tarjei-stavanger",
  "body": "### Summary of the new feature / enhancement\n\nIt would help a lot if Import-CSV could be told to ignore newlines within delimited fields. There are text fields which contain text which legitimately contains newlines.\r\n\r\nExample of such legitimate use is output from some SQL server management tools found in www.firstresponderkit.org. It is really annoying that they can't be easily imported into Excel. And it does not help that Import-CSV can't handle it either.\r\n\r\nThe newlines for those tools are in columns which contain XML data. They work fine in SQL Server Management Studio, but getting the data into Excel would help a lot.\n\n### Proposed technical implementation details (optional)\n\n_No response_",
  "closed_at": "2022-02-13T00:00:42Z",
  "comments": [
    {
      "author": "jhoneill",
      "author_association": "NONE",
      "body": "```\r\n$text = @\" \r\nCol1,Col2,Col3\r\none,two,three\r\nfour,\"five\r\nand\r\nsix\",Seven\r\neight,\"\"\"nine\"\"\",ten\r\n\"@\r\nconvertfrom-csv $text\r\nCol1  Col2           Col3 \r\n----  ----           ---- \r\none   two            three\r\nfour  five...        Seven\r\neight \"nine\"         ten \r\n\r\n```\r\n\r\nIn a CSV file commas separate columns and new lines separate rows. If a field contains  a comma or a new line it needs to be wrapped in quotes, and if it contains quotes they need to be doubled up. \r\n\r\nIf the source file is generated by something which doesn't check for comma, newline or quotes in the data it needs to be pre-processed, although how you tell which new lines are \"end of row\" and which are not is a puzzle you will need to solve. \r\n\r\n**edit**\r\n>The newlines for those tools are in columns which contain XML data. They work fine in SQL Server Management Studio, but getting the data into Excel would help a lot.\r\n\r\nActually a regular expression to recognize a sequence of `<  >`  followed by a comma and put it in quote marks would probably fix it.  \r\n \r\n",
      "created_at": "2022-02-11T10:01:24Z",
      "updated_at": "2022-02-11T10:06:21Z"
    },
    {
      "author": "Tarjei-stavanger",
      "author_association": "NONE",
      "body": "For preprosessing, searching for a < preceded by a separator and a > followed by a separator will probably work. For SQL server, the separator is a tab.\r\n\r\nThere is quite a lot of XML in the exported query plans.\r\n\r\nThanks for the preprosessing idea!",
      "created_at": "2022-02-11T10:27:22Z",
      "updated_at": "2022-02-11T10:27:22Z"
    },
    {
      "author": "msftbot[bot]",
      "author_association": "NONE",
      "body": "This issue has been marked as answered and has not had any activity for **1 day**. It has been closed for housekeeping purposes.",
      "created_at": "2022-02-13T00:00:41Z",
      "updated_at": "2022-02-13T00:00:41Z"
    }
  ],
  "created_at": "2022-02-11T09:03:19Z",
  "labels": [
    "Issue-Enhancement",
    "Resolution-Answered",
    "WG-Cmdlets-Utility",
    "Needs-Triage"
  ],
  "number": 16871,
  "state": "closed",
  "title": "Import-CSV importing fields with newlines",
  "updated_at": "2022-02-13T00:00:42Z"
}