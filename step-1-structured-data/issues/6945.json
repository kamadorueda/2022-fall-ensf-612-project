{
  "_url": "https://github.com/PowerShell/PowerShell/issues/6945",
  "author": "bergmeister",
  "body": "## PR Summary\r\n\r\nRelated: #6944\r\n\r\nReduce PR build time by 5 minutes by:\r\n- Having Packaging as a separate build job in a matrix -> runs in parallel in PR builds because the Microsoft account is a paid account that allows that (at no additional costs)\r\n- Not caching the dotnet folder any more, which is too large and the overhead of zip/unzip/upload/download does not pay off (and fails in forked builds that are on a free AppVeyor account due to the size).\r\n- Setting the environment variable `DOTNET_SKIP_FIRST_TIME_EXPERIENCE` to `1` because the initialization of the dotnet cli cache (1 minute) does not pay off for the whole build.\r\n\r\nThe total build time of builds on a fork that is on a free AppVeyor account and therefore do not have parallelism, remains the same due to the time saving of redundant caching.\r\n\r\nThis is just a simple example of what we can easily achieve, we could continue this pattern and split the test runs as per the referenced issue to bring PR builds down to 10 minutes (but this will incur an increase for fork builds on free AppVeyor accounts)\r\n\r\n## PR Checklist\r\n\r\n- [x] [PR has a meaningful title](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n    - Use the present tense and imperative mood when describing your changes\r\n- [x] [Summarized changes](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [x] [Change is not breaking](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#making-breaking-changes)\r\n- [x] [Make sure all `.h`, `.cpp`, `.cs`, `.ps1` and `.psm1` files have the correct copyright header](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [ ] This PR is ready to merge and is not [Work in Progress](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---work-in-progress).\r\n    - If the PR is work in progress, please add the prefix `WIP:` to the beginning of the title and remove the prefix when the PR is ready.\r\n- **User-facing changes**\r\n    - [x] Not Applicable\r\n    - **OR**\r\n    - [ ] User-facing [Documentation needed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n        - [ ] Issue filed - Issue link:\r\n- **Testing - New and feature**\r\n    - [x] Not Applicable or can only be tested interactively\r\n    - **OR**\r\n    - [ ] [Make sure you've added a new test if existing tests do not effectively test the code changed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#before-submitting)\r\n        - [ ] [Add `[feature]` if the change is significant or affects feature tests](https://github.com/PowerShell/PowerShell/blob/master/docs/testing-guidelines/testing-guidelines.md#requesting-additional-tests-for-a-pr)\r\n",
  "closed_at": "2018-06-05T17:48:44Z",
  "comments": [
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Seems we don't want publish packages if tests failed.\r\nAnd \r\n```\r\nmatrix:\r\n  fast_finish: true\r\n```\r\ndoesn't help.\r\n",
      "created_at": "2018-05-28T04:06:53Z",
      "updated_at": "2018-05-28T04:07:53Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Restoring build cache take 4 minutes! Unzipping - can we cache unzipped data?",
      "created_at": "2018-05-28T05:19:03Z",
      "updated_at": "2018-05-28T05:19:03Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov `fast_finish: true` would still be helpful in the sense that running tests don't continue to run if the packaging build is broken. I don't see a reason for not publishing the packages even if some tests fail later on because if it is something that is just a prototype/experiment then I would not want to be blocked on that, in fact, the packages are the first thing that I want from a build.\r\nI do think that trying to cache dotnet does not pay off the zip/unzip/upload/download costs, instead of just installing the required dotnet SDK anyway (which takes only 12 seconds to download, extract and install). Especially in forks, the cache is too big for the free version, therefore that time is wasted because it fails at the end.\r\nI now set an environment variable `DOTNET_SKIP_FIRST_TIME_EXPERIENCE` to `1` to avoid unnecessary cache initialisation in this case, which saves around one minute",
      "created_at": "2018-05-28T09:11:56Z",
      "updated_at": "2018-05-28T09:17:31Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Make sense set DOTNET_SKIP_FIRST_TIME_EXPERIENCE in second job too?",
      "created_at": "2018-05-28T11:38:43Z",
      "updated_at": "2018-05-28T11:38:43Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Seems we could decouple still two job - for admin tests and xUnit tests. If first we start CI-tagged tests and then packaging, admin-tagged tests and xUnit tests we get minimal time about 14 minutes.",
      "created_at": "2018-05-28T14:35:30Z",
      "updated_at": "2018-05-28T14:35:30Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "Yes, that's why this PR is not supposed to close the issue but yes, this is the way to go, I have outlined ideas like that in the issue. This PR is just the first step to show the direction without disadvantages for builds on a fork with a free account. Bear in mind that for every additional build job, people on non-free AppVeyor accounts incur a 2 minute penalty on their fork builds (i.e. their own builds before they have submitted a PR) due to it having to bootstrap  the environment.\r\nIn general, I'd prefer to drip-feed those improvements one by one into master instead of having one big PR. This way we can also split the work should it get more technical with XUnit/Admin tests.\r\nFrom my point of view this PR is complete as it leads to an overall improvement on both sides (PR and fork builds) without any disadvantages.",
      "created_at": "2018-05-28T15:13:50Z",
      "updated_at": "2018-05-28T15:19:19Z"
    },
    {
      "author": "TravisEz13",
      "author_association": "MEMBER",
      "body": "I'm not sure this will speed things up.  It may actually slow things down as we often hit our maximum number of jobs.  We would need more budget to make this actually work.  @SteveL-MSFT   What do you think?",
      "created_at": "2018-05-31T19:27:04Z",
      "updated_at": "2018-05-31T19:27:04Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "I ran this also on my fork (which has only a concurrency of 1 because I am cheap \ud83d\ude1b ), the time was the same (due to time savings of dumping the dotnet caching and skipping the dotnet initialization). Therefore at least, when job pipelines are available (which probably applies more to me due due to my difference in time-zone and more frequent weekend work), then there will be a speedup. Of course a more efficient split-up would be to do something more expensive than packaging in the 2nd build but this is just the first step to show the future path",
      "created_at": "2018-05-31T19:39:07Z",
      "updated_at": "2018-05-31T19:57:52Z"
    },
    {
      "author": "TravisEz13",
      "author_association": "MEMBER",
      "body": "Does `DOTNET_SKIP_FIRST_TIME_EXPERIENCE` mean dotnet cli doesn't download the files?  We weren't caching the dotnet cache for perf but for reliability.  ",
      "created_at": "2018-05-31T20:07:07Z",
      "updated_at": "2018-05-31T20:07:07Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@travisez13\r\n`DOTNET_SKIP_FIRST_TIME_EXPERIENCE` skips the dotnet internal initial cache performance optimisation (that is only useful for long term performance but not when one uses dotnet only a couple of times in a build). It only happens on the very first dotnet command after a fresh install. This process takes about a minute, which is time that we never get back.\r\nFor details see e.g. here:\r\nhttp://donovanbrown.com/post/Stop-wasting-time-during-NET-Core-builds",
      "created_at": "2018-05-31T20:15:39Z",
      "updated_at": "2018-05-31T20:18:21Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@TravisEz13 Ok, done. What are your thoughts on the concern about reliability due to removing the CLI cache and instead always just installing it from scratch. PSScriptAnalyzer does this as well and I have not seen a sporadic failure due to that yet.",
      "created_at": "2018-06-04T20:40:07Z",
      "updated_at": "2018-06-04T20:41:00Z"
    },
    {
      "author": "TravisEz13",
      "author_association": "MEMBER",
      "body": "@bergmeister I think we can try it and see what happens.  ",
      "created_at": "2018-06-05T00:53:55Z",
      "updated_at": "2018-06-05T00:53:55Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister Thanks for the contribution!",
      "created_at": "2018-06-06T03:42:37Z",
      "updated_at": "2018-06-06T03:42:37Z"
    }
  ],
  "created_at": "2018-05-27T20:09:03Z",
  "number": 6945,
  "state": "closed",
  "title": "Use Appveyor matrix for faster PR builds",
  "updated_at": "2018-06-06T03:42:37Z"
}