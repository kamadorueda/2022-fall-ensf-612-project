{
  "_url": "https://github.com/PowerShell/PowerShell/issues/9268",
  "author": "jszabo98",
  "body": "<!--\r\n\r\nFor Windows PowerShell 5.1 issues, suggestions, or feature requests please use the following link instead:\r\nWindows PowerShell [UserVoice](https://windowsserver.uservoice.com/forums/301869-powershell)\r\n\r\nThis repository is **ONLY** for PowerShell Core 6 issues.\r\n\r\n- Make sure you are able to repro it on the [latest released version](https://github.com/PowerShell/PowerShell/releases)\r\n- Search the existing issues.\r\n- Refer to the [FAQ](https://github.com/PowerShell/PowerShell/blob/master/docs/FAQ.md).\r\n- Refer to the [known issues](https://docs.microsoft.com/powershell/scripting/whats-new/known-issues-ps6?view=powershell-6).\r\n\r\n-->\r\n\r\nIt would be nice if get-content automatically recognized unicode no bom.  Notepad does.\r\n\r\n# Steps to reproduce\r\n\r\n```powershell\r\n$file = 'hi.txt'\r\n'hi there' | set-content -Encoding unicode $file\r\n$bytes = [io.file]::ReadAllBytes($file)\r\n[IO.File]::WriteAllBytes($file, $bytes[2..$bytes.length])\r\nget-content $file\r\n```\r\n\r\n# Expected behavior\r\n\r\n```none\r\nhi there \r\n```\r\n\r\n# Actual behavior\r\n\r\n```none\r\n# displays nulls as spaces\r\n\r\nh i   t h e r e \r\n```\r\n\r\n# Environment data\r\n\r\n<!-- provide the output of $PSVersionTable -->\r\n\r\n```none\r\nName                           Value\r\n----                           -----\r\nPSVersion                      5.1.16299.1004\r\nPSEdition                      Desktop\r\nPSCompatibleVersions           {1.0, 2.0, 3.0, 4.0, 5.0, 5.1.16299.1004}\r\nBuildVersion                   10.0.16299.1004\r\nCLRVersion                     4.0.30319.42000\r\nWSManStackVersion              3.0\r\nPSRemotingProtocolVersion      2.3\r\nSerializationVersion           1.1.0.1\r\n```\r\n",
  "closed_at": "2019-09-29T12:15:29Z",
  "comments": [
    {
      "author": "vexx32",
      "author_association": "COLLABORATOR",
      "body": "I don't know that there's actually a reliable way to have that work. Notepad might just be using its default encoding to read the file. Both utf16-le and utf16-be encodings (both of which are referred to as \"Unicode\") require a byte order mark as far as I know.\r\n\r\nIf you want to specify an encoding when you retrieve the data with Get-Content, I believe it has an -Encoding parameter you can use to force in to use the encoding you'd like.\r\n\r\nAutodetection can only do so much if the file literally goes against established standards for the format.",
      "created_at": "2019-04-01T21:19:29Z",
      "updated_at": "2019-04-01T21:19:59Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I guess we use .Net Core StreamReader heuristics.",
      "created_at": "2019-04-02T05:37:37Z",
      "updated_at": "2019-04-02T05:37:37Z"
    },
    {
      "author": "jszabo98",
      "author_association": "NONE",
      "body": "PS 6 uses utf8 no bom by default.  *shrug*.  I just helped someone on a forum with a utf16 no bom file.  https://powershell.org/forums/topic/multi-line-pattern-looking-for-contained-content-in-file/#post-147620",
      "created_at": "2019-04-02T15:15:51Z",
      "updated_at": "2019-04-02T15:16:13Z"
    },
    {
      "author": "vexx32",
      "author_association": "COLLABORATOR",
      "body": "Certainly, UTF8 without a BOM is a pretty common standard. However, as far as I'm aware, all UTF16 files are supposed to have a BOM as otherwise they are frequently indistinguishable in terms of _valid_ characters or not from a UTF8noBOM file. Reading a UTF16 w/o BOM file _by default_ is problematic as it is _also_ a perfectly valid UTF8 w/o BOM file, and without reading the entire file first, there's no way to be sure one way or the other.\r\n\r\nI don't see any issues with requiring you to specify an encoding in ambiguous situations. \ud83e\udd37\u200d\u2642\ufe0f ",
      "created_at": "2019-04-02T16:07:23Z",
      "updated_at": "2019-04-02T16:07:23Z"
    },
    {
      "author": "HumanEquivalentUnit",
      "author_association": "CONTRIBUTOR",
      "body": "Related: Notepad guesses using [IsTextUnicode()](https://docs.microsoft.com/en-us/windows/desktop/api/winbase/nf-winbase-istextunicode), and it supports Little Endian UTF16 without BOM, it does not support Big Endian UTF16 without BOM.\r\n\r\nSource: Raymond Chen's The Old New Thing blog, which Microsoft have moved recently and broken all the old links to, but [here's a Google cache view](https://webcache.googleusercontent.com/search?q=cache:7KkwzhYbQZoJ:https://devblogs.microsoft.com/oldnewthing/20040324-00/%3Fp%3D40093+)\r\n\r\n> However, as far as I'm aware, all UTF16 files are supposed to have a BOM as otherwise they are frequently indistinguishable in terms of valid characters or not from a UTF8noBOM file.\r\n\r\nI thought so too, but I've gone to try and prove it, and found that it isn't.  The current Unicode 12 standard is [here in this huge PDF](https://www.unicode.org/versions/Unicode12.0.0/UnicodeStandard-12.0.pdf) and on page 41 / section 2.6 there's a table of Encoding Schemes. If the data stream is marked as `UTF-16BE` or `UTF-16LE` such as in a HTTP transfer or database record, no BOM is allowed. If it's  UTF16 generally but the byte order is not marked anywhere else, then a BOM is \"allowed\". I can't see anywhere it says it's mandatory.\r\n\r\n",
      "created_at": "2019-04-03T08:32:18Z",
      "updated_at": "2019-04-03T08:32:18Z"
    },
    {
      "author": "jszabo98",
      "author_association": "NONE",
      "body": "PS 6 is utf8 no bom by default.  https://docs.microsoft.com/en-us/powershell/scripting/whats-new/what-s-new-in-powershell-core-60?view=powershell-6 On here is an algorithm to recognize utf8 no bom at least.  https://unicodebook.readthedocs.io/guess_encoding.html  Notepad++ and Ultraedit can handle unicode no bom (utf16 le not utf16 be, just like Notepad).  Ultraedit can even save as unicode no bom.\r\n",
      "created_at": "2019-04-03T14:44:05Z",
      "updated_at": "2019-04-03T15:10:01Z"
    },
    {
      "author": "vexx32",
      "author_association": "COLLABORATOR",
      "body": "Right, but in order to _guess_ the encoding, you have to read the file data multiple times. PowerShell is an administrative tool at the end of the day, and I'm not really sure it makes any sense to make a guess or assumption for the user in terms of what the file format is. The `Get-Content` cmdlet allows you to specify encodings for the ambiguous cases for this reason.",
      "created_at": "2019-04-03T14:56:08Z",
      "updated_at": "2019-04-03T14:58:12Z"
    },
    {
      "author": "jszabo98",
      "author_association": "NONE",
      "body": "For what it's worth.  Opening a chinese unicode no bom document (http://www-personal.umich.edu/~dporter/sampler/advocate.gb) in:\r\n\r\n```\r\nnotepad    ok\r\nuedit64    ok\r\nnotepad++  fail\r\nise        fail\r\ncode       fail\r\n```\r\n\r\nChinese utf8nobom fails in the ise btw.\r\n\r\nUnicode no bom example:  saving perms to a file with icacls. ",
      "created_at": "2019-04-03T18:25:51Z",
      "updated_at": "2019-04-04T21:10:13Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> In fact, Japan, South Korea, India. These large character sets are all similar.\r\n\r\nIt is true for all non-english. You could feeadback in .Net and Windows - most of (performance) optimizations is done for Latin and english.",
      "created_at": "2019-04-04T05:22:39Z",
      "updated_at": "2019-04-04T05:22:39Z"
    },
    {
      "author": "jszabo98",
      "author_association": "NONE",
      "body": "Here's IsTextUnicode() in Powershell, just for kicks.  I wonder how notepad recognizes utf8nobom?\r\n\r\n```powershell\r\n$MethodDefinition = @'\r\n[DllImport(\"Advapi32\",SetLastError=false)]\r\npublic static extern bool IsTextUnicode(byte[] buf, int len, ref IsTextUnicodeFlags opt);\r\n\r\n[Flags]\r\npublic enum IsTextUnicodeFlags:int \r\n{\r\n  IS_TEXT_UNICODE_ASCII16            = 0x0001,\r\n  IS_TEXT_UNICODE_REVERSE_ASCII16    = 0x0010,\r\n\r\n  IS_TEXT_UNICODE_STATISTICS         = 0x0002,\r\n  IS_TEXT_UNICODE_REVERSE_STATISTICS = 0x0020,\r\n\r\n  IS_TEXT_UNICODE_CONTROLS           = 0x0004,\r\n  IS_TEXT_UNICODE_REVERSE_CONTROLS   = 0x0040,\r\n\r\n  IS_TEXT_UNICODE_SIGNATURE          = 0x0008,\r\n  IS_TEXT_UNICODE_REVERSE_SIGNATURE  = 0x0080,\r\n\r\n  IS_TEXT_UNICODE_ILLEGAL_CHARS      = 0x0100,\r\n  IS_TEXT_UNICODE_ODD_LENGTH         = 0x0200,\r\n  IS_TEXT_UNICODE_DBCS_LEADBYTE      = 0x0400,\r\n  IS_TEXT_UNICODE_NULL_BYTES         = 0x1000,\r\n\r\n  IS_TEXT_UNICODE_UNICODE_MASK       = 0x000F,\r\n  IS_TEXT_UNICODE_REVERSE_MASK       = 0x00F0,\r\n  IS_TEXT_UNICODE_NOT_UNICODE_MASK   = 0x0F00,\r\n  IS_TEXT_UNICODE_NOT_ASCII_MASK     = 0xF000\r\n}\r\n'@\r\n\r\nAdd-Type $MethodDefinition Advapi32 -Namespace Win32\r\n\r\n[Win32.Advapi32+IsTextUnicodeFlags]$opt = 0xffff\r\n\r\n$file = $args[0]\r\n$bytes = [io.file]::ReadAllBytes($file)\r\n$result = [win32.advapi32]::IsTextUnicode($bytes, $bytes.length, [ref]$opt)\r\n\r\n[pscustomobject]@{\r\n  Result = $result\r\n  Flags = $opt\r\n}\r\n\r\n\r\nPS C:\\users\\me> istextunicode hi.txt\r\n\r\nResult                                                                            Flags\r\n------                                                                            -----\r\n  True IS_TEXT_UNICODE_STATISTICS, IS_TEXT_UNICODE_CONTROLS, IS_TEXT_UNICODE_NULL_BYTES\r\n\r\n```",
      "created_at": "2019-04-11T17:45:35Z",
      "updated_at": "2019-04-11T17:50:25Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "If anybody want a progress with the issue please open new issue in CoreFX repo - it is right place for the enhancement. Currently Core team started to plan .Net Core 5.0.",
      "created_at": "2019-09-29T12:15:29Z",
      "updated_at": "2019-09-29T12:15:29Z"
    }
  ],
  "created_at": "2019-04-01T19:48:53Z",
  "number": 9268,
  "state": "closed",
  "title": "get-content -- not recognizing unicode no bom",
  "updated_at": "2019-09-29T12:16:05Z"
}