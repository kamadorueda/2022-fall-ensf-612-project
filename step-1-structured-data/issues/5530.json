{
  "_url": "https://github.com/PowerShell/PowerShell/issues/5530",
  "author": "Jaykul",
  "body": "Steps to reproduce\r\n------------------\r\n\r\n```powershell\r\nInvoke-RestMethod 'http://api.forismatic.com/api/1.0/?method=getQuote&format=json&lang=ru' -verbose\r\n```\r\n\r\nExpected behavior\r\n-----------------\r\n\r\nIt should **detect** the utf-8 encoding, and produce the same output as this:\r\n\r\n```posh\r\n$resp = Invoke-WebRequest 'http://api.forismatic.com/api/1.0/?method=getQuote&format=json&lang=ru'\r\n$char = $resp.RawContentStream.ToArray()\r\n$str = [Text.Encoding]::UTF8.GetString($char)\r\nConvertFrom-Json $str\r\n```\r\n\r\ni.e. something like this:\r\n\r\n```none\r\nVERBOSE: GET http://api.forismatic.com/api/1.0/?method=getQuote&format=json with 0-byte payload\r\nVERBOSE: received 536-byte response of content type application/json\r\nVERBOSE: Content encoding: utf-8\r\n\r\nquoteText   : \u0418\u043c\u0435\u043d\u043d\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0438\u0439 \u0434\u0438\u0430\u043b\u043e\u0433 \u043f\u0440\u0438\u0436\u0438\u043c\u0430\u0435\u0442 \u043a \u0437\u0435\u043c\u043b\u0435 \u043b\u044e\u0434\u0435\u0439 \u0432 \u043f\u043e\u0432\u0441\u0435\u0434\u043d\u0435\u0432\u043d\u043e\u0439 \u0436\u0438\u0437\u043d\u0438. \u041c\u0438\u0440 \u0434\u043b\u044f \u043d\u0430\u0441 \u0442\u0430\u043a\u043e\u0439-\u0442\u043e \u0438 \u0442\u0430\u043a\u043e\u0439-\u0442\u043e \u0438\u043b\u0438 \u044d\u0442\u0430\u043a\u0438\u0439 \u0438 \u044d\u0442\u0430\u043a\u0438\u0439 \u043b\u0438\u0448\u044c \u043f\u043e\u0442\u043e\u043c\u0443, \u0447\u0442\u043e \u043c\u044b \u0441\u0430\u043c\u0438 \u0441\u0435\u0431\u0435 \u0433\u043e\u0432\u043e\u0440\u0438\u043c \u043e \u043d\u0435\u043c, \u0447\u0442\u043e \u043e\u043d \u0442\u0430\u043a\u043e\u0439-\u0442\u043e \u0438 \u0442\u0430\u043a\u043e\u0439-\u0442\u043e \u0438\u043b\u0438 \u044d\u0442\u0430\u043a\u0438\u0439 \u0438 \u044d\u0442\u0430\u043a\u0438\u0439.\r\nquoteAuthor : \u041a\u0430\u0440\u043b\u043e\u0441 \u041a\u0430\u0441\u0442\u0430\u043d\u0435\u0434\u0430\r\nsenderName  :\r\nsenderLink  :\r\nquoteLink   : http://forismatic.com/ru/6309006412/\r\n```\r\n\r\nActual behavior\r\n---------------\r\n\r\nIt falls back to iso-8859-1 encoding and produces gobbledygook with a lot of \u00d0's in it.  Also, it utterly fails to produce a number for the `#-byte response` string in the verbose output.\r\n\r\n```none\r\nVERBOSE: GET http://api.forismatic.com/api/1.0/?method=getQuote&format=json with 0-byte payload\r\nVERBOSE: received -byte response of content type application/json\r\nVERBOSE: Content encoding: iso-8859-1\r\n\r\nquoteText   : \u00d0\u009a\u00d0\u00be \u00d0\u00b2\u00d1\u0081\u00d1\u008f\u00d0\u00ba\u00d0\u00be\u00d0\u00bc\u00d1\u0083 \u00d0\u00bf\u00d1\u0080\u00d0\u00b8\u00d0\u00b1\u00d0\u00b5\u00d0\u00b6\u00d0\u00b8\u00d1\u0089\u00d1\u0083 \u00d0\u00be\u00d0\u00b1\u00d1\u0080\u00d0\u00b0\u00d1\u0089\u00d0\u00b0\u00d1\u008e\u00d1\u0082\u00d1\u0081\u00d1\u008f \u00d0\u00bb\u00d1\u008e\u00d0\u00b4\u00d0\u00b8, \u00d0\u00bc\u00d1\u0083\u00d1\u0087\u00d0\u00b8\u00d0\u00bc\u00d1\u008b\u00d0\u00b5 \u00d1\u0081\u00d1\u0082\u00d1\u0080\u00d0\u00b0\u00d1\u0085\u00d0\u00be\u00d0\u00bc: \u00d0\u00ba \u00d0\u00b3\u00d0\u00be\u00d1\u0080\u00d0\u00b0\u00d0\u00bc\r\n              \u00d0\u00b8 \u00d0\u00ba \u00d0\u00bb\u00d0\u00b5\u00d1\u0081\u00d0\u00b0\u00d0\u00bc, \u00d0\u00ba \u00d0\u00b4\u00d0\u00b5\u00d1\u0080\u00d0\u00b5\u00d0\u00b2\u00d1\u008c\u00d1\u008f\u00d0\u00bc \u00d0\u00b2 \u00d1\u0080\u00d0\u00be\u00d1\u0089\u00d0\u00b5, \u00d0\u00ba \u00d0\u00b3\u00d1\u0080\u00d0\u00be\u00d0\u00b1\u00d0\u00bd\u00d0\u00b8\u00d1\u0086\u00d0\u00b0\u00d0\u00bc.\r\nquoteAuthor : \u00d0\u0091\u00d1\u0083\u00d0\u00b4\u00d0\u00b4\u00d0\u00b0 \u00d0\u0093\u00d0\u00b0\u00d1\u0083\u00d1\u0082\u00d0\u00b0\u00d0\u00bc\u00d0\u00b0\r\nsenderName  :\r\nsenderLink  :\r\nquoteLink   : http://forismatic.com/ru/804c7d14d9/\r\n```\r\n\r\nDiscussion\r\n----------\r\n\r\nWhen calling an HTTP endpoint that returns a header: `Content-Type: application/json` the WebCmdlets are **incorrectly** defaulting to `iso-8859-1` rather than a proper unicode encoding, and are *disregarding* the application/json RFC's simple specification for how to determine the content encoding.\r\n\r\n1. The JSON standard [ECMA-404 (PDF)](http://ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf) clearly states that JSON must be unicode\r\n2. The [application/json RFC (in section 3)](https://tools.ietf.org/html/rfc4627#section-3) clearly indicates how the encoding should be determined from the first 4 bytes of the content.\r\n\r\n**NOTE:** Please don't work around this by just defaulting to utf-8.  I'm sure that 90% of the time, you could probably get away with that, but it's not actually correct, and the RFC implementation is _trivial_.\r\n\r\n**ALSO NOTE:** The WebCmdlets *do* respect the [`; charset=utf-8`](https://github.com/PowerShell/PowerShell/blob/f5f3fab1ea8a51dd2e5d34e0e580ab39176eb696/src/Microsoft.PowerShell.Commands.Utility/commands/utility/WebCmdlet/StreamHelper.cs#L442) attribute if it's present on the content-type header -- which makes sense, but isn't technically standards compliant for an `application/*` content-type, as far as I can tell.\r\n\r\nTo get started: [`ProcessResponse`](https://github.com/PowerShell/PowerShell/blob/f5f3fab1ea8a51dd2e5d34e0e580ab39176eb696/src/Microsoft.PowerShell.Commands.Utility/commands/utility/WebCmdlet/CoreCLR/InvokeRestMethodCommand.CoreClr.cs#L54) and [`TryGetEncoding`](https://github.com/PowerShell/PowerShell/blob/f5f3fab1ea8a51dd2e5d34e0e580ab39176eb696/src/Microsoft.PowerShell.Commands.Utility/commands/utility/WebCmdlet/StreamHelper.cs#L411) \r\n\r\nSee also #5528 which was a specific instance of this problem. @lipkau was incorrectly convinced by early responders that the problem was in the webserver, but it's actually in PowerShell's cmdlets. If you invoke the rest API against the Atlassian wiki, you can see the problem happening in the Verbose stream:\r\n\r\n```posh\r\n$r = IRM $url -Credential $mycred -Authentication basic -Verbose\r\nVERBOSE: GET https://powershell.atlassian.net/wiki/rest/api/content/13009245?expand=space,version with 0-byte payload\r\nVERBOSE: received -byte response of content type application/json\r\nVERBOSE: Content encoding: iso-8859-1\r\n```\r\n\r\nThe content is **actually** correctly utf-8 encoded (as you could tell from the positions of the nulls in the first 4 bytes), and iso-8859-1 is _**never** a valid encoding for application/json_, period.\r\n\r\n```plain\r\nPS C:\\Program Files\\PowerShell\\6.0.0-rc> $PSVersionTable\r\n\r\nName                           Value\r\n----                           -----\r\nPSVersion                      6.0.0-rc\r\nPSEdition                      Core\r\nGitCommitId                    v6.0.0-rc\r\nOS                             Microsoft Windows 10.0.15063\r\nPlatform                       Win32NT\r\nPSCompatibleVersions           {1.0, 2.0, 3.0, 4.0...}\r\nPSRemotingProtocolVersion      2.3\r\nSerializationVersion           1.1.0.1\r\nWSManStackVersion              3.0\r\n```",
  "closed_at": "2018-02-22T05:31:00Z",
  "comments": [
    {
      "author": "markekraus",
      "author_association": "CONTRIBUTOR",
      "body": "That seems reasonable.. Tell me if this logic makes sense:\r\n\r\nIf the `Content-type` is `application/json` and does not provide a `charset`, inspect the first 4 bytes of the content stream to determine the correct unicode encoding and If it cannot be determined, fall back to utf-8.\r\n\r\n`1` is valid JSON and is only 1 byte in utf-8 and 2 in utf-16, but it's painful logic to try and figure out if 2 bytes is a 2 digit utf-8 or a single digit utlf-16. \r\n\r\nedit: thinking about it, it wouldn't be 2 hard. if the response is 3 bytes, it's utf8. if it's 2 and the first byte is 00, then it is UTF-16BE. if it is 2 and the second byte is 00 its UTF-16LE, and if nether 1 nor 2 are 00, it's utf-8.",
      "created_at": "2017-11-22T23:38:36Z",
      "updated_at": "2017-11-22T23:49:40Z"
    },
    {
      "author": "markekraus",
      "author_association": "CONTRIBUTOR",
      "body": "Hmm I'm wondering what standard we should follow here. RFC 8259 released in December 2017 now enforces UTF-8 (no-BOM) encoding for JSON. https://tools.ietf.org/html/rfc8259#section-8.1\r\n\r\n> JSON text exchanged between systems that are not part of a closed ecosystem MUST be encoded using UTF-8 [RFC3629].\r\n> \r\n> Previous specifications of JSON have not required the use of UTF-8 when transmitting JSON text. However, the vast majority of JSON-based software implementations have chosen to use the UTF-8 encoding, to the extent that it is the only encoding that achieves interoperability.\r\n\r\n@SteveL-MSFT  Do we have any kind of guidance on what standards should be followed and how soon after acceptance they should be implemented? Currently RFC 8259 is set as \"Internet Standard\" and has obsoleted the standard @Jaykul cited (RFC 4627) but conflicts with EMCA-404 which still allows for any Unicode and not exclusively UTF-8. I agree with the IETF that UTF-8 reigns supreme (I don't personally know a single JSON API that returns anything other than UTF-8).\r\n\r\nIt would seem to me the default encoding for application/json responses should be UTF-8. I'm torn on whether we should ignore or honor the char encoding provided by a remote endpoint. I think part of this could be solved is we enforced UTF-8 but allowed users to supply their own response encoding via parameter. this would solve some of the other open issues where char detection is not working because the remote endpoints are not being compliant. ",
      "created_at": "2018-02-02T20:31:34Z",
      "updated_at": "2018-02-02T20:31:34Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "@markekraus the great thing about standards is that there's so many to choose from :)\r\n\r\nI think we should default to UTF-8.  If the response includes an encoding, we should use that.  For edge cases, end users can use `Invoke-WebRequest` and handle the encoding themselves.  I expect this to be rare until proven otherwise.\r\n\r\nAt this time, I wouldn't bother with providing a parameter until a need arises.",
      "created_at": "2018-02-02T21:00:24Z",
      "updated_at": "2018-02-02T21:00:24Z"
    },
    {
      "author": "markekraus",
      "author_association": "CONTRIBUTOR",
      "body": "@SteveL-MSFT  Re: user supplied encoding. this has come up several times. #3267 from @chuanjiao10 has a few examples. I could dig but there have been other issues where this is a comment. Andi suspect we might not see a great number of complaints as it seems a common problem in Asia (language barrier and all that). web browsers do a fair bit of magic to select the encoding. The least we could do is provide the user the option to select encoding. It's probably not a priority, but there does appear to be a need.",
      "created_at": "2018-02-02T22:09:22Z",
      "updated_at": "2018-02-02T22:09:22Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "@markekraus if it's come up several times already, then we should probably support it.",
      "created_at": "2018-02-02T22:24:42Z",
      "updated_at": "2018-02-02T22:24:42Z"
    },
    {
      "author": "markekraus",
      "author_association": "CONTRIBUTOR",
      "body": "@chuanjiao10 Hopefully, whatever we land on for HTML parsing (AngleSharp) will support multiple character encoding in a single response. For now, we are concerned only with the outer content type encoding of the response as a whole as our current implementation only does basic HTML parsing. Could you please open a new issue for multiple response encoding in a single HTML and maybe include some examples? Thanks!",
      "created_at": "2018-02-04T11:10:47Z",
      "updated_at": "2018-02-04T11:10:47Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I agree that we should default to UTF-8 - CoreFX uses this and PowerShell Core too in many places.\r\n\r\nI believe we should get PowerShell committee conclusion to close the discussion.",
      "created_at": "2018-02-04T13:00:45Z",
      "updated_at": "2018-02-04T13:02:31Z"
    },
    {
      "author": "markekraus",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov for this particular issue, we are only changing the default to UTF-8 for `aplication/json` responses because the RFC's are clear on this one. \r\n\r\nThe standards are a bit less clear on HTML responses. Historically, when no charset is defined in the header ISO-8859-1 was assumed. So if we changed the default for everything to UTF-8, legacy systems will be potentially broken.  This is complicated because now the default charset for HTML5 is UTF-8. HTML5 becomes heavily reliant on charset in the `Content-Type` HTTP response header and then the HTML rendering engine uses that to interpret the first `<meta http-equiv=\"content-type\"` or `<meta charset` to switch encoding for the inner elements. Unless HTTP response header includes an alternate charset, one should assume the the charset is 8859-1 to ensure backwards compat.\r\n\r\nUltimately, we will never have perfect encoding in this project because we do not aspire to be a full parity web browser. For HTML, My hope is that when we move to AngleSharp for HTML rendering they can handle the terrifying task of navigating all the charset complexities for us.",
      "created_at": "2018-02-04T13:40:16Z",
      "updated_at": "2018-02-04T13:40:16Z"
    },
    {
      "author": "markekraus",
      "author_association": "CONTRIBUTOR",
      "body": "@chuanjiao10 I understand the CJK user experience is currently bad. I have a personal interest in addressing that (for the limited amount of \u65e5\u672c\u8a9e I deal with). The problem is that `Invoke-WebRequest`, under the current plans, no longer seeks to be a full parity web browser. In PS Core, it doesn't even support HTML parsing at this point. `Invoke-RestMethod` should work for APIs in any part of the work because JSON and XML follow stricter standards (and this issue in particular is about bringing the cmdlet into even close alignment with standards). \r\n\r\nI really do feel much of the CJK pain will be reduced when we can add in a proper HTML parser. This project doesn't have the resources to make its own full functioning browser, so we will be relying on another community project that does. I also feel that adding the ability for the user to supply their desired character encoding will address some of this pain. \r\n\r\n`Invoke-WebRequest` will very likely never directly support multiple encoding scenarios allowed under HTML5. But, `ConvertFrom-Html` would in theory would. That leaves us with navigating only the baseline encoding for the \"outer envelope\". \r\n\r\nFor that, we must follow standards, as painful as they are for a significant user population. Current standards make it clear the default for HTML must be `iso-8859-1` and that it is the responsibility of the remote endpoint to suggest an alternate encoding when something other than `iso-8859-1` is used. This is on the web developers and web server admins more than us. Though, we can and do seek to make this less painful. We currently support a wide range of encoding detection. It's not perfect but it can also be improved give specific examples where it breaks down. For when that breaks down, allowing you to supply your own encoding should work.",
      "created_at": "2018-02-05T14:10:25Z",
      "updated_at": "2018-02-05T14:10:25Z"
    },
    {
      "author": "markekraus",
      "author_association": "CONTRIBUTOR",
      "body": "@chuanjiao10 That solution uses Internet Explorer's engine to parse the HTML and determine internal element content type. Internet Explorer is full fledged web browser. It has teams dedicated to complexe charset identification and string encoding. `Invoke-WebRequest` is not a full web browser and does not have those kinds of resources. Internet Explorer inter-op is not available in PowerShell core so this solution cannot be used in PowerShell Core.\r\n\r\n`Invoke-WebRequest` and `Invoke-RestMethod` in PowerShell core now support charset detection in the HTML for the outer most tag. This is an improvement over PowerShell core 5.1. They do not and likely will not ever support it in the inner elements. That is a task for a separate cmdlet.\r\n\r\nUTF-8 is supported. If the server declares `charset=utf-8` in the `Content-Type` header and if it is declared in the outermost HTML element. This is not limited to UTF-8. Support for any encoding that .NET Core supports is possible. \r\n\r\n> Why WebCmdlets very bad for a long time?\r\n\r\nI can't answer that. I don't work for Microsoft.. I'm a community member like yourself. \ud83d\ude04  I do share some of your frustration, though. That's why I have been contributing.\r\n\r\n> `\"<a charset=xxx> C </a> <a charset=yyy> J </a>\"` in html4 is not standard?\r\n\r\nIt is, but that is only something that can be implemented in a web browser where you can click links and the browser has context surrounding the URI it retrieves. You are not clicking links in `Invoke-WebRequest`, you are providing URI's. The burden is 100% on the web developer and web server administrators to ensure the response for a given endpoint returns the proper charset definitions in the \"outer envelope\".  Otherwise, PowerShell has no context to understand what the charset should be based on an anchor element.\r\n\r\nIn PowerShell, this would be accomplished by accomplished by parsing the uri and charset from the HTML anchor element (`<a>`), calling `Invoke-WebRequest` with that information. if we exposed a way for you to declare what encoding type you are expecting it would be possible with something like `Invoke-WebRequest -Uri $uri -ResponseCharset 'UTF-8'` or something.\r\n\r\n> if WebCmdlets do not do well, calling an external mature library\r\n\r\nLike I said, we will be using an external library for HTML parsing (AngleSharp). But this wont be baked into `Invoke-WebRequest`. The focus of the web cmdlets has shifted beginning with 6.0.0. HTML parsing will never return to them. Instead, a separate cmdlet will be introduced so it can be used for more than just `Invoke-WebRequest` and `Invoke-RestMethod`. `Invoke-WebRequest` alone wont do what you want even in the future. But, there will be a way with something like `$Html = Invoke-WebRequest $uri | ConvertFrom-Html`\r\n\r\nI should also note that as far as I know none of these changes will be ported back to Windows PowerShell 5.1 or older. To get these benefits, you will need to move to PowerShell Core.",
      "created_at": "2018-02-06T12:21:55Z",
      "updated_at": "2018-02-06T12:21:55Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "Further HTML parsing discussion should be part of https://github.com/PowerShell/PowerShell/issues/2867.\r\n\r\nFor this specific issue, we should default to UTF-8 unless an encoding is provided in the response or if the user specified an encoding they want to use.",
      "created_at": "2018-02-06T18:07:55Z",
      "updated_at": "2018-02-06T18:07:55Z"
    },
    {
      "author": "Jaykul",
      "author_association": "CONTRIBUTOR",
      "body": "> the default encoding for application/json responses should be UTF-8.\r\n\r\nThis is _most **certainly**_ correct. Even in the (older) standard I cited, UTF-8 (with no BOM) is specified as the default, and they suggest reading the first 4 bytes _only_ as a way of determining if it's a different Unicode encoding (since UTF-16 and UTF-32 require BOM).\r\n\r\nSince you point out the version I cited is twice obsolete, and the newer standard says UTF-8 only, I would be happy with UTF-8 only (i.e. skipping the algorithm to check for BOM). \r\n\r\nI'd be willing to bet that nearly ever times you've had complaints about encoding problems are instances _like this one_, where the content was UTF-8 encoded without specifying anything (since that's _supposed to be_ the default), and the cmdlet is improperly treating it as the Windows default encoding.\r\n\r\nI also agree that for _anything else_ that's not JSON, all bets are off \ud83d\ude09 but I'll go look at #2867 too  \ud83d\ude01 ",
      "created_at": "2018-02-07T04:16:12Z",
      "updated_at": "2018-02-07T04:20:53Z"
    }
  ],
  "created_at": "2017-11-22T22:33:19Z",
  "labels": [
    "Issue-Enhancement",
    "Resolution-Fixed",
    "WG-Cmdlets-Utility"
  ],
  "number": 5530,
  "state": "closed",
  "title": "WebCmdlets should read the encoding of Content-Type application/json per RFC",
  "updated_at": "2018-03-24T17:58:54Z"
}