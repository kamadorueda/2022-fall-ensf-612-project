{
  "_url": "https://github.com/PowerShell/PowerShell/issues/7603",
  "author": "bergmeister",
  "body": "Steps to reproduce\r\n------------------\r\nImporting a 150 MB CSV file with 50k rows, 700 columns and 5 +/- 3 characters per entry results in a memory consumption of 7GB of the PowerShell process. This is a ratio of around 50 when compared to the file size. I have seen this ratio also with a similar file of smaller size (1.5MB) and therefore think this is a more generic issue not specific to the CSV file structure itself.\r\n```powershell\r\n$csv = Import-Csv $pathToCsvFiile\r\n```\r\n\r\nNote that this does not happen if I do not assign to a variable or pipe to `Out-Null`\r\n\r\nExpected behavior\r\n-----------------\r\n\r\nFilesize to memory ratio is reasonable (around 10)\r\n\r\nActual behavior\r\n---------------\r\n\r\nFilesize to memory ratio is around 50\r\n\r\nEnvironment data\r\n----------------\r\n\r\nLatest daily build and RC1\r\n\r\n```powershell\r\n> $PSVersionTable\r\nName                           Value\r\n----                           -----\r\nPSVersion                      6.1.0-preview.761\r\nPSEdition                      Core\r\nGitCommitId                    6.1.0-preview.761\r\nOS                             Microsoft Windows 6.3.9600\r\nPlatform                       Win32NT\r\nPSCompatibleVersions           {1.0, 2.0, 3.0, 4.0...}\r\nPSRemotingProtocolVersion      2.3\r\nSerializationVersion           1.1.0.1\r\nWSManStackVersion              3.0\r\n\r\n\r\nName                           Value\r\n----                           -----\r\nPSVersion                      6.1.0-rc.1\r\nPSEdition                      Core\r\nGitCommitId                    6.1.0-rc.1\r\nOS                             Microsoft Windows 6.3.9600\r\nPlatform                       Win32NT\r\nPSCompatibleVersions           {1.0, 2.0, 3.0, 4.0...}\r\nPSRemotingProtocolVersion      2.3\r\nSerializationVersion           1.1.0.1\r\nWSManStackVersion              3.0\r\n\r\n\r\n```\r\n",
  "closed_at": null,
  "comments": [
    {
      "author": "thezim",
      "author_association": "CONTRIBUTOR",
      "body": "Dup #7112",
      "created_at": "2018-08-23T00:30:13Z",
      "updated_at": "2018-08-23T00:30:13Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@thezim I do not see this as a duplicate because the behaviour in Windows PowerShell was the same.",
      "created_at": "2018-08-23T06:44:30Z",
      "updated_at": "2018-08-23T06:44:30Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister Could you please test with latest build or RC1? We already added two performance fixes. I guess you will be pleasantly surprised.",
      "created_at": "2018-08-23T10:35:03Z",
      "updated_at": "2018-08-23T10:35:03Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov I tried with the latest daily build and using the RC1 today and there was no noticeable difference.",
      "created_at": "2018-08-23T11:11:34Z",
      "updated_at": "2018-08-23T11:11:34Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister Thanks! \r\n\r\n>the behaviour in Windows PowerShell was the same.\r\n\r\nPlease add results of the comparision in the PR description: memory and speed.",
      "created_at": "2018-08-23T11:54:37Z",
      "updated_at": "2018-08-23T11:54:37Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister I tried with a randomly generated file (600 columns, 50000 lines and 10 MB size) and can not confirm - RC1 works very good (process size is 40 MB at start then reduced to 22 MB in TaskManager).",
      "created_at": "2018-08-24T05:59:28Z",
      "updated_at": "2018-08-24T05:59:28Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov How did you run it? If I run it using `Import-Csv $file | Out-Null` there is hardly any memory usage but if I assign it to a variable using `$csv = Import-Csv $file` I get the big memory allocation that I can only get rid of at the end by calling `[System.GC]::Collect()`",
      "created_at": "2018-08-24T08:44:34Z",
      "updated_at": "2018-08-24T08:44:34Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Test script\r\n```powershell\r\ncd c:\\tmp\\\r\n\r\nfunction perf_test($source, $result) {\r\n    Write-Host \"Measuring Import-Csv performance over time...\"\r\n\r\n    \"index,duration_ms,bytes_consumed\" | Out-File $result\r\n    for ($i=0; $i -le 400; $i++) {\r\n\r\n            $millis = (Measure-Command { Import-Csv $source }).TotalMilliseconds\r\n            # Uncomment this if you want analize results in Excel\r\n            $memory = [System.GC]::GetTotalMemory($false)\r\n\t    $i.ToString() + \",\" + $millis.ToString() + \",\" + $memory | Out-File $result -Append\r\n    }\r\n    Write-Host \"Done\"\r\n}\r\n\r\n###############\r\n# For measuring adding new properties to PSObject-s\r\n$fields = 0..699 | ForEach-Object { \"random_numbers$_\" }\r\n($fields -join \",\") | Out-File .\\source2.csv\r\nGet-Random -SetSeed 1 | Out-Null\r\nfor ($i=0; $i -le 50000; $i++) {\r\n    $values = 0..19 | ForEach-Object { (Get-Random).ToString() }\r\n    ($values -join \",\") | Out-File .\\source2.csv -Append\r\n}\r\n\r\nperf_test .\\source2.csv .\\results2.csv\r\n```\r\n\r\nYour issue is not directly related with Import-Csv. Seems we have extra allocations in \"=\" operator.",
      "created_at": "2018-08-24T09:06:37Z",
      "updated_at": "2018-08-24T09:06:37Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "The memory pressure most likely comes from the cost of PSNoteProperty. Each PSNoteProperty has an overhead of 48 bytes, so when you just store a few bytes per property, that becomes massive.",
      "created_at": "2019-02-10T09:37:12Z",
      "updated_at": "2019-02-10T09:37:12Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "A workaround you can try is to generate a type for the items, and store the data there.\r\n```powershell\r\nImport-Csv .\\source2.csv |\r\n     Select -first 1 |\r\n     foreach {$_.psobject.properties.name} |\r\n     join-string -Separator \"`r`n\" -OutputPrefix \"class MyCsv {`r`n\" -OutputSuffix \"`n}\" -property {\"`t`$$_\"}|\r\n     invoke-expression\r\n$a = Import-Csv .\\source2.csv | Foreach{[MyCsv] $_}\r\n```\r\nThat should be more efficient. You can improve the typing, ints are cheaper than strings for example, but you get the gist.",
      "created_at": "2019-02-10T10:43:04Z",
      "updated_at": "2019-02-10T10:43:04Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Additional thoughts. The cmdlet works well in Framework where GC free memory more aggressively.  .Net Core GC has different behavior. Perhaps we could adjust Core GC settings.",
      "created_at": "2019-02-10T10:44:57Z",
      "updated_at": "2019-02-10T10:44:57Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister  I created a gist here https://gist.github.com/powercode/19eeb7c65e7542f4f221d54bb487307a where I made that into a function.",
      "created_at": "2019-02-10T11:04:03Z",
      "updated_at": "2019-02-10T11:04:03Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "@iSazonov The `IDataView` looks really promising! But this isn't so much a GC issue. It's about how we store our properties. If you pipe to out-null, we do a lot of work of creating the properties, but they probably stay in Gen0, which is fast to collect. The memory pressure is only noticeable when the data is saved to a variable.\r\n\r\nWe really hit the degenerated case when we have very many properties, and very little data in each.",
      "created_at": "2019-02-10T11:15:44Z",
      "updated_at": "2019-02-10T11:15:44Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "It would be interesting to play with IDataView and use it in PSObject as another way of storing properties (instead of noteproperties, that is).",
      "created_at": "2019-02-10T11:18:24Z",
      "updated_at": "2019-02-10T11:18:24Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I was thinking about a global property cache. I don't know what benefits and problems this will bring. And we could consider IDataView for this cache. Although perhaps there could be a rather simpler structure. Combining this with Simple Case Folding #8120 we would get a huge resource saving.",
      "created_at": "2019-02-10T11:29:21Z",
      "updated_at": "2019-02-10T11:31:01Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister I have a working implementation to import csv into a typed object.\r\nIf a class has properties, or constructor parameters, that matches the names of the columns in the file, either the default ctor is invoked, and properties are set (with conversion if necessary), or the ctor with matching count and names are invoked, also with conversion if necessary on the parameters.\r\n\r\nIt works by generating expression trees, that are then compiled to a `Func<IList<string>, object>`, that is invoked for each line of CSV.\r\n\r\nMaybe time for a PR?",
      "created_at": "2019-02-10T19:37:01Z",
      "updated_at": "2019-02-10T19:37:01Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "I have a prototype here: https://github.com/PowerShell/PowerShell/pull/8860\r\n",
      "created_at": "2019-02-10T22:42:20Z",
      "updated_at": "2019-02-10T22:42:20Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "Just to also link to the proposal relating to PR #8860: #8862\r\n",
      "created_at": "2019-11-09T16:50:16Z",
      "updated_at": "2020-02-23T17:43:57Z"
    }
  ],
  "created_at": "2018-08-22T13:25:49Z",
  "labels": [],
  "number": 7603,
  "state": "open",
  "title": "Import-CSV has very high filesize-to-memory consumption ratio of around 50",
  "updated_at": "2020-02-23T17:43:57Z"
}