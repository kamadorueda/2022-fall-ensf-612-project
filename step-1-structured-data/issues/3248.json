{
  "_url": "https://github.com/PowerShell/PowerShell/issues/3248",
  "author": "mklement0",
  "body": "This issue has two distinct aspects:\r\n* discussion of an existing _documentation bug_\r\n* discussion of the problematic fixed default file encoding currently (alpha16) chosen for _Core_. \r\n\r\nSteps to reproduce\r\n------------------\r\n\r\n```powershell\r\n'\u00f6' | Set-Content -NoNewline -Encoding ASCII tmp.txt \r\n'\u00f6' | Add-Content -Encoding ASCII -NoNewline tmp.txt \r\nGet-Content -Encoding ASCII tmp.txt\r\n(Get-Content -Encoding Byte -TotalCount 2 tmp.txt) | % { '0x{0:x}' -f $_ }\r\n'--'\r\n'\u00f6' | Set-Content -NoNewline tmp.txt   # use default encoding\r\n'\u00f6' | Add-Content -NoNewline tmp.txt   # use default encoding\r\nGet-Content tmp.txt                    # use default encoding\r\n(Get-Content -Encoding Byte -TotalCount 2 tmp.txt) | % { '0x{0:x}' -f $_ }\r\n```\r\n\r\n\r\nExpected behavior\r\n-----------------\r\n\r\n```\r\n??\r\n0x3f\r\n0x3f\r\n--\r\n??\r\n0x3f\r\n0x3f\r\n```\r\n\r\nActual behavior\r\n---------------\r\n\r\n```\r\n??\r\n0x3f\r\n0x3f\r\n--\r\n\u00f6\u00f6\r\n0xf6\r\n0xf6\r\n```\r\n\r\nThat is, ASCII encoding turns a non-ASCII character into _literal_ `?` (`0x3f`)\r\n\r\nThe fact that `Set-Content` without an `-Encoding` argument resulted in `\u00f6` on reading implies that ASCII encoding wasn't used, and the specific byte value of `0xf6` further implies that that a single-byte, extended-ASCII encoding was used:\r\n\r\n* For _Windows_ PowerShell, it is the _respective_ system's legacy codepage (\"ANSI\"), such as [Windows-1252](https://en.wikipedia.org/wiki/Windows-1252) on US-English systems, or [Windows-1251](https://en.wikipedia.org/wiki/Windows-1251) on Russian systems. In other words: the specific encoding is, to put it in Unix terms, _locale-dependent_.\r\n\r\n* For PowerShell _Core_, _as of alpha 16_, it is [ISO-8859-1](https://en.wikipedia.org/wiki/ISO/IEC_8859-1), as @iSazonov helpfully points out (see [his comment below](https://github.com/PowerShell/PowerShell/issues/3248#issuecomment-284038694) for the source-code links).\r\n   * **Using a _fixed_ encoding that is limited to 256 code points is problematic, however.**\r\n   * See @iSazonov's [comment below](https://github.com/PowerShell/PowerShell/issues/3248#issuecomment-284241580) and the [discussion](https://github.com/PowerShell/PowerShell-RFC/issues/71) of the [RFC about default file encodings](https://github.com/PowerShell/PowerShell-RFC/blob/master/1-Draft/RFC0020-DefaultFileEncoding.md).\r\n\r\nIn contrast,  `Get-Help Set-Content`, `Get-Help Add-Content`, and `Get-Help Get-Content` state for parameter `-Encoding`:\r\n\r\n> Specifies the file encoding. The default is ASCII.\r\n\r\nThe help-topic sources (branch `live`) for the relevant cmdlets can be found [here](https://github.com/PowerShell/PowerShell-Docs/tree/live/reference/5.1/Microsoft.PowerShell.Core/Providers/FileSystem-Provider).\r\n\r\nAdditionally:\r\n\r\n* While these cmdlets _accept_ an encoding identifier `Default`, as used in other cmdlets, the help only mentions `String`.\r\n\r\n* Given that the two appear to result in the same encoding - what is their relationship?\r\n\r\n* The description for encoding `String` in the [online help](https://msdn.microsoft.com/en-us/powershell/reference/5.1/microsoft.powershell.management/set-content) is inadequate:\r\n\r\n> Uses the encoding type for a string.\r\n\r\nEnvironment data\r\n----------------\r\n\r\n<!-- provide the output of $PSVersionTable -->\r\n\r\n```powershell\r\nPowerShell Core v6.0.0-alpha (v6.0.0-alpha.16) on Microsoft Windows 10 Pro (64-bit; v10.0.14393)\r\n```\r\n",
  "closed_at": "2017-04-14T18:43:41Z",
  "comments": [
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "The default is changed for PowerShell Core to [ISO-8859-1](https://github.com/PowerShell/PowerShell/blob/fc30ae1d8713d930b7301bd6d9a85c77256f8669/src/System.Management.Automation/utils/ClrFacade.cs#L385)\r\nFor OEM too [ISO-8859-1](https://github.com/PowerShell/PowerShell/blob/fc30ae1d8713d930b7301bd6d9a85c77256f8669/src/System.Management.Automation/utils/ClrFacade.cs#L403)\r\n\r\nFile provider \r\n[GetContentReader](https://github.com/PowerShell/PowerShell/blob/02b5f357a20e6dee9f8e60e3adb9025be3c94490/src/System.Management.Automation/namespaces/FileSystemProvider.cs#L6476)\r\n[GetContentWriter](https://github.com/PowerShell/PowerShell/blob/02b5f357a20e6dee9f8e60e3adb9025be3c94490/src/System.Management.Automation/namespaces/FileSystemProvider.cs#L6639)\r\n",
      "created_at": "2017-03-03T18:53:35Z",
      "updated_at": "2017-03-03T18:53:35Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "This is real regression (breaking change) and we should fix it.",
      "created_at": "2017-03-04T15:35:13Z",
      "updated_at": "2017-03-04T15:35:13Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "The `Default` is changed for PowerShell Core to [ISO-8859-1](https://github.com/PowerShell/PowerShell/blob/fc30ae1d8713d930b7301bd6d9a85c77256f8669/src/System.Management.Automation/utils/ClrFacade.cs#L385)\r\nFor `OEM` [ISO-8859-1](https://github.com/PowerShell/PowerShell/blob/fc30ae1d8713d930b7301bd6d9a85c77256f8669/src/System.Management.Automation/utils/ClrFacade.cs#L403) too.\r\n\r\nLets see PowerShell FullCRL.\r\n`Default` use function [GetACP](https://msdn.microsoft.com/en-us/library/windows/desktop/dd318070%28v=vs.85%29.aspx) (Retrieves the current Windows ANSI code page identifier for the operating system.) See [.Net Framework Reference](https://referencesource.microsoft.com/#mscorlib/system/text/encoding.cs,1400)\r\n\r\n`OEM` is in only PowerShell and use function [GetOEMCP](https://msdn.microsoft.com/en-us/library/windows/desktop/dd318114(v=vs.85).aspx) (Returns the current original equipment manufacturer (OEM) code page identifier for the operating system.) See [PowerShell code](https://github.com/PowerShell/PowerShell/blob/fc30ae1d8713d930b7301bd6d9a85c77256f8669/src/System.Management.Automation/utils/ClrFacade.cs#L405)\r\n\r\nI don't know why the both encodings was added in Powershell. Maybe PowerShell PG comment this.\r\n\r\n`Default` is still not released in CoreCLR - so it is external issue. Maybe PowerShell PG find out this internally with .Net team. And should we use `waiting-netstandart20` label?\r\n`OEM` is not in CoreCLR at all - so it seems is internal issue. Is it make sense to fix it?",
      "created_at": "2017-03-04T20:37:08Z",
      "updated_at": "2017-03-04T20:37:08Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@mklement0 See [.Net Framework Reference](https://referencesource.microsoft.com/#mscorlib/system/text/encoding.cs,1400)\r\nWe can not use Windows-1252 as default.\r\n",
      "created_at": "2017-03-04T20:38:47Z",
      "updated_at": "2017-03-04T20:38:47Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Here `Default` is not PowerShell default, it is OS default. Every system can has own default. Original .Net code use `GetACP()` to get OS default code page. Modern Unix use `en_US.UTF-8` as default.",
      "created_at": "2017-03-05T05:24:39Z",
      "updated_at": "2017-03-05T05:24:39Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "cc @JamesWTruher @BrucePay ",
      "created_at": "2017-03-05T05:55:39Z",
      "updated_at": "2017-03-05T05:55:39Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@mklement0 Current `Windows Powershell` behavior is based on .Net Framework and it is dynamic:\r\n\r\nSystem | FileSystemCmdletProviderEncoding.Default (GetACP()) | FileSystemCmdletProviderEncoding.OEM (GetOEMCP())\r\n-|-|-\r\nWindows English | 1252 | 437\r\nWindows Russian | 1251 | 866\r\n\r\nCurrent `PowerShell Core` behavior is hard-coded to ISO-8859-1. If we change it on Windows-1252 we still not get Windows PowerShell behavior:\r\n\r\nSystem | FileSystemCmdletProviderEncoding.Default (GetACP()) | FileSystemCmdletProviderEncoding.OEM (GetOEMCP())\r\n-|-|-\r\nWindows English | 1252 | 437\r\nWindows Russian | 1252 | 437\r\n\r\nPreferred solution is to fix this in CoreCLR.\r\n\r\nAs you can see then we can properly read and write files on Windows Russian with 1251 (default system) code page by:\r\n`Get-Content -Encoding Default` and `Set-Content -Encoding Default`\r\n\r\nAs far as Unix locale names mapping Unix uses standard names [Table of locales](https://docs.moodle.org/dev/Table_of_locales) (This is not a complete sample). Therefore, the fix in CoreCLR will not be too difficult.\r\n\r\nWe should wait for MSFT expert conclusion and then it will be clear that we need to fix in the code and documentation.\r\n",
      "created_at": "2017-03-05T16:35:00Z",
      "updated_at": "2017-03-05T16:35:00Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@mklement0 We have a RFC draft for this. Welcome to discuss https://github.com/PowerShell/PowerShell-RFC/issues/71\r\n",
      "created_at": "2017-03-06T04:54:23Z",
      "updated_at": "2017-03-06T04:54:23Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov: Good idea. I've cleaned up my comments here, and I've revised the original post to point to the relevant other issues / comments / RFC.",
      "created_at": "2017-03-06T19:26:04Z",
      "updated_at": "2017-03-06T19:26:04Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@mklement0 \r\n>\u2022Are the help topics open-sourced too? \r\n\r\nSee full PowerShell repo list https://github.com/PowerShell/",
      "created_at": "2017-03-06T19:30:08Z",
      "updated_at": "2017-03-06T19:30:08Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "@mklement0 more specifically https://github.com/powershell/powershell-docs\r\n",
      "created_at": "2017-03-06T20:31:36Z",
      "updated_at": "2017-03-06T20:31:36Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "Thanks - I've added a link to the original post that links specifically to the parent folder of the relevant cmdlets' help-topic sources.",
      "created_at": "2017-03-06T20:37:22Z",
      "updated_at": "2017-03-06T20:37:22Z"
    },
    {
      "author": "joeyaiello",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov do you know of an issue where .NET Core is tracking this problem? You're right, ideally the fix is made in .NET Core. ",
      "created_at": "2017-03-20T23:18:12Z",
      "updated_at": "2017-03-20T23:18:12Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "@joeyaiello:\r\n\r\n* I don't think there is a fix to be made in .NET Core, or any variant of .NET, for that matter.\r\n\r\n* **PowerShell, from v1 on, decided to do its own thing, _separate from the .NET framework_**, which at its core (no pun intended) has always been UTF-8-without-BOM-based - and .NET Core is no exception.\r\n\r\n* Therefore, **aligning PS with .NET's defaults - if chosen - must be a very deliberate act**, carefully weighing potentially breaking backward-compatibility against the gains (I do think it's worth doing, however).\r\n\r\n* Similarly, with respect to **providing _legacy Windows_ PowerShell behavior on _Unix_ platforms, the onus is on _PowerShell_,** not .NET Core.\r\n\r\n\r\n",
      "created_at": "2017-03-21T01:56:02Z",
      "updated_at": "2017-03-21T01:59:34Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@joeyaiello I have not found such Issue in CoreFX repo. We should create new. I prefer that it made the PowerShell team because it can cause a large discussion.",
      "created_at": "2017-03-21T05:22:22Z",
      "updated_at": "2017-03-21T05:22:22Z"
    },
    {
      "author": "joeyaiello",
      "author_association": "CONTRIBUTOR",
      "body": "Wow, there's a lot there. Let me clarify a few things:\r\n\r\nFirst, my ask to @iSazonov was purely around the codepage issue he referenced above. I admit I skimmed the problem a little too quickly and mistook `FileSystemCmdletProviderEncoding` for a CoreCLR type rather than for our type. I had assumed this was similar to #2009 where we were reading an inaccurate value given to us by CoreCLR. If \"current PowerShell Core behavior is hard-coded to ISO-8859-1\" means that we're hardcoding a value in `FileSystemCmdletProviderEncoding` , let's fix that. (I'm hoping this one is noncontroversial because the behavior in Windows PowerShell is already the correct behavior.)\r\n\r\nBefore diving into the rest of the problems you raised, I should also note that I did not intend to put the onus on .NET Core for addressing the myriad of other problems we have around file encodings. As I've read it, the heart of this issue (#3248, not #707 which talks about the problem more generally) is that we're not following the same behavior as Windows PowerShell today because we're not respecting the codepage associated with a given machine's locale. **What I still don't fully understand (and what we need to answer) is whether that is happening because of PowerShell or .NET Core.** No matter what we do in the rest of the encoding space, `Default` and `OEM` need to work properly. If everyone agrees that I'm capturing the essence of this issue properly, I'll change the title to reflect it. \r\n\r\nNow, to the more general problem: I am the first to admit that PowerShell's approach to encoding is a horrible mish-mash of inconsistent behaviors. That's why [we have an RFC out](https://github.com/PowerShell/PowerShell-RFC/blob/master/1-Draft/RFC0020-DefaultFileEncoding.md) that's intended to create more sane defaults on Linux (and for those people willing to change their defaults on Windows) while also maintaining the legacy mish-mash for those who have written scripts already to work around it. As @mklement0, @iSazonov, and others have already been doing, I highly encourage anyone who cares about the encoding problem [to give us feedback on that RFC](https://github.com/PowerShell/PowerShell-RFC/issues/71). \r\n\r\nAdditional side notes: \r\n* Unfortunately, after a deep-dive investigation, we know that the behavior in .NET Framework has not always been purely non-BOM (and in fact, [CoreCLR still maintains this inconsistency](https://github.com/PowerShell/PowerShell/issues/707#issuecomment-219570662) for back-compat). \r\n* To give you historical context as I understand it from those who have been on the team for a long time, Microsoft thought UTF-16 was the future and little thought was given to BOM or multi-byte standards around UTF-8. Given our heavy bend towards localization, and (at least as perceived by MSFT at the time) a lack of prevalence of multi-byte UTF-8, we were all in on UTF-16 (hence why `Unicode` is the enum value associated with `UTF-16`, despite the technical inaccuracy of that label). ",
      "created_at": "2017-03-21T20:38:52Z",
      "updated_at": "2017-03-21T20:38:52Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "@joeyaiello: Thanks for that detailed response.\r\n\r\n> What I still don't fully understand (and what we need to answer) is whether that is happening because of PowerShell or .NET Core\r\n\r\nThe  **_Windows_ perspective**:\r\n\r\n**I may have spoken too soon when I said that no .NET Core fix is needed, though PowerShell could do its own implementation, if needed**: \r\n\r\nThe current PS Core source code contains [this comment](https://github.com/PowerShell/PowerShell/blob/b4049879d432a4a8b9d40845ef634dc5f22aa44e/src/System.Management.Automation/utils/ClrFacade.cs#L539):\r\n\r\n> #if CORECLR     // Encoding.Default is not in CoreCLR\r\n                // As suggested by CoreCLR team (tarekms), use latin1 (ISO-8859-1, CodePage 28591) as the default encoding.\r\n                // We will revisit this if it causes any failures when running tests on Core PS.\r\n                s_defaultEncoding = Encoding.GetEncoding(28591);\r\n\r\nand a [similar comment](https://github.com/PowerShell/PowerShell/blob/b4049879d432a4a8b9d40845ef634dc5f22aa44e/src/System.Management.Automation/utils/ClrFacade.cs#L554) re OEM encoding.\r\n\r\n(As has been discussed, using ISO-8859-1 is inadequate, primarily because it doesn't respect the _variable_ Windows legacy system locale, and secondarily because [it doesn't even cover all characters in the most widely used \"ANSI\" codepage, Windows-1252](https://github.com/PowerShell/PowerShell/issues/3258#issue-211898576).)\r\n\r\nWhile `[System.Text.Encoding]::Default` isn't part of the .NET contract, it _is_ available, and so is the in-contract equivalent, `[System.Text.Encoding]::GetEncoding(0)`.\r\n\r\n**What .NET Core returns is a _UTF-8_ encoding _with_ BOM**, however, even on Windows, whereas **on _Windows_ it arguably should return the \"ANSI\" encoding (the active code page implied by the system locale), as the .NET _Framework_ does**.\r\n\r\nHowever, [the majority of the _Windows_ code pages are _not_ part of .NET Core](https://msdn.microsoft.com/en-us/library/system.text.encodingprovider(v=vs.110).aspx)., notably missing Windows-1252 and any of the OEM code pages.\r\n\r\n**An [optional NuGet package](https://www.nuget.org/packages/System.Text.Encoding.CodePages/) does make them all available in .NET Core, even on Unix**, however (as demonstrated [here](http://stackoverflow.com/a/37870346/45375)).\r\n\r\nThat package already seems to part of PS Core _at runtime_, actually, as evidenced by `[System.Text.CodePagesEncodingProvider]::Instance.GetEncoding(1252)` succeeding, even on Unix.\r\n\r\n**With this package, PS Core could fix the issue even without any changes to .NET Core**, by passing the code-page identifiers returned by `[cultureinfo]::CurrentCulture.TextInfo.ANSICodePage` and\r\n`[cultureinfo]::CurrentCulture.TextInfo.OEMCodePage` \r\n(which presumably call the `GetACP` (\"ANSI\") and `GetOEMCP` (OEM) Windows API functions that @iSazonov mentions) to `[System.Text.CodePagesEncodingProvider]::Instance.GetEncoding()`.\r\n\r\n---\r\n\r\nAs for the **_Unix_ perspective:**\r\n\r\nFirst and foremost: **Is it worth trying to emulate the _Windows_ encoding behavior on Unix**, using _Windows_ encodings, **by mapping the Unix locales onto Windows code pages**?\r\n\r\n@iSazonov links to an [(incomplete) table](https://docs.moodle.org/dev/Table_of_locales) from the Moodle (a CMS) docs that seemingly provides this kind of mapping, but I see a problem with that:\r\n\r\n* The mapping cannot be unambiguous, because there are locales that have variations that use _different scripts_ (character sets). For instance, Bosnian can be written in both the Latin alphabet and the Cyrillic alphabet, and on _Windows_ these variants - of necessity - use _distinct code pages_.  \r\nSay you're on a Unix platform whose active locale is `bs_BA.UTF-8` - this locale, due to using UTF-8, is capable of representing _both_ writing systems. To map that onto a Windows code page, you must _choose_ between Windows-1250 (Latin) and Windows-1251 (Cyrillic), and there's no obvious choice.\r\n\r\nPerhaps a compromise is to expose the Windows codepages as distinct `-Encoding` values, so that an explicit choice is possible (e.g., `-Encoding 1250`).\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "created_at": "2017-03-22T21:28:37Z",
      "updated_at": "2017-03-23T20:22:32Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "@joeyaiello: As for the side notes:\r\n\r\n> Unfortunately, after a deep-dive investigation, we know that the behavior in .NET Framework has not always been purely non-BOM (and in fact, CoreCLR still maintains this inconsistency for back-compat).\r\n\r\nWhile the differing BOM behavior between `[System.Text.Encoding]::UTF8` and `[System.Text.UTF8Encoding]` is regrettable, **the true _default_ behavior has always been _BOM-less_ UTF-8.**\r\n\r\nBy true default behavior I mean what happens when you use `[System.IO.File]` methods _without specifying an encoding_:\r\n\r\n* On _writing_, a BOM-less UTF-8 file is created.\r\n\r\n* On _reading_, a BOM-less file is interpreted as UTF-8.\r\n\r\nThis is in line with what modern Unix platforms do (with a now-ubiquitous UTF-8-based locale in effect).\r\n\r\n\r\n\r\n",
      "created_at": "2017-03-22T21:50:25Z",
      "updated_at": "2017-03-22T21:50:25Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I collected all links for more easy review.\r\n\r\n#### File encoding ####\r\n1. [`FileSystemCmdletProviderEncoding` _enum_](https://github.com/PowerShell/PowerShell/blob/master/src/System.Management.Automation/namespaces/FileSystemProvider.cs#L7329)\r\nUsed by FileSystemProviger cmdlets.\r\nContain special member `Byte` for BinaryStreams. It is processed by separated code, other members is converted to `System.Text.Encoding` type.\r\nCode is distributed in two files:\r\n[FileSystemProvider.cs](https://github.com/PowerShell/PowerShell/blob/master/src/System.Management.Automation/namespaces/FileSystemProvider.cs)\r\n[Utils.cs](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/engine/Utils.cs)\r\n2. [`EncodingConversion` _class_](https://github.com/PowerShell/PowerShell/blob/02b5f357a20e6dee9f8e60e3adb9025be3c94490/src/System.Management.Automation/utils/PathUtils.cs#L440)\r\nUsed by non-FileSystemProviger cmdlets (+ web cmdlets).\r\nDon't contains `Byte` type.\r\nUnlike `FileSystemCmdletProviderEncoding` the `EncodingConversion` can be easily enhanced (to support dynamic list of all installed codepages). \r\nAll member converted to `System.Text.Encoding` type.\r\nThere is `ArgumentToEncodingNameTransformationAttribute` in [Send-MailMessage](https://github.com/PowerShell/PowerShell/blob/02b5f357a20e6dee9f8e60e3adb9025be3c94490/src/Microsoft.PowerShell.Commands.Utility/commands/utility/Send-MailMessage.cs#L498)\r\nIt would be good to have `ValidateEncoding` attribute for cmdlet parameters.\r\nI believe we could enhance the class with `Byte` and exclude `FileSystemCmdletProviderEncoding` enum\r\n\r\nBoth types use call [ClrFacade.GetDefaultEncoding()](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/ClrFacade.cs#L535) and [ClrFacade.GetOEMEncoding()\r\n](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/ClrFacade.cs#L554)\r\n\r\n#### Default and OEM ####\r\n1. Default\r\nFor PowerShell CoreCLR - [Encoding.GetEncoding(28591)](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/ClrFacade.cs#L542) - ISO-8859-1\r\nFor PowerShell FullCLR   - [Encoding.Default](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/ClrFacade.cs#L544) ([Encoding.Default](https://referencesource.microsoft.com/#mscorlib/system/text/encoding.cs,1423) and [CreateDefaultEncoding()](https://referencesource.microsoft.com/#mscorlib/system/text/encoding.cs,da50c22465aa9274)) - it is Win32Native.GetACP() for .Net Framework.\r\n(So Windows PowerShell use native call and work well)\r\n.Net Framework use [UTF-8 as default for Silverlight](https://referencesource.microsoft.com/#mscorlib/system/text/encoding.cs,1413)\r\n\r\n2. OEM\r\nFor .Net Framework it is [not supported](https://referencesource.microsoft.com/#mscorlib/system/text/encoding.cs,119)  for encoding.\r\nFor PowerShell CoreCLR - [GetDefaultEncoding()](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/ClrFacade.cs#L560)-  ISO-8859-1\r\nFor PowerShell FullCLR - [NativeMethods.GetOEMCP()](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/ClrFacade.cs#L562) - PowerShell already has the [P/Invoke](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/ClrFacade.cs#L1033) for [CoreCLR](https://github.com/PowerShell/PowerShell/blob/7f83c48ca5e39bc98dbb9071d414bd02166cd4af/src/System.Management.Automation/utils/PInvokeDllNames.cs#L19) too. So we can fix OEM for PowerShell Core on Windows. But for Unix we should get answer: what should GetOEMCP() returns? (Ex.: `GetACP()` returns \"system/machine locale\", `GetOEMCP()` returns \"current session locale\").\r\nIt seems we cannot use ` [cultureinfo]::CurrentCulture.TextInfo.OEMCodePage` (from @mklement0 )because it always returns `null` on Unix (I tested on WSL only). (It is in [CoreCLR](https://github.com/dotnet/coreclr/tree/d905f67f12c6b2eed918894e0642ec972a1d9fec/src/mscorlib/src/System/Globalization) CultureInfo and CultureData)\r\n\r\nAlso we never talked about IOS - that has its codepages.\r\n\r\nHere you can see that `Default` is external Issue and should be fixed in CoreFX, `OEM` is internal Issue and should be fixed in PowerShell repo.\r\n\r\n#### About Web cmdlets ####\r\nPowerShell Core defaults is [ISO-8859-1](https://github.com/PowerShell/PowerShell/blob/master/src/Microsoft.PowerShell.Commands.Utility/commands/utility/WebCmdlet/Common/ContentHelper.Common.cs#L20)\r\nHTML5 default is UTF-8 [HTML 5 rules for determining content type](https://dev.w3.org/html5/cts/html5-type-sniffing.html)\r\nIt seems HTTP1.1 UTF-8 too  https://tools.ietf.org/html/rfc7231\r\nCurrently CoreFX already use [UTF8 as default](https://github.com/dotnet/corefx/blob/b1865ea0847a7a86baefe8378b772ecf0b785681/src/System.Net.Http/src/System/Net/Http/HttpContent.cs#L223).\r\n\r\n\r\n\r\n\r\n",
      "created_at": "2017-03-23T09:25:39Z",
      "updated_at": "2017-03-23T09:25:39Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov: Great compilation of links, thanks.\r\n\r\nYes, `[cultureinfo]::CurrentCulture.TextInfo.ANSICodePage` and `[cultureinfo]::CurrentCulture.TextInfo.OEMCodePage` appear to be empty on all Unix platforms at the moment - though it appears the the groundwork has been laid in [LocaleDataUnix.cs](https://github.com/dotnet/coreclr/blob/a2c684d4094d00c715d67238cf4f4650248d4ded/src/mscorlib/src/System/Globalization/LocaleData.Unix.cs#L25) and [CultureDataUnix.cs](https://github.com/dotnet/coreclr/blob/d905f67f12c6b2eed918894e0642ec972a1d9fec/src/mscorlib/src/System/Globalization/CultureData.Unix.cs#L324)  - including mapping to Windows LCIDs (which is the part I think that can't be done unambiguously - unless all Unix locale identifiers, across all platforms, have a `@<script>` suffix that denotes the charset).\r\n\r\nAlso, what I didn't consider earlier is that, of course, all culture/locale aspects _aside_ from legacy character encoding  (date format, number format, ...) _must_ work in .NET Core on Unix platforms too, and it appears that that's already the case.\r\n\r\nI don't know what the .NET Core team's plans are, but _conceivably_ - as suggested by not including the majority of Windows code pages - the intent is  to _not_ support legacy Windows code pages - and let's not forget that they're _legacy_ for a reason.\r\n\r\nIn today's world, with Unicode as the lingua franca, the question really shifts from what the active, _culture-specific, mutually incompatible code page_ is to what _encoding_ of the _universal alphabet (Unicode)_ should be the default.\r\n\r\nIn other words: using Unicode has taken culture specificity out of the equation and reduced the question to _which encoding of Unicode_ should be assumed _by default_ when faced with an unmarked byte stream (file).\r\n\r\nWindows - sorta, kinda, but not yet, really - settling on UTF-16 LE is, unfortunately, at odds with the Unix world, which has chosen UTF-8 (which allowed for a much smoother transition from legacy encodings, though it is Western-centric).\r\n\r\nSo if we take _legacy_ behavior out of the picture, what _default encoding of Unicode_ that is applied _in the absence of a BOM_ should officially be used, per each platform's policies?\r\n\r\n* Unix: UTF-8  - and the transition from legacy single-byte encodings _has_ happened.\r\n\r\n* Windows: UTF-16 LE - but the transition from legacy single-byte encodings has _not_ happened, to this day.\r\n\r\nPerhaps the fact that Windows never truly transitioned to UTF-16 LE - at least in terms of _file_ encoding - is an _opportunity_ to align the two worlds, by both making them speak (by definition BOM-less) UTF-8 _by default_.\r\n\r\nIf so, \r\n\r\n* the only change to .NET Core that's required is to change `[System.Text.Encoding]::GetEncoding(0)` to _BOM-less_ UTF-8, on both Windows and Unix - as stated, the `[System.IO.File]` type already does that by default.\r\n\r\n* anyone wishing to use _legacy_-encoded files in PowerShell Core needs to re-encode them to _some_ encoding of Unicode: either BOM-less UTF-8, or one of the BOM-prefixed standard Unicode encoding forms (UTF-8, UTF-16, UTF-32).\r\n\r\nDo we really need to support _legacy_ Windows code pages in PowerShell _Core_ (whether on Unix or Windows)?\r\n\r\n\r\n\r\n\r\n\r\n",
      "created_at": "2017-03-23T22:23:55Z",
      "updated_at": "2017-03-23T22:27:35Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": ">Do we really need to support legacy Windows code pages in PowerShell Core (whether on Unix or Windows)?\r\n\r\nThere is a huge amount of software that only works with legacy code pages. Although the number has decreased since 2003 year.",
      "created_at": "2017-03-24T06:59:46Z",
      "updated_at": "2017-03-24T06:59:46Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov: I hear you, but do users who rely on this kind of software need this legacy support in PowerShell _Core_? Aren't users who rely on legacy _Windows_ applications likely to stay in the realm of _Windows_ PowerShell?\r\n\r\nI see the following **fundamental options** (from a purely _conceptual_ standpoint - ease of implementation is not being considered here).\r\n\r\nI think it's **important to get clarity with respect to what _should_ be implemented** - as opposed to what _can_ be.\r\nBased on the appropriate way forward, we can assess what aspects should be implemented by the underlying .NET Core rather than in PowerShell Core.\r\n\r\n* (a) **Core-NoWinLegacy**:\r\n\r\n  Forgo all Windows legacy support in PowerShell _Core_ - only implement it in _Windows_ PowerShell.\r\n\r\n* (b) **Core-WinLegacy-onWindows**:\r\n\r\n  Provide Windows legacy support in PowerShell _Core_ too, but only _on Windows_.\r\n\r\n* (c) **Core-WinLegacy-Everywhere**:\r\n\r\n  Provide Windows legacy support in PowerShell Core on _all_ platforms, including Unix.\r\n\r\n\r\n(c) may be what @JamesWTruher  had in mind in his RFC, though the RFC mistakenly assumes only having to deal with _1_,  _fixed_ single-byte legacy behavior: ASCII  - whereas the truth is that a whole raft of _culture-specific_ \"ANSI\" codepages must be emulated.\r\n\r\n\u2014\r\n\r\nAs for how these options relate to  **things needed from .NET Core:**\r\n\r\n(a) clearly needs no additional effort.\r\n\r\n(b) also needs no additional effort - the [aforementioned NuGet package](https://www.nuget.org/packages/System.Text.Encoding.CodePages/) can bring in all Windows legacy code pages, and `[cultureinfo]::CurrentCulture.TextInfo.ANSICodePage` and `[cultureinfo]::CurrentCulture.TextInfo.OEMCodePage` _on Windows_ already tell us what code pages to use as the legacy defaults.\r\n\r\n(c) _Will be implemented in .NET CoreCLR v2_: The current pre-v2 version already  reports values for `[cultureinfo]::CurrentCulture.TextInfo.ANSICodePage` and `[cultureinfo]::CurrentCulture.TextInfo.OEMCodePage` on _Unix too_, performing the aforementioned mapping of Unix locale identifiers to legacy Windows code pages.  \r\nThere are still _edge cases_ - see below.   \r\nThat said, if the consensus is to implement (c), these edge cases (see bottom) should be considered an acceptable price to pay for Windows legacy support on Unix.\r\n\r\n---\r\n\r\nNote that **currently, _Unix_ legacy support is not even part of the debate** - while UTF-8-based locales are near-ubiquitous nowadays, Unix platforms still support legacy locales based on single-byte charmaps comparable to Windows legacy code pages.  \r\nTo be legacy-friendly on Unix platforms, these charmaps would have to be respected too.\r\n\r\n.NET Core, with the limited set of code pages it comes with, is _not_ capable of this legacy Unix support, and, as of this writing, the preview version of v2 doesn't change that.\r\n\r\n---\r\n\r\n**Edge cases when mapping Unix locales to Windows legacy code pages**:\r\n\r\nAs mentioned before, some culture uses _more than one_ script (alphabet); gotta love [Wikipedia](https://en.wikipedia.org/wiki/Serbian_language):\r\n\r\n> Serbian is practically the only European standard language with complete synchronic digraphia,[15] using both Cyrillic and Latin alphabets;\r\n\r\nThus, when mapping a Serbian Unix locale to a legacy Windows code page, _one or the other_ alphabet must be chosen, because no single legacy code page can represent _both_ alphabets.\r\n\r\n_This choice isn't unambiguous._\r\n\r\nHere is the list of Serbian (`sr_*`) locales available on two sample Unix platforms:\r\n\r\n* macOS 10.12:\r\n\r\n```\r\nsr_YU\r\nsr_YU.ISO8859-2\r\nsr_YU.ISO8859-5\r\nsr_YU.UTF-8\r\n```\r\n\r\n* Ubuntu 16.04:\r\n\r\n```\r\nsr_ME UTF-8\r\nsr_RS UTF-8\r\nsr_RS@latin UTF-8\r\n```\r\n\r\nmacOS is stuck in the past (`YU` representing the long-defunct former Yugoslavia); the `.ISO8859-2` and `.ISO8859-5` unambiguously imply the Latin and Cyrillic alphabet respectively, but what `sr_YU.UTF-8` should map to - given that UTF-8 is capable of encoding _both_ alphabets - is open to interpretation.  \r\n**If there's always a _preferred_ alphabet for such cultures, perhaps that's a non-issue - I don't know the answer to that.**\r\n\r\nUbuntu faces the same issues, with only `sr_RS@latin UTF-8` _implying_ the alphabet via the embedded `@latin` script/variant identifier.\r\n\r\n**In practice, as of .NET Core v2.0.0-beta-001836-00, _all_ of the above cases default to the _Latin_ alpabet.**\r\n",
      "created_at": "2017-03-26T23:11:46Z",
      "updated_at": "2017-03-26T23:11:46Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@joeyaiello @SteveL-MSFT @mklement0 I opened issue-question in .Net Core repo and get great comments about defaults https://github.com/dotnet/standard/issues/260#issuecomment-289549508\r\n",
      "created_at": "2017-03-28T06:41:43Z",
      "updated_at": "2017-03-28T06:41:43Z"
    },
    {
      "author": "joeyaiello",
      "author_association": "CONTRIBUTOR",
      "body": "First just want to say, thanks for the extended explanations, everyone. This has been thoroughly useful. And thanks, @iSazonov, for looping in the dotnet/standard folks. \r\n\r\nNow, next steps: \r\n* I want to tease the encoding issue into as many smaller chunks as possible. This thread was originally about the `OEM`/`Default` codepage issue. If we can fix that in Windows with a platform-specific guard today, and fix it later on Linux with .NET Standard and `System.Text.Encoding.CodePages`, we should do that and close out this issue. \r\n* As I said in the other thread, I'm not concerned about the legacy Linux encoding scenario. It's uncommon, and we don't have baggage there.\r\n* The other questions should all be addressed in PowerShell/PowerShell-RFC#71 and fixed in the RFC so that everyone can have a central view of how we're addressing encodings and so the @PowerShell/powershell-committee can sign off on that view. \r\n\r\nSound reasonable? ",
      "created_at": "2017-03-30T23:42:36Z",
      "updated_at": "2017-03-30T23:42:36Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I pushed PR with fix for Default/OEM.",
      "created_at": "2017-03-31T17:28:09Z",
      "updated_at": "2017-03-31T17:28:09Z"
    },
    {
      "author": "mklement0",
      "author_association": "CONTRIBUTOR",
      "body": "@joeyaiello: Thanks, that indeed sounds reasonable (and I hope it's OK that, as an outsider, I'm being vocal here - I love PowerShell and I think getting the encoding right is crucial to PowerShell's cross-platform success).\r\n\r\n",
      "created_at": "2017-04-01T17:32:05Z",
      "updated_at": "2017-04-01T17:32:05Z"
    },
    {
      "author": "joeyaiello",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov Sweet! \r\n\r\n@mklement0 I don't consider you an outsider, you're here constructively voicing opinions. Keep it coming :+1:\r\n\r\nAnd for what it's worth, I absolutely agree. We need to nail encodings. ",
      "created_at": "2017-04-05T16:28:56Z",
      "updated_at": "2017-04-05T16:28:56Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "#3467 merged and we would close the Issue or leave it open in waiting our Encoding RFC.",
      "created_at": "2017-04-06T03:07:50Z",
      "updated_at": "2017-04-06T03:07:50Z"
    },
    {
      "author": "joeyaiello",
      "author_association": "CONTRIBUTOR",
      "body": "Per the plan I posted above, let's close this particular as resolved, and drive the RFC to completion via the normal process. If other issues arise after that, we should open new issues. ",
      "created_at": "2017-04-14T18:43:41Z",
      "updated_at": "2017-04-14T18:43:41Z"
    }
  ],
  "created_at": "2017-03-03T16:48:43Z",
  "labels": [
    "Issue-Bug",
    "Issue-Discussion",
    "Resolution-Fixed"
  ],
  "number": 3248,
  "state": "closed",
  "title": "Set-Content/Add-Content/Get-Content use an 8-bit character encoding by default, but the help topics state ASCII; problematic Core default file encoding",
  "updated_at": "2017-04-14T18:43:54Z"
}