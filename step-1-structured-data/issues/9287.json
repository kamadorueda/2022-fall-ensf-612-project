{
  "_url": "https://github.com/PowerShell/PowerShell/issues/9287",
  "author": "vexx32",
  "body": "# Summary of the new feature/enhancement\r\n\r\nAs a user, it's currently quite tricky to accurately gauge the execution times of any individual block of code. An individual sequence of code may have quite variable execution times depending on a number of factors, so the simple approach of `Measure-Command` is not particularly suitable for any fine-tuning in many cases, especially in the <10ms range.\r\n\r\nInstead, perhaps we could implement more robust usages, with additional switch options and configurability.\r\n\r\nTake, for example, `BenchmarkDotNet`. It's _really_ good at testing one method against another, with the downside being that it requires more time to test more rigorously. Measure-Command could potentially implement some degree of the functionality present in BenchmarkDotNet in ways that are more useful when dealing with PowerShell code, for example separate measures of particular steps in a pipeline, particularly slow patterns used in the code, etc.\r\n\r\nIncreasing the reliability of the benchmark would also be fantastically helpful to many who do want to try their best to avoid particularly sluggish patterns. PowerShell may not be optimised for speed in general, but there _definitely_ are some coding patterns that are simply unnecessarily far too slow.\r\n\r\n# Proposed technical implementation details (optional)\r\n\r\n1. Builtin support for more rigorous benchmarks, including repeated tests with some basic statistical output (min, max, mean, median, mode for execution times), explicit discarding of especially unusual outliers where it seems likely to have been caused by something not relevant to the test run.\r\n2. Configurable options when using the advanced functionality for:\r\n    * Number of test runs\r\n    * Whether to flag/remove outliers from statistical calculations.\r\n3. Line-by-line analysis of code timings.\r\n4. (Maybe?) Sub-pipeline analysis of code timings.\r\n\r\nCurrently, the only comparable tools that I'm aware of are @KevinMarquette's [Chronometer](https://github.com/KevinMarquette/Chronometer) module, and Pester, _both_ of which are hampered in two ways:\r\n\r\n1. They're both written in PowerShell code, limiting their access to information on the internals and hampering their ability to get consistently accurate timings.\r\n2. They both have to use breakpoints to figure out timings, which slows down the code execution a fair bit just by necessity, making it very tricky to actually figure out the time taken to run the code itself, as the breakpoints also take time to create and step through.\r\n",
  "closed_at": null,
  "comments": [
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> Measure-Command could potentially implement some degree of the functionality present in BenchmarkDotNet\r\n\r\nYou mix microbenchmaring and profiling - it is different approaches. I think it is impossible to implement microbenchmaring on PowerShell language because every command (cmdlet, operator) involves full engine. So we could say about `profiler`. I remember that @daxian-dbw has a great desire to work on it, but it is unlikely that something is progressing there due to lack of free time.",
      "created_at": "2019-04-04T06:42:59Z",
      "updated_at": "2019-04-04T06:43:57Z"
    }
  ],
  "created_at": "2019-04-03T17:32:17Z",
  "number": 9287,
  "state": "open",
  "title": "Improve Robustness of Measure-Command",
  "updated_at": "2019-04-04T06:43:57Z"
}