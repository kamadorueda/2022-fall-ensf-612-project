{
  "_url": "https://github.com/PowerShell/PowerShell/issues/8347",
  "author": "HumanEquivalentUnit",
  "body": "Convert a plain English string to UTF16 (\"Unicode\") 2-bytes-per-character and convert it back through UTF8, and it ends up double the length, with spaces between every character. It's a wrong decoding, but that is something you can do.\r\n\r\nDo the same conversion path using `Set-Content -Encoding Unicode` and then `Get-Content -Encoding UTF8` , and I'd expect the exact same outcome. Instead, it decodes the string correctly:\r\n\r\n```\r\n$s = 'test'\r\n$bytes = [Text.Encoding]::Unicode.GetBytes($s)\r\n[text.encoding]::UTF8.GetString($bytes)\r\n\r\nt e s t\r\n\r\n\r\n$s | set-content ~\\test.txt -Encoding unicode\r\nget-content ~\\test.txt -Encoding utf8\r\n\r\ntest\r\n```\r\n\r\nI haven't tried to verify why, but the content of the file in bytes is a 2-byte encoding, so  my guess is that Get-Content is detecting the file's BOM and using the detected encoding instead of the encoding I told it to use.  The `-Encoding` section of the Get-Content help doesn't seem to mention it.\r\n\r\nIf I specify an encoding, should that override any auto-detection? Or should it at least be documented that it won't?",
  "closed_at": null,
  "comments": [
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "/cc @JamesWTruher Could you please look the Issue?",
      "created_at": "2018-11-29T10:41:04Z",
      "updated_at": "2018-11-29T10:41:04Z"
    }
  ],
  "created_at": "2018-11-28T09:48:38Z",
  "labels": [
    "Issue-Bug",
    "WG-Cmdlets-Management"
  ],
  "number": 8347,
  "state": "open",
  "title": "Get-Content ignores the -Encoding parameter sometimes",
  "updated_at": "2018-11-29T10:41:32Z"
}