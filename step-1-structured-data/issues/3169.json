{
  "_url": "https://github.com/PowerShell/PowerShell/issues/3169",
  "author": "rjmholt",
  "body": "This PR adds a new entry point for defining `DynamicKeyword`s to PowerShell. Where currently these can be added at runtime in PowerShell, this now uses CIL metadata in an assembly as a specification of the syntax requirements, and performs some validation of the specification.\r\n\r\nI've also added the concept of nested keywords -- there are keywords that will only be parsed and invoked as keywords when they are in the scope of another keyword. This seemed like a common feature in Domain Specific Languages we've been looking at.\r\n\r\nI still need to do some work on this PR, but I want to get the ball rolling because it's a substantial addition.\r\n\r\nWork to still to do includes:\r\n\r\n- Making the tests work on Linux. I didn't want to submit before this happened, but the errors are in module loading (module paths) and Add-Type (\"Could not load type...\") -- so I thought I would ask for advice on this\r\n- Adding a `Types.ps1xml`-like test case\r\n- Adding more tests for UseMode checking, keyword scope, and other DynamicKeyword features\r\n- Adding completions/intellisense for keywords\r\n\r\nI've been doing work on adding `DynamicKeyword` runtime execution using C# code (so a domain-specific language for PowerShell can be defined entirely in a C#/dotnet module/assembly -- see [here](https://github.com/rjmholt/PowerShell/blob/dsl-csharp-prototype/src/System.Management.Automation/engine/parser/DslSpecification.cs) for a very rough prototype), and this PR is essentially the first step toward that. I intend to submit an issue describing the work and a roadmap soon.\r\n\r\nFinally, in this PR, there are some points I think that need special scrutiny:\r\n\r\n- The `UseMode` concept (restricting how many times a keyword may appear in a block) -- it may be unneccessary or unwanted, and is where the metadata reader starts to verge on too opinionated. I included it because it was part of the RFC I submitted.\r\n- The metadata reader type providers -- one uses System.String and the other System.Type, but they could both be consolidated to use a custom type description class. I've seen dotnet core/corefx use a class called [TypeDesc](https://github.com/dotnet/corefx/blob/master/src/System.Private.Xml/src/System/Xml/Serialization/Types.cs#L71), but that might be a bit heavyweight. The type providers are also only partially implemented because some methods are never called -- but it would be nice to fix that.\r\n- Error messages -- I'm not sure what the standard way to report errors to the user is",
  "closed_at": "2018-02-23T05:37:55Z",
  "comments": [
    {
      "author": "msftclas",
      "author_association": "NONE",
      "body": "Hi __@rjmholt__, I'm your friendly neighborhood Microsoft Pull Request Bot (You can call me MSBOT). Thanks for your contribution!\r\n    <p>\r\n        It looks like you're a Microsoft contributor. If you're full-time or an intern, we DON'T require a Contribution License Agreement. If you are a vendor, please DO sign the electronic Contribution License Agreement. It will take 2 minutes and there's no faxing! https://cla.microsoft.com.\r\n    </p>\r\n\r\nTTYL, MSBOT;\r\n",
      "created_at": "2017-02-18T02:50:02Z",
      "updated_at": "2017-02-18T02:50:02Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "I have a rough idea of what needs fixing for the Unix support, but does AppVeyor use something other than `project.json` to resolve dependencies? I added `System.Reflection.Metadata` there, but clearly it needs to go somewhere else.",
      "created_at": "2017-02-18T22:50:08Z",
      "updated_at": "2017-02-18T22:50:08Z"
    },
    {
      "author": "lzybkr",
      "author_association": "MEMBER",
      "body": "project.json is it. You are likely missing a reference to System.Collections.Immutable.\r\n\r\nYou can try to repro locally by clearing your nuget cache unless it was resolving that assembly to the gac.",
      "created_at": "2017-02-18T23:16:13Z",
      "updated_at": "2017-02-18T23:16:13Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "The System.Reflection.Metadata package already depends on System.Collections.Immutable. Should I add System.Collections.Immutable anyway? I also noticed it's not resolving on types from System.Reflection.Metadata in the error message -- I can only replicate the problem when building with `-FullCLR`, which gives me a pretty perfect repro, but still comes up when I add System.Collections.Immutable by hand. Where does FullCLR look for dependencies?",
      "created_at": "2017-02-19T00:08:12Z",
      "updated_at": "2017-02-19T00:08:12Z"
    },
    {
      "author": "lzybkr",
      "author_association": "MEMBER",
      "body": "Ah, yeah, that's the failure in AppVeyor - the target is `net451` - which I've stopped doing in #3066 - we just need to get that approved.",
      "created_at": "2017-02-19T05:40:16Z",
      "updated_at": "2017-02-19T05:40:16Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@rjmholt Great work! \ud83d\udc4d ",
      "created_at": "2017-02-21T16:12:44Z",
      "updated_at": "2017-02-21T16:12:44Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "Closing and reopening to help @msftclas ",
      "created_at": "2017-02-22T20:04:46Z",
      "updated_at": "2017-02-22T20:04:46Z"
    },
    {
      "author": "msftclas",
      "author_association": "NONE",
      "body": "Hi __@rjmholt__, I'm your friendly neighborhood Microsoft Pull Request Bot (You can call me MSBOT). Thanks for your contribution!\r\n    <p>\r\n        It looks like you're a Microsoft contributor. If you're full-time or an intern, we DON'T require a Contribution License Agreement. If you are a vendor, please DO sign the electronic Contribution License Agreement. It will take 2 minutes and there's no faxing! https://cla.microsoft.com.\r\n    </p>\r\n\r\nTTYL, MSBOT;\r\n",
      "created_at": "2017-02-22T20:04:54Z",
      "updated_at": "2017-02-22T20:04:54Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "Trying again",
      "created_at": "2017-02-22T20:52:13Z",
      "updated_at": "2017-02-22T20:52:13Z"
    },
    {
      "author": "msftclas",
      "author_association": "NONE",
      "body": "Hi __@rjmholt__, I'm your friendly neighborhood Microsoft Pull Request Bot (You can call me MSBOT). Thanks for your contribution!\r\n    <p>\r\n        It looks like you're a Microsoft contributor. If you're full-time or an intern, we DON'T require a Contribution License Agreement. If you are a vendor, please DO sign the electronic Contribution License Agreement. It will take 2 minutes and there's no faxing! https://cla.microsoft.com.\r\n    </p>\r\n\r\nTTYL, MSBOT;\r\n",
      "created_at": "2017-02-22T20:52:20Z",
      "updated_at": "2017-02-22T20:52:20Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@rjmholt Earlier, I saw that the problem with CLA because someone used a different e-mail address for GitHub and CLA.",
      "created_at": "2017-02-23T15:33:11Z",
      "updated_at": "2017-02-23T15:33:11Z"
    },
    {
      "author": "msftgits",
      "author_association": "NONE",
      "body": "Hi, I am closing and re-opening this PR to bump the CLA bot. Sorry for the inconvenience!",
      "created_at": "2017-02-23T17:10:54Z",
      "updated_at": "2017-02-23T17:10:54Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "@iSazonov Thanks -- I wasn't sure what was going on there, but it seems to have worked now.",
      "created_at": "2017-02-23T19:19:01Z",
      "updated_at": "2017-02-23T19:19:01Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Isn't `Keyword` too common for base class? Maybe use `DSLKeyword`?",
      "created_at": "2017-02-28T18:09:16Z",
      "updated_at": "2017-02-28T18:09:16Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "@iSazonov I had the same thoughts, and would like to change it too. Only reason I didn't was that @PowerShell/powershell-committee didn't comment on it in their RFC review -- I left it with the thought that someone with a better knowledge of the codebase might have a better suggestion.\r\n\r\nI think `DslKeyword` seems as appropriate as anything else. I recall we rejected `PSKeyword` because it's inconsistent with other type and attribute names (namely Cmdlets). But whatever `Keyword` gets changed to, I think `KeywordAttribute`, `KeywordParameterAttribute` and `KeywordPropertyAttribute` should follow too. The shame is that `DynamicKeyword` is taken -- and that the `DynamicKeyword` class has a sort of uncertain role. In some respects it should be `KeywordInfo` or `DynamicKeywordInfo`, in other ways it behaves a little bit like what `Keyword` does, and then it holds all that parse state as a thread-static variable.\r\n\r\nI think if the change didn't break possible existing scripts that do things with the public (albeit obscure) API, along the lines of:\r\n```powershell\r\n$kw = [System.Management.Automation.Language.DynamicKeyword]::new()\r\n$kw.Keyword = \"MyKeyword\"\r\n...\r\n```\r\nthen the class would be a good candidate to split off into several smaller classes like:\r\n* `DynamicKeywordMetadata` -- the skeleton data of a `DynamicKeyword` before we load the assembly\r\n* `DynamicKeywordInfo` -- the loaded type information of a `DynamicKeyword` (encapsulating the above)\r\n* `DynamicKeyword` (in place of `Keyword`) -- the instantiated keyword, to work like `Cmdlet`\r\n* `DynamicKeywordParseState` -- like `SessionState`, but in the parser and specific to keywords",
      "created_at": "2017-02-28T21:29:20Z",
      "updated_at": "2017-02-28T22:25:32Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> then the class would be a good candidate to split off into several smaller classes like:\r\n\r\nVery tempting! I like it. If we try to do this it is necessary to consider that perhaps our DSC test suite is too small now.\r\n(Perhaps we should develop some DSL for tests when we shall have a working prototype. Or convert Pester to DSL - Pester guys can provide lots of useful comments.)",
      "created_at": "2017-03-03T19:46:48Z",
      "updated_at": "2017-03-03T19:54:35Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@rjmholt Is this PR still active or do you have a rough timeline for this? If so, can you please resolve the conflicts in the meantime? This fix would be very helpful to resolve [this](https://github.com/PowerShell/PSScriptAnalyzer/issues/850) parsing issue in PSScriptAnalyzer.",
      "created_at": "2018-02-18T17:51:06Z",
      "updated_at": "2018-02-18T18:03:02Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "@bergmeister  @rjmholt was an intern on my team at the time this PR was submitted and went back to finish school shortly after.  He's actually joining Microsoft as a full time employee on my team the first week of March.  @rjmholt should work with @daxian-dbw to determine if we should continue with this PR as-is.",
      "created_at": "2018-02-21T00:07:01Z",
      "updated_at": "2018-02-21T00:07:12Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@SteveL-MSFT Thanks for the update. Assuming that this gets fixed, would this also mean that if you published then new PowerShell referencing assemblies that tools such as PSSA using the AST parser could receive this fix to be able to parse types that are imported by `using` statements? I don't need a precise answer but would like to know if this is something that is technically feasible or would this scenario require more? Knowing this could help us make a decision whether we need to workaround this issue in PSSA or if we can wait for the parser improvements?",
      "created_at": "2018-02-21T20:26:51Z",
      "updated_at": "2018-02-21T20:27:18Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "@bergmeister PSSA still needs to support older version of PowerShell though?",
      "created_at": "2018-02-21T21:24:19Z",
      "updated_at": "2018-02-21T21:24:19Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@SteveL-MSFT Yes, but if I understand correctly, the referencing assemblies (containing the parser) are compiled into PSSA. Therefore my hope that updated reference assemblies would solve it. WDYT?",
      "created_at": "2018-02-21T21:28:41Z",
      "updated_at": "2018-02-21T21:28:41Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "@bergmeister I see, if it's only the reference assemblies and not the runtime assemblies (don't know enough about the internals of PSSA), it may work.  Since this work is not committed, my recommendation is to not build a dependency on it.",
      "created_at": "2018-02-22T18:50:26Z",
      "updated_at": "2018-02-22T18:50:26Z"
    },
    {
      "author": "lzybkr",
      "author_association": "MEMBER",
      "body": "@bergmeister - the reference assemblies contain no code - they are like a header file in C/C++ or an interface definition.\r\n\r\nIt does make sense to produce nuget packages for some of PowerShell like the parser, but it's a ton of work to factor things in a reasonable way to be useful.",
      "created_at": "2018-02-22T19:40:23Z",
      "updated_at": "2018-02-22T19:40:23Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "I've been meaning to close this PR. I'll revisit it later with @daxian-dbw , but the code is stale now and if we proceed with it, it's probably worth rewriting a fair amount of it.\r\n\r\nThere seems to be some interest in the feature though (#6194, #4016), so I would like to spend some more time on it.\r\n\r\n@bergmeister this PR is intended more to extend the `DynamicKeyword` feature than to fix anything. I read through the PSSA issue you linked, but not sure I fully understand the fix. It's possible a smaller fix could be implemented based on this PR (and also serve as an incremental step toward DSL support?).",
      "created_at": "2018-02-23T05:37:55Z",
      "updated_at": "2018-02-23T05:37:55Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "Ah, the other thing to note is that having tests for this feature is very painful so long as we require unloading the assemblies that describe the `DynamicKeyword`s. See [corefx #552](https://github.com/dotnet/coreclr/issues/552).",
      "created_at": "2018-02-23T05:45:18Z",
      "updated_at": "2018-02-23T05:45:18Z"
    },
    {
      "author": "SteveL-MSFT",
      "author_association": "MEMBER",
      "body": "@rjmholt I think a workaround to loaded assemblies is to start new pwsh processes",
      "created_at": "2018-02-23T21:16:26Z",
      "updated_at": "2018-02-23T21:16:26Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "It seems AppDomains come back in .Net Core 2.1?",
      "created_at": "2018-02-24T05:47:55Z",
      "updated_at": "2018-02-24T05:47:55Z"
    },
    {
      "author": "daxian-dbw",
      "author_association": "MEMBER",
      "body": "I have the changes in this PR rebased and moved to my fork at https://github.com/daxian-dbw/PowerShell/tree/dsl. It was rebased a while ago, but at least it was rebased to the point after we moved to msbuild. It won't be too much trouble to rebase it again.\r\n\r\nI have a separate branch `my-dsl` that contains some further improvement work I made on top of this PR, it's at https://github.com/daxian-dbw/PowerShell/tree/my-dsl. The work was not finished.",
      "created_at": "2018-02-27T00:50:20Z",
      "updated_at": "2018-02-27T00:50:20Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@lzybkr It turns out, PSScriptAnalyzer is not using the reference assemblies of PowerShell but has a self-contained copy of `System.Management.Automation.dll` and its dependencies and therefore the parser. I just made a proof of concept where I can parse the AST using `System.Management.Automation.Language.Parses.ParseInput(...)` on an Ubuntu VM in a .net core console app that does not have PowerShell installed but only the .net core runtime. The reason why this works is because we use an unofficial NuGet package of `6.0.0-alpha13` (because the official ones on Nuget are only full .net and not compatible with netcore2.0 or netstandard1.6) for getting `System.Management.Automation.dll` and its dependencies like `Microsoft.Management.Infrastructure`.\r\nUsing either the `System.Management.Automation` or `Microsoft.PowerShell.SDK` packages from `https://powershell.myget.org/F/powershell-core/api/v3/index.json` feed I could get the prototype to work as well but I need to do a PoC for PSSA to see which of the 2 are required for PSSA. What I am not sure about is whether we would need to do a dotnet publish to be sure that it really uses the nuget package and not the parser of PowerShell. It would be interesting if you could comment on the PR below.",
      "created_at": "2018-03-03T18:29:49Z",
      "updated_at": "2018-03-03T23:33:28Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "I've discussed this PR with @daxian-dbw, and it seems simpler to approach DSL support without metadata-parsing for now (e.g. using PowerShell classes as schemas). Implementation is not a priority currently though.\r\n\r\n@bergmeister: I know there's a use-case for [PSSA](https://github.com/PowerShell/PSScriptAnalyzer), but the implementation here was designed only to read DSL specifications and error on anything else. Possibly the parse-time assembly load meant that PSSA could discover types in `using` statements, but this is not desired behavior. The purpose of using the metadata reader was to prevent parse-time execution of static .NET code blocks (and to save us having to deal with the lack of AppDomains and assembly unloading in .NET Core, as well as a performance hit on module loading). Because of those properties in .NET Core, the general recommendation is to rely on the module manifest to provide the information. However, talking with @JamesWTruher, I can imagine there is a use case for PSSA to do its own metadata analysis to provide richer script analysis, and that could also pay dividends for things like completions. But I'm not sure there are good reasons for metadata parsing to be in PowerShell's engine itself.",
      "created_at": "2018-03-14T00:57:28Z",
      "updated_at": "2018-03-14T00:57:28Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@rjmholt Ok, I'll have to accept for now that this feature will not be implemented in PowerShell's parser. But what does the PowerShell team suggest to do for PSSA? PSSA depends on PowerShell's parser (it does not use the one being installed but has it's own version of it as part of a self-contained PSCore version of System.Management.Automation. Should PSSA then maintain its own customized fork of PowerShell in order to build and consume a custom parser? Catching the `ParseException` for TargetObject `TypeNotFound` and trying to remove the type name in memory might be a temporary workaround but is going to be hairy when using commands such as `Invoke-Formatter` or the `-Fix` switch, which actually manipulate the script content.",
      "created_at": "2018-03-14T22:02:02Z",
      "updated_at": "2018-03-14T22:02:32Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "@bergmeister We might be speaking at cross-purposes a little here -- essentially the fact that this prototype feature loaded modules at parse-time was something we don't want, because we don't want arbitrary code execution when we're just parsing PowerShell. It's one of the several reasons this PR was rejected. In fact, for PSSA to avoid executing malicious code by just parsing PowerShell, it will need to avoid module loading too.\r\n\r\nI'm not familiar at all with PSSA's codebase though, so I didn't quite understand where you talked about a `ParseException` and `Invoke-Formatter`. Could you give the links to where those occur in the PSSA code so I can take a look?\r\n\r\nIn terms of the parser, I think the System.Management.Automation.dll parser is definitely the one to use (even though it won't and shouldn't ever load a module in at parse time). **But**, the way I imagine it, PSSA could use the parser to get an AST as normal, and then extract any module-loading statements from that (maybe in [`AnalyzeSyntaxTree`](https://github.com/PowerShell/PSScriptAnalyzer/blob/2056fe0c63dc63dfac2cc18cb79b1373d7f5ec6f/Engine/ScriptAnalyzer.cs#L1999)), and use that information to go and look at that module. If it's a PowerShell module, then PSSA just runs the parser on it. If it's a DLL, then maybe a module manifest or possibly use a metadata reader to read the attributes.",
      "created_at": "2018-03-15T22:59:15Z",
      "updated_at": "2018-03-15T22:59:15Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@rjmholt Sorry for coming back to you later, I forgot about it. I understand and respect the decision that the PowerShell parser won't get those module loading features. In short PSSA is relying on the parser to analyse ASTs and calls `scriptAst = Parser.ParseFile(filePath, out scriptTokens, out errors);` [here ](https://github.com/PowerShell/PSScriptAnalyzer/blob/03ee3c434d25070e558fa2b1aa85f290c650534d/Engine/ScriptAnalyzer.cs#L1818)or `Parser.ParseInput(scriptDefinition, out scriptTokens, out errors);` [here](https://github.com/PowerShell/PSScriptAnalyzer/blob/development/Engine/ScriptAnalyzer.cs#L1517) initially to get the ASTs and then statically analyses them. If parsing fails, then PSSA cannot do its job for the whole file.\r\nSince a custom fork of the parser seems to be undesired for security reasons (although I think having a `-Force` switch to allow loading of dlls would be reasonable), I was thinking of trying to catch the parser errors and trying to replace the 'naughty' type definitions of the in-memory presentation (assuming it is possible to extract the exact error in a locale independent way) of the script to make it parse-able. There are some special features like `Invoke-Formatter` or `Invoke-ScriptAnalyzer -Fix` that take either a string of the script or a path to the script file and outputs them with some rules being auto-fixed (this is how formatting of selected code using Ctrl+K+F works in VSCode btw). Therefore you can see that using a workaround of removing the type strings introduces the complexity of having to add them back in when outputting the script.\r\nMaybe I am missing something but it would be great it the PowerShell team could provide some suggestions on how to better handle scripts that are not parseable.",
      "created_at": "2018-03-29T21:13:56Z",
      "updated_at": "2018-03-29T21:37:03Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "Hmmm, do you know what error the parser throws when a type is used that isn't loaded. Philosophically, the parser shouldn't be looking up types at all. You should be able to use a string that is totally meaningless as long as it is syntactically representative of a type (`[Foo.Quux]::Banana()`) and get an AST. If there are some kind of type lookups or semantic checks happening earlier than I would expect and causing an error, then our path forward could be complicated. /cc @daxian-dbw",
      "created_at": "2018-03-29T21:22:45Z",
      "updated_at": "2018-03-29T21:22:45Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@rjmholt  An example is\r\n````powershell\r\nusing namespace Microsoft.Azure.Commands.ResourceManager.Cmdlets.SdkModels\r\nusing namespace Microsoft.Azure.Commands.Common.Authentication.Abstractions\r\nImport-Module \"AzureRm\"\r\nclass MyClass { [IStorageContext]$StorageContext }\r\n````\r\nWe get the parse error `Unable to find type [IStorageContext] at line 4 column 18.`. If the parser supported using unknown types like `[Foo.Banana]` (maybe using a different mode/overload), etc then this would solve the issue for PSSA.",
      "created_at": "2018-03-29T21:31:19Z",
      "updated_at": "2018-03-29T21:42:24Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "Immediately after writing that last comment I went and tracked down [the issue the code above comes from](https://github.com/PowerShell/PSScriptAnalyzer/issues/850), because I remembered it being the problematic code in question. Which then brought me to [this issue](https://github.com/PowerShell/PowerShell/issues/2074), and then [this issue](https://github.com/PowerShell/PowerShell/issues/3641) which really documents what's going on. And then I spent a fair amount of time thinking about this.\r\n\r\nFor whatever reason I didn't understand that it was PowerShell that was producing the error here, just because I didn't think it would be trying to resolve types at parse time. I've heard before that it's to do with being able to integrate with .NET types (although I'm not sure why `Add-Type` works in that case then). But long story short, I owe you an apology on that one @bergmeister.\r\n\r\nBut to summarise, here are some dot points (most of which I imagine are already well known to @bergmeister , but I document here anyway):\r\n* Type resolution within PowerShell classes and their members occurs at *parse* time, meaning that runtime type loading that occurs in `Add-Type` and `Import-Module` won't work for classes; even though the statements might come before the classes that use the types, they can't execute until after the class is parsed and the check fails.\r\n* This means that PSSA is quite correct when it says there's an error there -- those scripts won't run unless the type is loaded at parse time. Which means users should be loading them before running PSSA too.\r\n* @bergmeister is quite right that there is an unfinished feature in the `using assembly` statement, where we should offer parse-time type loading for classes. However, loading an assembly the normal way here would give an entry point for arbitrary code execution at parse time (when we'd like to keep script analysis and AST generation pure and safe operations).\r\n* As far as I know, the only alternative is to do metadata parsing by hand, which is a very sizeable implementation task in terms of handling arbitrary .NET types. To be clear, the work in this PR is only looking for specific attributes on types and then ignores everything else. I think there could be a lot more work required to do something like build an arbitrary `TypeInfo` or something like that.\r\n* But changing any of the parse-time class type resolution behaviour would also be an unfeasible change for PowerShell.\r\n\r\nThe idea that a PowerShell script's AST/parse could be valid or invalid based on the environment its parsed in doesn't really sit well with me, but I'm sure there were good reasons for going that way. It looks like maybe we should implement the metadata reading, but the performance cost could be considerable, especially for complex webs of inter-referenced assemblies.\r\n\r\nAnyway, PSSA is correctly reporting that PowerShell won't run the script under normal circumstances. And in this case, I think you still get a fully-formed AST (you just also get an error). You can try this:\r\n\r\n```powershell\r\n$file = \"$PWD\\ex.ps1\"\r\n\r\n$problem = @'\r\nusing namespace Microsoft.Azure.Commands.ResourceManager.Cmdlets.SdkModels\r\nusing namespace Microsoft.Azure.Commands.Common.Authentication.Abstractions\r\nImport-Module \"AzureRm\"\r\nclass MyClass { [IStorageContext]$StorageContext }\r\n'@\r\n\r\nSet-Content -Path $file -Value $problem\r\n\r\n$tokens = @()\r\n$errors = @()\r\n\r\n$ast = [System.Management.Automation.Language.Parser]::ParseFile($file, [ref]$tokens, [ref]$errors)\r\n\r\n$ast.EndBlock.Statements[1].Members[0].PropertyType\r\n```\r\nA complete, well-formed AST is still given back, it's just that the error array is not empty.",
      "created_at": "2018-03-31T01:39:51Z",
      "updated_at": "2018-03-31T01:39:51Z"
    },
    {
      "author": "bergmeister",
      "author_association": "CONTRIBUTOR",
      "body": "@rjmholt Thank you very much for putting so much thought into it. I did not know that the Parser can still continue and return an AST despite parse errors. Because PSSA throws on any parse errors, I made the wrong assumption that parsing cannot continue at all after a parse error. This will help PSSA very much because it can then simply ignore/remove `TypeNotFound` parse errors and continue. I had not clue it could be that simple, thank you very much. :-)",
      "created_at": "2018-03-31T16:43:54Z",
      "updated_at": "2018-03-31T16:43:54Z"
    },
    {
      "author": "rjmholt",
      "author_association": "COLLABORATOR",
      "body": "Well the parser is designed (to my knowledge) not to throw at all, since it's trying to be helpful about errors. So it just collects errors and keeps parsing. If the parser actually throws, it's because something very bad has happened that it can't recover from. But otherwise it will try and make the most sense that it can and keep parsing. Even in cases where there's some malformed syntax, you will still get an AST, but it will contain [error ASTs](https://github.com/PowerShell/PowerShell/blob/404e876740aa65b1bdd17ce614060eb88e3e7da9/src/System.Management.Automation/engine/parser/ast.cs#L427) where bad script was, up until the point where the parser can understand what's going on again.",
      "created_at": "2018-03-31T16:53:33Z",
      "updated_at": "2018-03-31T16:53:33Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I can add that the parser even tries to perform some recovery to continue the correct parsing after an error. If the parser does it wrong then this is a reason to open a issue.",
      "created_at": "2018-03-31T18:47:21Z",
      "updated_at": "2018-03-31T18:47:21Z"
    }
  ],
  "created_at": "2017-02-18T02:49:58Z",
  "number": 3169,
  "state": "closed",
  "title": "Dynamic keyword metadata reader",
  "updated_at": "2018-03-31T18:47:21Z"
}