{
  "_url": "https://github.com/PowerShell/PowerShell/issues/9091",
  "author": "SytzeAndr",
  "body": "<!-- Anything that looks like this is a comment and can't be seen after the Pull Request is created. -->\r\n\r\n# PR Summary\r\nThe old implementation used a for loop with lots of if statements to parse a csv string, which is used in the `import-alias` cmdlet. I think the old implementation is bug sensitive and hard to read. A new implementation can have a reduced complexity and uses the `StringReader` and `StringBuilder` to convert a string in csv format to a collection of elements, while keeping functionality intact. Experimental analysis shows this new implementation performs better, especially for large Strings.\r\n\r\n## PR Checklist\r\n\r\n- [x] [PR has a meaningful title](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n    - Use the present tense and imperative mood when describing your changes\r\n- [x] [Summarized changes](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [x] [Change is not breaking](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#making-breaking-changes)\r\n- [x] [Make sure all `.h`, `.cpp`, `.cs`, `.ps1` and `.psm1` files have the correct copyright header](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n- [x] This PR is ready to merge and is not [Work in Progress](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---work-in-progress).\r\n    - If the PR is work in progress, please add the prefix `WIP:` or `[ WIP ]` to the beginning of the title (the `WIP` bot will keep its status check at `Pending` while the prefix is present) and remove the prefix when the PR is ready.\r\n- **User-facing changes**\r\n    - [x] Not Applicable\r\n    - **OR**\r\n    - [ ] [Documentation needed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#pull-request---submission)\r\n        - [ ] Issue filed: <!-- Number/link of that issue here -->\r\n- **Testing - New and feature**\r\n    - [ ] N/A or can only be tested interactively\r\n    - **OR**\r\n    - [ ] [Make sure you've added a new test if existing tests do not effectively test the code changed](https://github.com/PowerShell/PowerShell/blob/master/.github/CONTRIBUTING.md#before-submitting)\r\n        - [ ] [Add `[feature]` to your commit messages if the change is significant or affects feature tests](https://github.com/PowerShell/PowerShell/blob/master/docs/testing-guidelines/testing-guidelines.md#requesting-additional-tests-for-a-pr)\r\n",
  "closed_at": "2020-05-27T06:32:44Z",
  "comments": [
    {
      "author": "msftclas",
      "author_association": "NONE",
      "body": "[![CLA assistant check](https://cla.opensource.microsoft.com/pull/badge/signed)](https://cla.opensource.microsoft.com/PowerShell/PowerShell?pullRequest=9091) <br/>All CLA requirements met.",
      "created_at": "2019-03-08T18:49:33Z",
      "updated_at": "2019-03-08T18:56:33Z"
    },
    {
      "author": "vexx32",
      "author_association": "COLLABORATOR",
      "body": "@SytzeAndr the `#` case is for when the CSV contains a type hint like it used to in Windows PowerShell -- CSVs generated without the `-NoTypeInformation` would have a one-line header with something like this:\r\n```\r\nPS Z:\\> [pscustomobject]@{a = 1} | ConvertTo-Csv\r\n#TYPE System.Management.Automation.PSCustomObject\r\n\"a\"\r\n\"1\"\r\n```",
      "created_at": "2019-03-08T19:07:53Z",
      "updated_at": "2019-03-08T19:07:53Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "> @SytzeAndr the `#` case is for when the CSV contains a type hint like it used to in Windows PowerShell -- CSVs generated without the `-NoTypeInformation` would have a one-line header with something like this:\r\n> \r\n> ```\r\n> PS Z:\\> [pscustomobject]@{a = 1} | ConvertTo-Csv\r\n> #TYPE System.Management.Automation.PSCustomObject\r\n> \"a\"\r\n> \"1\"\r\n> ```\r\n\r\nThanks for the comment, I'll then reuse the part from the old implementation for when to return an empty collection.",
      "created_at": "2019-03-08T19:20:10Z",
      "updated_at": "2019-03-08T19:20:37Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@SytzeAndr Thanks for your contribution!\r\n\r\nWe are working on enhancing the cmdlet and have plans to improve performance.\r\nI am concerned that your change affects performance and adds extra allocations. Did you measure?",
      "created_at": "2019-03-09T04:39:10Z",
      "updated_at": "2019-03-09T04:39:10Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov I haven't tested it yet, but performance is one of the reasons I think refactoring this code would make sense. <s>The old implementation is synchronous, but it should be possible to make this an asynchronous process instead of iterating over all the characters which should be faster.</s> (edit: I realized this is only possible if the order in which the elements are in result is not important)\r\n\r\nI haven't set up the testing environment locally (so therefore WIP), but when I do and the tests are passing I'll do a measure in terms of performance against the old implementation aswell. ",
      "created_at": "2019-03-09T16:20:28Z",
      "updated_at": "2019-03-13T16:32:36Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "Are you aware that this method is only called from the `Import-Alias` cmdlet?\r\n\r\nThe implementation of `Import-Csv` is in the file CSVCommands.cs, and the bulk of the work is done in the ImportCsvHelper class. That said, almost all of the cost of this operation is in creating the resulting objects. IIRC, the stream parsing was below 5%. And while the first rule of performance is to measure, in this case I would venture to speak from experience and say that using Regex is not the way to improve the performance.",
      "created_at": "2019-03-09T17:57:46Z",
      "updated_at": "2019-03-09T17:57:46Z"
    },
    {
      "author": "powercode",
      "author_association": "COLLABORATOR",
      "body": "@SytzeAndr If you want to improve performance, I would suggest a different approach. Start with a scenario you know is slow. Then run it under a profiler, and try to understand if there are any bottlenecks.\r\n\r\nThen try to understand the code around the bottleneck - think about it, why is it written the way it is, how could it be done instead etc. Keep recordings of the original scenario. Try out changes, and measure them, while at the same time making sure that the tests that covers your changes still passes.\r\n\r\nThe area you have selected here is very hard to improve significantly upon, especially since it is not in the hot path.",
      "created_at": "2019-03-09T18:17:31Z",
      "updated_at": "2019-03-09T18:17:31Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "some updates on this PR:\r\n\r\nI've implemented the method by using the StringReader and StringBuilder. It currently passes all CI tests, so I assume my implementation is fine.\r\n\r\nI assume use of the [Stringbuilder](\r\nhttps://docs.microsoft.com/en-us/dotnet/api/system.text.stringbuilder?view=netcore-2.2) has a positive impact on performance since the `string` class builds a new string at each operation while the stringbuilder maintains it. \r\n\r\nI've reduced the complexity of this method according to CodeFactor (and is regarded as being a fixed issue to the repo). Although I still think it can be improved by splitting some things and might do so.\r\n\r\n@powercode I used this PR aswell to get a bit used to contributing to powershell, and I chose to tackle an issue which could be fixed with some refactoring. Therefore, I didn't start with analyzing the bottlenecks since I had to set up things yet and wanted to start small by just refactoring some code. I agree with you in the sense that it would make more sense to analyze from a bit higher perspective to find the true bottlenecks. \r\n\r\nSo the next step for me is to test it for performance against the old implementation, after that I'll remove the WIP tag (assuming performance is not worse). \r\nIs there some simple way of checking the performance/runtime by checking the CI runtime results for different branches, or is it better to do some local performance-based-tests myself of the different implementations and report them here?",
      "created_at": "2019-03-12T18:57:14Z",
      "updated_at": "2019-03-12T19:10:53Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "@Geweldig makes sense, thanks for the suggestions!",
      "created_at": "2019-03-13T09:47:18Z",
      "updated_at": "2019-03-13T09:47:18Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "I did some test and the performance seems to be improved, especially for large strings. I took the largest csv file from [here](https://sample-videos.com/download-sample-csv.php) called SampleCSVFile_53000kb.csv which contained 500.000 rows and is 53kb large. Then, I created some other very small csv file `very_small.csv` with the content `this, is, a, \"very\", small, file`. I did an experiment 100.000 times for the small file, and 100 times for the large file. The log is below.\r\n\r\nFor the large file, the performance seems to be twice as good (70s to 35s). For the small file, the performance is better, but not significantly (11.1s to 10.8s).\r\n\r\nI'll remove the WIP tag and have this open for review.\r\n\r\n```\r\nfile:csv_files/SampleCSVFile_53000kb.csv\r\niterations:100\r\nuseold:True\r\ntime elapsed:74262ms\r\n\r\nfile:csv_files/SampleCSVFile_53000kb.csv\r\niterations:100\r\nversion:False\r\ntime elapsed:35953ms\r\n\r\nfile:csv_files/very_small.csv\r\niterations:100000\r\nuseold:True\r\ntime elapsed:11080ms\r\n\r\nfile:csv_files/very_small.csv\r\niterations:100000\r\nversion:False\r\ntime elapsed:10759ms\r\n````",
      "created_at": "2019-03-13T12:01:07Z",
      "updated_at": "2019-03-13T12:01:07Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@SytzeAndr Can you share the test script?",
      "created_at": "2019-03-13T12:15:23Z",
      "updated_at": "2019-03-13T12:15:23Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "I used the following script. `CSVHelper` corresponds to my implementation, for `Csv_old` I copied code of the old implementation.\r\n\r\n```\r\nusing System;\r\nusing Microsoft.PowerShell.Commands;\r\nusing System.IO;\r\nusing System.Diagnostics;\r\n\r\nnamespace csv_helper_new\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            bool useold = true;\r\n            //args are files to read\r\n            int iterations = 100;\r\n            Stopwatch stopwatch = new Stopwatch();\r\n            foreach (String a in args) {\r\n                stopwatch.Reset();\r\n                Console.WriteLine(\"file:\"+a+\"\\n\"+\"iterations:\"+iterations+\"\\nuseold:\"+useold);\r\n                stopwatch.Start();\r\n                for (int i=0;i<iterations;i++) {\r\n                    if (useold) {\r\n                        Csv_old cSVHelper = new Csv_old(',');\r\n                        cSVHelper.ParseCsv(File.ReadAllText(a)).ToString();\r\n                    } else {\r\n                        CSVHelper cSVHelper = new CSVHelper(',');\r\n                        cSVHelper.ParseCsv(File.ReadAllText(a)).ToString();\r\n                    }\r\n                }\r\n                stopwatch.Stop();\r\n                Console.WriteLine(\"time elapsed:\"+stopwatch.ElapsedTicks/1000+\"ms\");\r\n            }            \r\n        }\r\n    }\r\n}\r\n```",
      "created_at": "2019-03-13T13:08:52Z",
      "updated_at": "2019-03-13T13:08:52Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@SytzeAndr Please clarify what do you want make faster? The `ParseCsv()` method is only used in Import-Alias cmdlet - do you really want to improve the cmdlet?",
      "created_at": "2019-03-13T13:22:53Z",
      "updated_at": "2019-03-13T13:22:53Z"
    },
    {
      "author": "LMiljak",
      "author_association": "NONE",
      "body": "I think the main goal of this PR is to have the original code refactored (as the complexity of the method was quite high), without sacrificing performance. Making it faster was not necessarily the goal.\r\nBut I can't speak for @SytzeAndr.",
      "created_at": "2019-03-13T13:44:16Z",
      "updated_at": "2019-03-13T13:44:36Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov I wanted to improve code quality since I found the method hard to read without affecting performance in a negative way. Since you commented\r\n\r\n> I am concerned that your change affects performance and adds extra allocations. Did you measure?\r\n\r\nI decided to do experimental analysis, for both a very large and small string, to show that the new implementation is not worse, and concluded it performs better. A bad performance of the `import-alias` cmdlet is not the reason for the PR, but a bad performance should not occur due to some PR.",
      "created_at": "2019-03-13T13:45:26Z",
      "updated_at": "2019-03-13T13:45:26Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I respect your efforts. Nevertheless, they are too wasteful. This code is very rarely used and only for importing a few aliases. Therefore, your tests for large files are useless.\r\n\r\nI will continue to review the code without these performance considerations. Please update the PR description.",
      "created_at": "2019-03-13T14:17:14Z",
      "updated_at": "2019-03-13T14:17:14Z"
    },
    {
      "author": "daxian-dbw",
      "author_association": "MEMBER",
      "body": "I believe adopting and reusing the `StringBuilder` is the right thing to do, but I don't think the `StringReader` will do you any benefit in perf because you are essentially replacing the direct array indexing (`csv[i]`) with method calls (`reader.Peek` and `reader.Read`), which is more expensive.\r\n\r\nHow about just refactoring on top of the existing code instead of writing new code? For example, replace the `switch` statement with `if/else`; restructure the `case '\"'` block to reduce the nested blocks; adopting `StringBuilder` like you already do. The existing code can be changed to something like the following, then we can add comments to make it more readable.\r\n```\r\n            bool inQuotes = false;\r\n            for (int i = 0; i < csv.Length; i++)\r\n            {\r\n                char ch = csv[i];\r\n                if (ch == Delimiter)\r\n                {\r\n                    if (inQuotes)\r\n                    {\r\n                        wordBuffer.Append(ch);\r\n                    }\r\n                    else\r\n                    {\r\n                        result.Add(wordBuffer.ToString());\r\n                        wordBuffer.Clear();\r\n                    }\r\n                }\r\n                else if (ch == '\"')\r\n                {\r\n                    if (!inQuotes)\r\n                    {\r\n                        // Comments to be added\r\n                        inQuotes = true;\r\n                        continue;\r\n                    }\r\n\r\n                    if (i < csv.Length - 1 && csv[i+1] == '\"')\r\n                    {\r\n                        // Comments to be added\r\n                        wordBuffer.Append('\"');\r\n                        i++;\r\n                    }\r\n                    else\r\n                    {\r\n                        // Comments maybe?\r\n                        inQuotes = false;\r\n                    }\r\n                }\r\n                else\r\n                {\r\n                    wordBuffer.Append(ch);\r\n                }\r\n            }\r\n\r\n            if (wordBuffer.Length > 0)\r\n            {\r\n                result.Add(wordBuffer.ToString());\r\n            }\r\n```",
      "created_at": "2019-03-14T02:38:32Z",
      "updated_at": "2019-03-17T18:50:13Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "@daxian-dbw I like the use of a `reader` instead of array indices, since then the flow becomes less based on values and more on logical statements, which I think is easier to read, easier to extend and results in cleaner code, since it is more restricted and less interpretations are possible. \r\n\r\nI don't think the `peek` and `read` differ that much in performance with respect to direct array index accessing. Readers are made to read lines and characters one-by-one from a String or file and contains some optimized code to do this efficiently. I'm not sure about the reader implementation and can't really back this up, but I do believe `read` will be compiled to something that corresponds with a simple index lookup. \r\n\r\nThen again, as @iSazonov commented, the performance should not really be an issue, \r\n\r\n> This code is very rarely used and only for importing a few aliases. \r\n\r\nSo if it makes a tiny performance boost with the cost of maintainability, I would prefer the better maintainable version, \r\n\r\nAs far as I can see, the method complexity per character read (the different paths per character read which can occur) of your implementation is at 7 (2+4+1 paths). The reader implementation has a complexity of 4 (1 + 2 + 1). \r\n\r\nAlthough I prefer the reader implementation, this might be a matter of opinion, and if the community prefers the `for` loop I'm fine with implementing a `for` loop based implementation. I think the question is whether we agree the `reader` is better maintainable or not.",
      "created_at": "2019-03-17T16:10:20Z",
      "updated_at": "2019-03-17T18:52:25Z"
    },
    {
      "author": "daxian-dbw",
      "author_association": "MEMBER",
      "body": "> your implementation is at 7 (2+4+1 paths). The reader implementation has a complexity of 4 (1 + 2 + 1).\r\n\r\nYou current implementation doesn't handle `\"abc\"\"def\"` correctly. This should be parsed to `abc\"def`, but your implementation will parse it to `abcdef`.\r\nYou will need to add 1 or 2 more `if` checks within `if (nextChar == '\"')` to fix your current implementation.\r\nThe sample code I pasted above can be easily changed to use 6 `if` paths altogether (already updated). So there is no much difference if you define maintainability as the number of code paths.\r\n\r\nIMHO, the switch statement used in the original implementation and the nested `if` blocks due to the switch is the root cause of bad readability/maintainability, not the fact that it's using array indexing.",
      "created_at": "2019-03-17T19:04:28Z",
      "updated_at": "2019-03-17T19:05:49Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "I've added an implementation which should resolve the issue regarding parsing `\"abc\"\"def\"`. @daxian-dbw what do you think, should I implement tests?",
      "created_at": "2019-03-18T01:29:17Z",
      "updated_at": "2019-03-18T01:29:17Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> should I implement tests?\r\n\r\nYes, we should cover all code by tests.",
      "created_at": "2019-03-18T04:01:01Z",
      "updated_at": "2019-03-18T04:01:01Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> I like the use of a reader instead of array indices\r\n\r\nI think StringReader complicates the code and doesn't add readability. Using StringReader looks like personal preference.",
      "created_at": "2019-03-18T04:11:23Z",
      "updated_at": "2019-03-18T04:11:23Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "Since the `csv.cs` is only called in `GetAliasesFromFile()` in `importAliasCommand.cs`, I'm thinking of refactoring `GetAliasesFromFile()`, which I think can be done in a way in which we don't need the seperate `csv.cs` file. \r\n\r\nIt seems `GetAliasesFromFile()` uses readers. This makes sense as a `reader` is able to read a line from a file faster than a `for` loop would be able to. I would say it makes more sense to use a reader as well for the individual line parsing, for the sake of consistency throughout the method. However, according to the discussion on this Pull Requests, using indices are preferred over readers. As I said before, I'm fine with implementing indices instead if that is preferred, but I do want that then we will be mixing two ways of reading which might be more confusing than to use the `reader` for all reading in the method. For now I will assume we prefer to use indices for parsing the individual lines.\r\n\r\nBefore I start with the actual implementation, I want to know if I'm on the same line as the community by asking if we agree on the following, to prevent working on something which is not according to the standards and guidelines used by PowerShell.\r\n\r\n* I want to get rid of having the file called `csv.cs` given its current functionality. I think it is confusing at is is not handling all the csv parsing within PowerShell but does have a very general name. \r\n* Creating the csv file can be called statically. There is no need to create a CSVhelper object to parse a line in the current implementation.\r\n* A check to Ignore blank lines and comment lines is performed in both CSVhelper and `GetAliasesFromFile()` and could be merged such that there's a single point in the code where this violation is checked.\r\n* `GetAliasesFromFile()` is too long and complex and can be split up. Functions can be created for the subprocesses (such as creating the options, creating the alias, checking for violation), such that we reduce complexity and it becomes easier to understand what the code does.\r\n* the error handling is all over the place and could be replaced by a try catch to keep it centralized and to keep it easy to read what the different error outcomes are and how these are handled.\r\n\r\nAs a start, I've spent some time to make some pseudo-ish-code based on the current implementation of what I think is a refactor that makes more sense while keeping the functionality intact. If we agree, I'd like to hear if you want me to open a new one or that I should keep working within this PR since it is all related.\r\n\r\n```\r\nGetAliasesFromFile() {\r\n    result = new collection()\r\n    // linenumber is used for error handling\r\n    Int lineNumber = 0;\r\n\r\n    using (StreamReader reader = OpenFile(out filePath, isLiteralPath)) {\r\n    \tlinenumber = 0\r\n   \t\r\n        while ((line = reader.ReadLine()) != null) {\r\n        \t++lineNumber\r\n        \ttry {\r\n        \t\t// parse the line, throw exception if invalid\r\n\t\t        parsedLine = parseLine(line)\r\n\r\n\t\t\t// check for any further violations which is able to throw an exception\r\n\t\t\t\r\n\t\t\tisValidParsedLine(parsedLine)\r\n\r\n\t\t\t// if valid add to results\r\n\t    \t\tresult.add(constructAlias(parsedLine))\r\n\t    \t} \r\n\t    \tcatch (InvalidLineException e ) {\r\n\t    \t\t// for some cases, like blank line or commented line, we should do nothing and just skip the line\r\n\t\t    } \r\n\t\t    catch (ArgumentException e) {\r\n\t\t    \t// ArgumentException can happen when the options object cannot be created\r\n\t\t    \t// we should write an error, create no alias and continue\r\n\t\t    } \r\n\t\t    catch (NoFourValuesException e) {\r\n\t\t    \t// if not four values, do ThrowTerminatingError(errorRecord) just like old code\r\n\t\t    \t// code below is copy pasted from importAliasCommand.cs\r\n\t\t    \tstring message = StringUtil.Format(AliasCommandStrings.ImportAliasFileInvalidFormat, filePath, lineNumber);\r\n\r\n\t\t        FormatException formatException =\r\n\t\t            new FormatException(message);\r\n\r\n\t\t        ErrorRecord errorRecord =\r\n\t\t            new ErrorRecord(\r\n\t\t                formatException,\r\n\t\t                \"ImportAliasFileFormatError\",\r\n\t\t                ErrorCategory.ReadError,\r\n\t\t                filePath);\r\n\r\n\t\t        errorRecord.ErrorDetails = new ErrorDetails(message)\r\n\t\t\tThrowTerminatingError(errorRecord)\r\n\t\t    }\t\t       \t\r\n        }\t\r\n    }\r\n    return result\r\n}\r\n\r\n\r\n// this method should correspond with the ParseCsv method in Csv.cs\r\nparseLine(line) {\r\n\tif (line.Length == 0 || OnlyContainsWhitespace(line) || line[0] == '#') {\r\n\t\tthrow new InvalidLineException()\r\n\t}\r\n\t// do the line parsing as implemented in CSVHelper.cs\r\n\t...\r\n\t...\r\n\t// return a collection representing the csv string that is parsed\r\n\treturn result\r\n}\r\n\r\nconstructAlias(parsedLine) throws argException {\r\n\t// create options out of parsed line i.e. a collection object. This might throw an exception\r\n\toptions = (ScopedItemOptions)Enum.Parse(typeof(ScopedItemOptions), values[3], true);\r\n\r\n\t// add description (which is the second term of parsedLine) if not null or empty, just like old code\r\n\r\n\tif (!string.IsNullOrEmpty(values[2]))\r\n        {\r\n            newAlias.Description = values[2];\r\n        }\r\n\r\n\t// create and return the the actual alias object\r\n\treturn new AliasInfo(parsedLine, options)\r\n}\r\n\r\n// note: I could migrate this violation into parseCSVLine, but then the method would become less general and needs to be renamed.\r\nisValidParsedLine(parsedLine) {\r\n\tif(parsedLine.count != 4) {\r\n\t    throw NoFourValuesException()\r\n\t}\r\n}\r\n```\r\n\r\n",
      "created_at": "2019-03-19T19:42:03Z",
      "updated_at": "2019-03-19T23:35:03Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "I wonder that you are going to refactor this old and _very rarely_ used code, but it is permissible for   community project and I will be happy to help you.\r\n\r\nFirst we need to make sure that this code is fully covered with tests and add new tests in another PR if needed.\r\nRemember that our basic rules are to keep PRs as small as possible and split style and functional changes.\r\n\r\nWe could consider using code from CSVCommand.cs to parse csv and then remove the parser from csv.cs at all. I don\u2019t like to just rename the file because it violates history.\r\nUsing static and indexers is good I believe.\r\nWe should avoid throws if possible.",
      "created_at": "2019-03-20T06:08:47Z",
      "updated_at": "2019-03-20T06:08:47Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov thanks for your comment and nice to hear it is a permissible community project. So I assume the order would then be to first make tests in a seperate PR (since we have found out the existing tests are not sufficient) and then open up this PR, including the refactorization as I described in my earlier comment.\r\n\r\n> I wonder that you are going to refactor this old and very rarely used code\r\n\r\nI'm curious about the motive of this statement. Since PowerShell embraces backwards compatibility (so regardless of how rarely a feature is used, it should always be in any newer version) we should include old functionality and thus any piece of code can only be replaced with a newer version: there is no discard option. If we consider code to be messy, it will therefore stay messy forever if we don't see the point of cleaning it up. Shouldn't the 'backwards-compatibility' be a motive to refactor any old code if possible, even if it is very rarely used?\r\n\r\n> We should avoid throws if possible\r\n\r\nThe [code guidelines](https://github.com/PowerShell/PowerShell/blob/master/docs/dev-process/coding-guidelines.md) writes the following about throws:\r\n\r\n> Avoid gratuitous exceptions as much as possible. Exception handling can be expensive due to cache misses and page faults when accessing the handling code and data. Finding and designing away exception-heavy code can result in a decent performance win. For example, you should stay away from things like using exceptions for control flow.\r\n\r\nThere are throws in the code already and IMO it makes an easy to read implementation and reduces complexity. I don't think an implementation based on my pseudocode will hurt performance in a significant bad way (besides, it is used rarely) and testing can be done a lot easier. Do you consider the implementation to be \"gratuitous\" exceptions? Because if so I'll go for a different approach.\r\n\r\n> We could consider using code from CSVCommand.cs to parse csv and then remove the parser from csv.cs at all. I don\u2019t like to just rename the file because it violates history.\r\n\r\nI also prefer to remove the parser from `csv.cs` and move/combine all functionality within `CSVCommands.cs`. At the moment the only method in `csv.cs` is the string-parser. If we remove this, there is nothing in `csv.cs` whatsoever. I suggest we will then delete `csv.cs` since the name is confusing.\r\n\r\nAlso, I'm planning to work on this PR the next few days, so I hope I can show you something nice by the end of this week.",
      "created_at": "2019-03-26T17:57:32Z",
      "updated_at": "2019-03-26T20:09:37Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "> Do you consider the implementation to be \"gratuitous\" exceptions? Because if so I'll go for a different approach.\r\n\r\nPlease try to do not use throw in hot paths.\r\n\r\nAlso keep PR as small as possible for fast review.",
      "created_at": "2019-03-27T06:38:22Z",
      "updated_at": "2019-03-27T06:38:22Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "I've added tests in a seperate PR #9247. @iSazonov would you mind taking a look?",
      "created_at": "2019-03-29T15:52:49Z",
      "updated_at": "2019-03-29T15:52:49Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "I've created new pseudocode. I've stepped away from exception throwing and replaced it with functions that checks the validity of the parsed and unparsed line. \r\n\r\n```\r\nGetAliasesFromFile() {\r\n    result = new collection()\r\n    // linenumber is used for error handling\r\n    Int lineNumber = 0;\r\n\r\n    using (StreamReader reader = OpenFile(out filePath, isLiteralPath)) {\r\n        linenumber = 0\r\n       \r\n        while ((line = reader.ReadLine()) != null) {\r\n            ++lineNumber\r\n\r\n            // skip line if it meets some conditions\r\n            if(lineShouldBeSkipped(line)) {\r\n                continue\r\n            }\r\n            \r\n            parsedLine = parseLine(line)\r\n\r\n            // if result is valid add to results\r\n            if(isValidParsedLine(parsedLine)) {            \r\n                result.add(constructAlias(parsedLine))\r\n            }\r\n        }    \r\n    }\r\n    return result\r\n}\r\n\r\n\r\n// this method should correspond with the ParseCsv method in Csv.cs\r\nparseLine(line) {\r\n    // do the line parsing as implemented in CSVHelper.cs\r\n    ...\r\n    ...\r\n    // return a collection representing the csv string that is parsed\r\n    return result\r\n}\r\n\r\nconstructAlias(parsedLine) throws argException {\r\n    // create options out of parsed line i.e. a collection object. This might throw an exception\r\n    options = (ScopedItemOptions)Enum.Parse(typeof(ScopedItemOptions), values[3], true);\r\n\r\n    // add description (which is the second term of parsedLine) if not null or empty, just like old code\r\n\r\n    if (!string.IsNullOrEmpty(values[2]))\r\n        {\r\n            newAlias.Description = values[2];\r\n        }\r\n\r\n    // create and return the the actual alias object\r\n    return new AliasInfo(parsedLine, options)\r\n}\r\n\r\nlineShouldBeSkipped(line) {\r\n    //if line is empty or a comment, return true\r\n    return line.Length == 0 || OnlyContainsWhitespace(line) || line[0] == '#'\r\n}\r\n\r\nisValidParsedLine(parsedLine) {\r\n    // if options object cannot be created\r\n    if(optiongoeswrong) {\r\n        //write an error, create no alias and continue\r\n        ...\r\n        return false\r\n    }\r\n\r\n    if(values != 4) {\r\n        // if not four values, do ThrowTerminatingError(errorRecord) with ImportAliasFileFormatError, just like old implementation\r\n    }\r\n\r\n    return true\r\n}\r\n```",
      "created_at": "2019-03-31T13:32:06Z",
      "updated_at": "2019-03-31T13:33:40Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "Tests are passing. \r\n\r\nCodeFactor is complaining about hungarian notation naming (I used `is` and `in` for naming), but since the rules will be changing soon I don't know if that needs to be fixed or not.\r\n\r\nCodeQuality wants some of the methods in `ImportAliasCommand.cs` to be static, but some of the mentions can't easily be called statically, like `isValidParsedLine` which used the method `ThrowTerminatingError` which is not a static method. I therefore only resolved part of the codequality suggestions. Let me know if this needs to be fixed or that it's fine at the moment.",
      "created_at": "2019-04-10T19:24:15Z",
      "updated_at": "2019-04-10T20:00:32Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "@SytzeAndr No need to fix this style issues.",
      "created_at": "2019-04-11T03:39:03Z",
      "updated_at": "2019-04-11T03:39:03Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "Can I get a new review then?",
      "created_at": "2019-04-21T10:51:28Z",
      "updated_at": "2019-04-21T10:51:28Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "Sorry for the delay. I managed to get rid of the `try/catch` and `KeyValuePair` in `CreateItemOptions`. Tests are passing locally. Can I get a new review?",
      "created_at": "2019-05-12T16:03:27Z",
      "updated_at": "2019-05-12T16:03:27Z"
    },
    {
      "author": "anmenaga",
      "author_association": "CONTRIBUTOR",
      "body": "@iSazonov @daxian-dbw do you see any pending issues with this PR?",
      "created_at": "2019-07-08T22:12:09Z",
      "updated_at": "2019-07-08T22:12:09Z"
    },
    {
      "author": "SytzeAndr",
      "author_association": "CONTRIBUTOR",
      "body": "Hi, sorry for the radio silence. I fixed the `ReadOnlySpan` trimming\r\n\r\n> @SytzeAndr Please fix Codacy issues in the new code: specifically about converting 'CreateItemOptions','ConstructAlias','IsValidParsedLine' to be static methods. Thank you.\r\n\r\nRegarding static methods, I didn't made them static due to the following reasons. I'm not sure why codefactor doesn't pick these up. Let me know if you agree, if so I suspect it is fine for merging.\r\n\r\n* I couldn't change `CreateItemOptions` to static due to a call to the public method `WriteError`. \r\n* `ConstructAlias` uses `Context` at line 434, which is an internal of the abstract class `InternalCommand.Context` and thus can be derived by calling `this.Context`. I changed `Contect` to `this.Context` and now Codacy doesn't complain anymore.\r\n* `IsValidParsedLine` can't be made static due to a call to the public void `ThrowTerminatingError`.",
      "created_at": "2019-07-13T14:47:00Z",
      "updated_at": "2019-07-14T14:02:21Z"
    },
    {
      "author": "anmenaga",
      "author_association": "CONTRIBUTOR",
      "body": "@daxian-dbw Can you please review this again? thank you.",
      "created_at": "2019-07-25T21:17:24Z",
      "updated_at": "2019-07-25T21:17:24Z"
    },
    {
      "author": "msftbot[bot]",
      "author_association": "NONE",
      "body": "This pull request has been automatically marked as Review Needed because it has been there has not been any activity for **7 days**.\nMainainer, Please provide feedback and/or mark it as `Waiting on Author`",
      "created_at": "2020-05-27T02:04:08Z",
      "updated_at": "2020-05-27T02:04:08Z"
    },
    {
      "author": "iSazonov",
      "author_association": "COLLABORATOR",
      "body": "Since there is no activity for a long time and this is too edge case, we can close the PR.\r\n",
      "created_at": "2020-05-27T06:32:44Z",
      "updated_at": "2020-05-27T06:32:44Z"
    }
  ],
  "created_at": "2019-03-08T18:49:19Z",
  "number": 9091,
  "state": "closed",
  "title": "csv parser used in import alias refactor",
  "updated_at": "2020-05-27T06:33:01Z"
}